---
title: 索引概述
---

索引人是The Graph 网络中的节点运营商，他们质押 Graph代币(GRT) 以提供索引和查询处理服务。 索引人通过他们的服务赚取查询费和索引奖励。 他们还根据 Cobbs-Douglas 回扣函数从回扣池中赚取收益，该回扣池与所有网络贡献者按他们的工作成比例共享。

抵押在协议中的 GRT 会受到解冻期的影响，如果索引人是恶意的并向应用程序提供不正确的数据或索引不正确，则可能会被削减。 索引人也可以从委托人那里获得委托，为网络做出贡献。

索引人根据子图的策展信号选择要索引的子图，其中策展人质押 GRT 以指示哪些子图是高质量的并应优先考虑。 消费者（例如应用程序）还可以设置索引人处理其子图查询的参数，并设置查询费用定价的偏好。

<Difficulty level="ADVANCED" />

## 常见问题

### 成为网络索引人所需的最低份额是多少？

索引人的最低抵押数量目前设置为 10万个 GRT。

### 索引人的收入来源是什么？

**Query fee rebates** - Payments for serving queries on the network. These payments are mediated via state channels between an Indexer and a gateway. Each query request from a gateway contains a payment and the corresponding response a proof of query result validity.

**索引奖励** - 通过 3% 的年度协议范围通货膨胀生成，索引奖励分配给为网络索引子图部署的索引人。

### 索引奖励如何分配？

Indexing rewards come from protocol inflation which is set to 3% annual issuance. They are distributed across subgraphs based on the proportion of all curation signal on each, then distributed proportionally to Indexers based on their allocated stake on that subgraph. **An allocation must be closed with a valid proof of indexing (POI) that meets the standards set by the arbitration charter in order to be eligible for rewards.**

Numerous tools have been created by the community for calculating rewards; you'll find a collection of them organized in the [Community Guides collection](https://www.notion.so/Community-Guides-abbb10f4dba040d5ba81648ca093e70c). You can also find an up to date list of tools in the #Delegators and #Indexers channels on the [Discord server](https://discord.gg/graphprotocol). Here we link a [recommended allocation optimiser](https://github.com/graphprotocol/allocation-optimizer) integrated with the indexer software stack.

### 什么是索引证明 (POI)？

网络中使用 POI 来验证索引人是否正在索引它们分配的子图。 在关闭该分配的分配时，必须提交当前时期第一个区块的 POI，才有资格获得索引奖励。 区块的 POI 是特定子图部署的所有实体存储交易的摘要，直到并包括该块。

### 索引奖励什么时候分配？

当分配活动在28个时期内分配时，分配会不断累积奖励。奖励由索引人收集，并在分配结束时分发。 这可以手动发生，每当索引人想要强制关闭它们时，或者在 28 个时期后，委托人可以关闭索引人的分配，但这会导致没有奖励。28 个时期是最大分配生命周期（现在，一个 时期持续约 24 小时）。

### 可以监控待处理的索引人奖励吗？

The RewardsManager contract has a read-only [getRewards](https://github.com/graphprotocol/contracts/blob/main/packages/contracts/contracts/rewards/RewardsManager.sol#L316) function that can be used to check the pending rewards for a specific allocation.

许多社区制作的仪表板包含悬而未决的奖励值，通过以下步骤可以很容易地手动检查这些值:

1. Query the [mainnet subgraph](https://thegraph.com/explorer/subgraphs/9Co7EQe5PgW3ugCUJrJgRv4u9zdEuDJf8NvMWftNsBH8?view=Query&chain=arbitrum-one) to get the IDs for all active allocations:

```graphql
query indexerAllocations {
  indexer(id: "<INDEXER_ADDRESS>") {
    allocations {
      activeForIndexer {
        allocations {
          id
        }
      }
    }
  }
}
```

Use Etherscan to call `getRewards()`:

- Navigate to [Etherscan interface to Rewards contract](https://etherscan.io/address/0x9Ac758AB77733b4150A901ebd659cbF8cB93ED66#readProxyContract)

<!---->

- To call `getRewards()`:
  - Expand the **9. getRewards** dropdown.
  - Enter the **allocationID** in the input.
  - Click the **Query** button.

### 争议是什么？ 在哪里可以查看？

在争议期间，索引人的查询和分配都可以在Graph上进行争论。 争议期限因争议类型而异。 查询/证明有 7 个时期的争议窗口，而分配有 56 个时期。 在这些期限过后，不能对分配或查询提出争议。 当争议开始时，Fishermen需要至少 10000 GRT 的押金，押金将被锁定，直到争议结束并给出解决方案。 Fishermen是任何引发争议的网络参与者。

Disputes have **three** possible outcomes, so does the deposit of the Fishermen.

- 如果争议被驳回，Fishermen存入的 GRT 将被消耗，争议的索引人将不会被削减。
- 如果以平局方式解决争议，Fishermen的押金将被退还，并且争议的索引人不会被削减。
- 如果争议被接受，Fishermen存入的 GRT 将被退回，有争议的索引人将被削减，Fishermen将获得被削减的 GRT的50%。

Disputes can be viewed in the UI in an Indexer's profile page under the `Disputes` tab.

### 什么是查询费返利？ 何时分配？

Query fees are collected by the gateway and distributed to indexers according to the exponential rebate function (see GIP [here](https://forum.thegraph.com/t/gip-0051-exponential-query-fee-rebates-for-indexers/4162)). The exponential rebate function is proposed as a way to ensure indexers achieve the best outcome by faithfully serving queries. It works by incentivizing Indexers to allocate a large amount of stake (which can be slashed for erring when serving a query) relative to the amount of query fees they may collect.

一旦分配已结束且争议期已过，索引人就可以要求回扣。 查询费用回扣根据查询费用减免和委托池比例分配给索引人及其委托人。

### 什么是查询费减免和索引奖励减免？

The `queryFeeCut` and `indexingRewardCut` values are delegation parameters that the Indexer may set along with cooldownBlocks to control the distribution of GRT between the Indexer and their Delegators. See the last steps in [Staking in the Protocol](/indexing/overview/#stake-in-the-protocol) for instructions on setting the delegation parameters.

- **queryFeeCut** - the % of query fee rebates that will be distributed to the Indexer. If this is set to 95%, the Indexer will receive 95% of the query fees earned when an allocation is closed with the other 5% going to the Delegators.

- **indexingRewardCut** - the % of indexing rewards that will be distributed to the Indexer. If this is set to 95%, the Indexer will receive 95% of the indexing rewards when an allocation is closed and the Delegators will split the other 5%.

### 索引人如何知道要索引哪些子图？

索引人可以通过应用高级技术来进行子图索引决策，从而使自己与众不同，但为了给出一个大致的概念，我们将讨论几个用于评估网络中子图的关键指标:

- **Curation signal** - The proportion of network curation signal applied to a particular subgraph is a good indicator of the interest in that subgraph, especially during the bootstrap phase when query voluming is ramping up.

- **Query fees collected** - The historical data for volume of query fees collected for a specific subgraph is a good indicator of future demand.

- **Amount staked** - Monitoring the behavior of other Indexers or looking at proportions of total stake allocated towards specific subgraphs can allow an Indexer to monitor the supply side for subgraph queries to identify subgraphs that the network is showing confidence in or subgraphs that may show a need for more supply.

- **Subgraphs with no indexing rewards** - Some subgraphs do not generate indexing rewards mainly because they are using unsupported features like IPFS or because they are querying another network outside of mainnet. You will see a message on a subgraph if it is not generating indexing rewards.

### 对硬件有什么要求？

- **Small** - Enough to get started indexing several subgraphs, will likely need to be expanded.
- **Standard** - Default setup, this is what is used in the example k8s/terraform deployment manifests.
- **Medium** - Production Indexer supporting 100 subgraphs and 200-500 requests per second.
- **Large** - Prepared to index all currently used subgraphs and serve requests for the related traffic.

| 设置 | (CPU 数量) | (内存 GB) | (硬盘 TB) | (CPU 数量) | (内存 GB) |
| -- | :------: | :-----: | :-----: | :------: | :-----: |
| 小型 |     4    |    8    |    1    |     4    |    16   |
| 标准 |     8    |    30   |    1    |    12    |    48   |
| 中型 |    16    |    64   |    2    |    32    |    64   |
| 大型 |    72    |   468   |   3.5   |    48    |   184   |

### 索引人应该采取哪些基本的安全防范措施？

- **Operator wallet** - Setting up an operator wallet is an important precaution because it allows an Indexer to maintain separation between their keys that control stake and those that are in control of day-to-day operations. See [Stake in Protocol](/indexing/overview/#stake-in-the-protocol) for instructions.

- **Firewall** - Only the Indexer service needs to be exposed publicly and particular attention should be paid to locking down admin ports and database access: the Graph Node JSON-RPC endpoint (default port: 8030), the Indexer management API endpoint (default port: 18000), and the Postgres database endpoint (default port: 5432) should not be exposed.

## 基础设施

At the center of an Indexer's infrastructure is the Graph Node which monitors the indexed networks, extracts and loads data per a subgraph definition and serves it as a [GraphQL API](/about/#how-the-graph-works). The Graph Node needs to be connected to an endpoint exposing data from each indexed network; an IPFS node for sourcing data; a PostgreSQL database for its store; and Indexer components which facilitate its interactions with the network.

- **PostgreSQL database** - The main store for the Graph Node, this is where subgraph data is stored. The Indexer service and agent also use the database to store state channel data, cost models, indexing rules, and allocation actions.

- **Data endpoint** - For EVM-compatible networks, Graph Node needs to be connected to an endpoint that exposes an EVM-compatible JSON-RPC API. This may take the form of a single client or it could be a more complex setup that load balances across multiple. It's important to be aware that certain subgraphs will require particular client capabilities such as archive mode and/or the parity tracing API.

- **IPFS node (version less than 5)** - Subgraph deployment metadata is stored on the IPFS network. The Graph Node primarily accesses the IPFS node during subgraph deployment to fetch the subgraph manifest and all linked files. Network Indexers do not need to host their own IPFS node, an IPFS node for the network is hosted at https://ipfs.network.thegraph.com.

- **Indexer service** - Handles all required external communications with the network. Shares cost models and indexing statuses, passes query requests from gateways on to a Graph Node, and manages the query payments via state channels with the gateway.

- **Indexer agent** - Facilitates the Indexers interactions onchain including registering on the network, managing subgraph deployments to its Graph Node/s, and managing allocations.

- **Prometheus metrics server** - The Graph Node and Indexer components log their metrics to the metrics server.

注意：为了支持敏捷扩展，建议在不同的节点集之间分开查询和索引问题：查询节点和索引节点。

### 端口概述

> **Important**: Be careful about exposing ports publicly - **administration ports** should be kept locked down. This includes the the Graph Node JSON-RPC and the Indexer management endpoints detailed below.

#### Graph 节点

| 端口   | 用途                             | 路径                                                      | CLI 参数             | 环境 变量 |
| ---- | ------------------------------ | ------------------------------------------------------- | ------------------ | ----- |
| 8000 | GraphQL HTTP 服务 <br />（用于子图查询） | /subgraphs/id/... <br /> <br /> /subgraphs/name/.../... | \--http-port       | -     |
| 8001 | GraphQL WS <br />（用于子图订阅）      | /subgraphs/id/... <br /> <br /> /subgraphs/name/.../... | \--ws-port         | -     |
| 8020 | JSON-RPC <br />（用于管理部署）        | /                                                       | \--admin-port      | -     |
| 8030 | 子图索引状态 API                     | /graphql                                                | \--index-node-port | -     |
| 8040 | Prometheus 指标                  | /metrics                                                | \--metrics-port    | -     |

#### 索引人服务

| 端口   | 用途                                | 路径                                                              | CLI 参数          | 环境 变量                  |
| ---- | --------------------------------- | --------------------------------------------------------------- | --------------- | ---------------------- |
| 7600 | GraphQL HTTP 服务器<br /> （用于付费子图查询） | /subgraphs/id/... <br /> /status <br /> /channel-messages-inbox | \--port         | `INDEXER_SERVICE_PORT` |
| 7300 | Prometheus 指标                     | /metrics                                                        | \--metrics-port | -                      |

#### 索引人代理

| 端口   | Purpose                | 路径     | CLI Argument               | Environment Variable                    |
| ---- | ---------------------- | ------ | -------------------------- | --------------------------------------- |
| 8000 | 索引人管理 API              | /      | \--indexer-management-port | `INDEXER_AGENT_INDEXER_MANAGEMENT_PORT` |

### 在谷歌云上使用 Terraform 建立服务器基础设施

> 注意：索引人可以选择使用AWS，Microsoft Azure, or Alibaba。

#### 安装先决条件

- 谷歌云 SDK
- Kubectl 命令行工具
- Terraform

#### 创建一个谷歌云项目

- Clone or navigate to the [Indexer repository](https://github.com/graphprotocol/indexer).

- Navigate to the `./terraform` directory, this is where all commands should be executed.

```sh
cd terraform
```

- 通过谷歌云认证并创建一个新项目。

```sh
gcloud auth login
project=<PROJECT_NAME>
gcloud projects create --enable-cloud-apis $project
```

- 使用 Google Cloud Console 的计费页面为新项目启用计费。

- 创建谷歌云配置。

```sh
proj_id=$(gcloud projects list --format='get(project_id)' --filter="name=$project")
gcloud config configurations create $project
gcloud config set project "$proj_id"
gcloud config set compute/region us-central1
gcloud config set compute/zone us-central1-a
```

- 启用所需的 Google Cloud API。

```sh
gcloud services enable compute.googleapis.com
gcloud services enable container.googleapis.com
gcloud services enable servicenetworking.googleapis.com
gcloud services enable sqladmin.googleapis.com
```

- 创建一个服务账户。

```sh
svc_name=<SERVICE_ACCOUNT_NAME>
gcloud iam service-accounts create $svc_name \
  --description="Service account for Terraform" \
  --display-name="$svc_name"
gcloud iam service-accounts list
# Get the email of the service account from the list
svc=$(gcloud iam service-accounts list --format='get(email)'
--filter="displayName=$svc_name")
gcloud iam service-accounts keys create .gcloud-credentials.json \
  --iam-account="$svc"
gcloud projects add-iam-policy-binding $proj_id \
  --member serviceAccount:$svc \
  --role roles/editor
```

- 启用将在下一步中创建的数据库和 Kubernetes 集群之间的对等连接。

```sh
gcloud compute addresses create google-managed-services-default \
  --prefix-length=20 \
  --purpose=VPC_PEERING \
  --network default \
  --global \
  --description 'IP Range for peer networks.'
gcloud services vpc-peerings connect \
  --network=default \
  --ranges=google-managed-services-default
```

- 创建最小的 terraform 配置文件（根据需要更新）。

```sh
indexer=<INDEXER_NAME>
cat > terraform.tfvars <<EOF
project = "$proj_id"
indexer = "$indexer"
database_password = "<database password>"
EOF
```

#### 使用 Terraform 创建基础设施

Before running any commands, read through [variables.tf](https://github.com/graphprotocol/indexer/blob/main/terraform/variables.tf) and create a file `terraform.tfvars` in this directory (or modify the one we created in the last step). For each variable where you want to override the default, or where you need to set a value, enter a setting into `terraform.tfvars`.

- 运行以下命令来创建基础设施。

```sh
# Install required plugins
terraform init

# View plan for resources to be created
terraform plan

# Create the resources (expect it to take up to 30 minutes)
terraform apply
```

Download credentials for the new cluster into `~/.kube/config` and set it as your default context.

```sh
gcloud container clusters get-credentials $indexer
kubectl config use-context $(kubectl config get-contexts --output='name'
| grep $indexer)
```

#### 为索引人创建 Kubernetes 组件

- Copy the directory `k8s/overlays` to a new directory `$dir,` and adjust the `bases` entry in `$dir/kustomization.yaml` so that it points to the directory `k8s/base`.

- Read through all the files in `$dir` and adjust any values as indicated in the comments.

Deploy all resources with `kubectl apply -k $dir`.

### Graph 节点

[Graph Node](https://github.com/graphprotocol/graph-node) is an open source Rust implementation that event sources the Ethereum blockchain to deterministically update a data store that can be queried via the GraphQL endpoint. Developers use subgraphs to define their schema, and a set of mappings for transforming the data sourced from the blockchain and the Graph Node handles syncing the entire chain, monitoring for new blocks, and serving it via a GraphQL endpoint.

#### 从来源开始

#### 安装先决条件

- **Rust**

- **PostgreSQL**

- **IPFS**

- **Additional Requirements for Ubuntu users** - To run a Graph Node on Ubuntu a few additional packages may be needed.

```sh
sudo apt-get install -y clang libpg-dev libssl-dev pkg-config
```

#### 设置

1. 启动 PostgreSQL 数据库服务器

```sh
initdb -D .postgres
pg_ctl -D .postgres -l logfile start
createdb graph-node
```

2. Clone [Graph Node](https://github.com/graphprotocol/graph-node) repo and build the source by running `cargo build`

3. 现在，所有的依赖关系都已设置完毕，启动 Graph节点。

```sh
cargo run -p graph-node --release -- \
  --postgres-url postgresql://[USERNAME]:[PASSWORD]@localhost:5432/graph-node \
  --ethereum-rpc [NETWORK_NAME]:[URL] \
  --ipfs https://ipfs.network.thegraph.com
```

#### 使用 Docker

#### 先决条件

- **Ethereum node** - By default, the docker compose setup will use mainnet: [http://host.docker.internal:8545](http://host.docker.internal:8545) to connect to the Ethereum node on your host machine. You can replace this network name and url by updating `docker-compose.yaml`.

#### 设置

1. 克隆Graph节点并导航到Docker目录。

```sh
git clone https://github.com/graphprotocol/graph-node
cd graph-node/docker
```

2. For linux users only - Use the host IP address instead of `host.docker.internal` in the `docker-compose.yaml `using the included script:

```sh
./setup.sh
```

3. 启动一个本地Graph节点，它将连接到你的以太坊端点。

```sh
docker-compose up
```

### 索引人组件

要成功地参与网络，需要几乎持续的监控和互动，所以我们建立了一套 Typescript 应用程序，以方便索引人的网络参与。 有三个索引人组件。

- **Indexer agent** - The agent monitors the network and the Indexer's own infrastructure and manages which subgraph deployments are indexed and allocated towards onchain and how much is allocated towards each.

- **Indexer service** - The only component that needs to be exposed externally, the service passes on subgraph queries to the graph node, manages state channels for query payments, shares important decision making information to clients like the gateways.

- **Indexer CLI** - The command line interface for managing the Indexer agent. It allows Indexers to manage cost models, manual allocations, actions queue, and indexing rules.

#### 开始

The Indexer agent and Indexer service should be co-located with your Graph Node infrastructure. There are many ways to set up virtual execution environments for your Indexer components; here we'll explain how to run them on baremetal using NPM packages or source, or via kubernetes and docker on the Google Cloud Kubernetes Engine. If these setup examples do not translate well to your infrastructure there will likely be a community guide to reference, come say hi on [Discord](https://discord.gg/graphprotocol)! Remember to [stake in the protocol](/indexing/overview/#stake-in-the-protocol) before starting up your Indexer components!

#### 来自 NPM 包

```sh
npm install -g @graphprotocol/indexer-service
npm install -g @graphprotocol/indexer-agent

# Indexer CLI is a plugin for Graph CLI, so both need to be installed:
npm install -g @graphprotocol/graph-cli
npm install -g @graphprotocol/indexer-cli

# Indexer service
graph-indexer-service start ...

# Indexer agent
graph-indexer-agent start ...

# Indexer CLI
#Forward the port of your agent pod if using Kubernetes
kubectl port-forward pod/POD_ID 18000:8000
graph indexer connect http://localhost:18000/
graph indexer ...
```

#### 来自数据源

```sh
# From Repo root directory
yarn

# Indexer Service
cd packages/indexer-service
./bin/graph-indexer-service start ...

# Indexer agent
cd packages/indexer-agent
./bin/graph-indexer-service start ...

# Indexer CLI
cd packages/indexer-cli
./bin/graph-indexer-cli indexer connect http://localhost:18000/
./bin/graph-indexer-cli indexer ...
```

#### 使用 docker

- 从注册表中提取图像

```sh
docker pull ghcr.io/graphprotocol/indexer-service:latest
docker pull ghcr.io/graphprotocol/indexer-agent:latest
```

或从数据源本地生成图像

```sh
# Indexer service
docker build \
  --build-arg NPM_TOKEN=<npm-token> \
  -f Dockerfile.indexer-service \
  -t indexer-service:latest \
# Indexer agent
docker build \
  --build-arg NPM_TOKEN=<npm-token> \
  -f Dockerfile.indexer-agent \
  -t indexer-agent:latest \
```

- 运行组件

```sh
docker run -p 7600:7600 -it indexer-service:latest ...
docker run -p 18000:8000 -it indexer-agent:latest ...
```

**NOTE**: After starting the containers, the Indexer service should be accessible at [http://localhost:7600](http://localhost:7600) and the Indexer agent should be exposing the Indexer management API at [http://localhost:18000/](http://localhost:18000/).

#### 使用 K8s 和 Terraform

See the [Setup Server Infrastructure Using Terraform on Google Cloud](/indexing/overview/#setup-server-infrastructure-using-terraform-on-google-cloud) section

#### 使用方法

> **NOTE**: All runtime configuration variables may be applied either as parameters to the command on startup or using environment variables of the format `COMPONENT_NAME_VARIABLE_NAME`(ex. `INDEXER_AGENT_ETHEREUM`).

#### 索引代理

```sh
graph-indexer-agent start \
  --ethereum <MAINNET_ETH_ENDPOINT> \
  --ethereum-network mainnet \
  --mnemonic <MNEMONIC> \
  --indexer-address <INDEXER_ADDRESS> \
  --graph-node-query-endpoint http://localhost:8000/ \
  --graph-node-status-endpoint http://localhost:8030/graphql \
  --graph-node-admin-endpoint http://localhost:8020/ \
  --public-indexer-url http://localhost:7600/ \
  --indexer-geo-coordinates <YOUR_COORDINATES> \
  --index-node-ids default \
  --indexer-management-port 18000 \
  --metrics-port 7040 \
  --network-subgraph-endpoint http://query-node-0:8000/subgraphs/id/QmUzRg2HHMpbgf6Q4VHKNDbtBEJnyp5JWCh2gUX9AV6jXv \
  --default-allocation-amount 100 \
  --register true \
  --inject-dai true \
  --postgres-host localhost \
  --postgres-port 5432 \
  --postgres-username <DB_USERNAME> \
  --postgres-password <DB_PASSWORD> \
  --postgres-database indexer \
  --allocation-management auto \
  | pino-pretty
```

#### 索引人服务

```sh
SERVER_HOST=localhost \
SERVER_PORT=5432 \
SERVER_DB_NAME=is_staging \
SERVER_DB_USER=<DB_USERNAME> \
SERVER_DB_PASSWORD=<DB_PASSWORD> \
graph-indexer-service start \
  --ethereum <MAINNET_ETH_ENDPOINT> \
  --ethereum-network mainnet \
  --mnemonic <MNEMONIC> \
  --indexer-address <INDEXER_ADDRESS> \
  --port 7600 \
  --metrics-port 7300 \
  --graph-node-query-endpoint http://localhost:8000/ \
  --graph-node-status-endpoint http://localhost:8030/graphql \
  --postgres-host localhost \
  --postgres-port 5432 \
  --postgres-username <DB_USERNAME> \
  --postgres-password <DB_PASSWORD> \
  --postgres-database is_staging \
  --network-subgraph-endpoint http://query-node-0:8000/subgraphs/id/QmUzRg2HHMpbgf6Q4VHKNDbtBEJnyp5JWCh2gUX9AV6jXv \
  | pino-pretty
```

#### 索引人 CLI

The Indexer CLI is a plugin for [`@graphprotocol/graph-cli`](https://www.npmjs.com/package/@graphprotocol/graph-cli) accessible in the terminal at `graph indexer`.

```sh
graph indexer connect http://localhost:18000
graph indexer status
```

#### 使用Indexer CLI 管理索引人

The suggested tool for interacting with the **Indexer Management API** is the **Indexer CLI**, an extension to the **Graph CLI**. The Indexer agent needs input from an Indexer in order to autonomously interact with the network on the behalf of the Indexer. The mechanism for defining Indexer agent behavior are **allocation management** mode and **indexing rules**. Under auto mode, an Indexer can use **indexing rules** to apply their specific strategy for picking subgraphs to index and serve queries for. Rules are managed via a GraphQL API served by the agent and known as the Indexer Management API. Under manual mode, an Indexer can create allocation actions using **actions queue** and explicitly approve them before they get executed. Under oversight mode, **indexing rules** are used to populate **actions queue** and also require explicit approval for execution.

#### 使用方法

The **Indexer CLI** connects to the Indexer agent, typically through port-forwarding, so the CLI does not need to run on the same server or cluster. To help you get started, and to provide some context, the CLI will briefly be described here.

- `graph indexer connect <url>` - Connect to the Indexer management API. Typically the connection to the server is opened via port forwarding, so the CLI can be easily operated remotely. (Example: `kubectl port-forward pod/<indexer-agent-pod> 8000:8000`)

- `graph indexer rules get [options] <deployment-id> [<key1> ...]` - Get one or more indexing rules using `all` as the `<deployment-id>` to get all rules, or `global` to get the global defaults. An additional argument `--merged` can be used to specify that deployment specific rules are merged with the global rule. This is how they are applied in the Indexer agent.

- `graph indexer rules set [options] <deployment-id> <key1> <value1> ...` - Set one or more indexing rules.

- `graph indexer rules start [options] <deployment-id>` - Start indexing a subgraph deployment if available and set its `decisionBasis` to `always`, so the Indexer agent will always choose to index it. If the global rule is set to always then all available subgraphs on the network will be indexed.

- `graph indexer rules stop [options] <deployment-id>` - Stop indexing a deployment and set its `decisionBasis` to never, so it will skip this deployment when deciding on deployments to index.

- `graph indexer rules maybe [options] <deployment-id>` — Set the `decisionBasis` for a deployment to `rules`, so that the Indexer agent will use indexing rules to decide whether to index this deployment.

- `graph indexer actions get [options] <action-id>` - Fetch one or more actions using `all` or leave `action-id` empty to get all actions. An additional argument `--status` can be used to print out all actions of a certain status.

- `graph indexer action queue allocate <deployment-id> <allocation-amount>` - Queue allocation action

- `graph indexer action queue reallocate <deployment-id> <allocation-id> <allocationAmount>` - Queue reallocate action

- `graph indexer action queue unallocate <deployment-id> <allocation-id>` - Queue unallocate action

- `graph indexer actions cancel [<action-id> ...]` - Cancel all action in the queue if id is unspecified, otherwise cancel array of id with space as separator

- `graph indexer actions approve [<action-id> ...]` - Approve multiple actions for execution

- `graph indexer actions execute approve` - Force the worker to execute approved actions immediately

All commands which display rules in the output can choose between the supported output formats (`table`, `yaml`, and `json`) using the `-output` argument.

#### 索引规则

Indexing rules can either be applied as global defaults or for specific subgraph deployments using their IDs. The `deployment` and `decisionBasis` fields are mandatory, while all other fields are optional. When an indexing rule has `rules` as the `decisionBasis`, then the Indexer agent will compare non-null threshold values on that rule with values fetched from the network for the corresponding deployment. If the subgraph deployment has values above (or below) any of the thresholds it will be chosen for indexing.

For example, if the global rule has a `minStake` of **5** (GRT), any subgraph deployment which has more than 5 (GRT) of stake allocated to it will be indexed. Threshold rules include `maxAllocationPercentage`, `minSignal`, `maxSignal`, `minStake`, and `minAverageQueryFees`.

数据模型：

```graphql
type IndexingRule {
    identifier: string
    identifierType: IdentifierType
    decisionBasis: IndexingDecisionBasis!
    allocationAmount: number | null
    allocationLifetime: number | null
    autoRenewal: boolean
    parallelAllocations: number | null
    maxAllocationPercentage: number | null
    minSignal: string | null
    maxSignal: string | null
    minStake: string | null
    minAverageQueryFees: string | null
    custom: string | null
    requireSupported: boolean | null
  }

IdentifierType {
  deployment
  subgraph
  group
}

IndexingDecisionBasis {
  rules
  never
  always
  offchain
}
```

索引规则用法示例:

```
graph indexer rules offchain QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK

graph indexer rules set QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK decisionBasis always allocationAmount 123321 allocationLifetime 14 autoRenewal false requireSupported false

graph indexer rules stop QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK

graph indexer rules delete QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK
```

#### 操作队列CLI

The indexer-cli provides an `actions` module for manually working with the action queue. It uses the **Graphql API** hosted by the indexer management server to interact with the actions queue.

The action execution worker will only grab items from the queue to execute if they have `ActionStatus = approved`. In the recommended path actions are added to the queue with ActionStatus = queued, so they must then be approved in order to be executed onchain. The general flow will look like:

- 第三方优化器工具或indexer-cli用户添加到队列的操作
- Indexer can use the `indexer-cli` to view all queued actions
- Indexer (or other software) can approve or cancel actions in the queue using the `indexer-cli`. The approve and cancel commands take an array of action ids as input.
- The execution worker regularly polls the queue for approved actions. It will grab the `approved` actions from the queue, attempt to execute them, and update the values in the db depending on the status of execution to `success` or `failed`.
- If an action is successful the worker will ensure that there is an indexing rule present that tells the agent how to manage the allocation moving forward, useful when taking manual actions while the agent is in `auto` or `oversight` mode.
- 索引人可以监视操作队列以查看操作执行的历史记录，如果需要，可以在操作项执行失败时重新批准和更新操作项。操作队列提供排队和执行的所有操作的历史记录。

数据模型：

```graphql
Type ActionInput {
    status: ActionStatus
    type: ActionType
    deploymentID: string | null
    allocationID: string | null
    amount: string | null
    poi: string | null
    force: boolean | null
    source: string
    reason: string | null
    priority: number | null
}

ActionStatus {
  queued
  approved
  pending
  success
  failed
  canceled
}

ActionType {
  allocate
  unallocate
  reallocate
  collect
}
```

数据源用法示例

```bash
graph indexer actions get all

graph indexer actions get --status queued

graph indexer actions queue allocate QmeqJ6hsdyk9dVbo1tvRgAxWrVS3rkERiEMsxzPShKLco6 5000

graph indexer actions queue reallocate QmeqJ6hsdyk9dVbo1tvRgAxWrVS3rkERiEMsxzPShKLco6 0x4a58d33e27d3acbaecc92c15101fbc82f47c2ae5 55000

graph indexer actions queue unallocate QmeqJ6hsdyk9dVbo1tvRgAxWrVS3rkERiEMsxzPShKLco6 0x4a58d33e27d3acbaecc92c15101fbc82f47c2ae

graph indexer actions cancel

graph indexer actions approve 1 3 5

graph indexer actions execute approve
```

请注意，分配管理支持的操作类型有不同的输入要求：

- `Allocate` - allocate stake to a specific subgraph deployment

  - 所需的操作参数：
    - 部署ID
    - 数量

- `Unallocate` - close allocation, freeing up the stake to reallocate elsewhere

  - 所需的操作参数：
    - 分配ID
    - 部署ID
  - 可选操作参数：
    - poi
    - force（使用提供的POI的力量，即使它与图形节点提供的不匹配)

- `Reallocate` - atomically close allocation and open a fresh allocation for the same subgraph deployment

  - 所需的操作参数：
    - 分配ID
    - 部署ID
    - 数量
  - 可选操作参数：
    - poi
    - force（使用提供的POI的力量，即使它与图形节点提供的不匹配)

#### 成本模式

成本模型根据市场和查询属性为查询提供动态定价。索引人服务与网关共享一个成本模型，用于它们打算响应查询的每个子图。反过来，网关使用成本模型对每个查询进行索引人选择决策，并与选定的索引人协商付款。

#### Agora

Agora 语言提供了一种灵活的格式来声明查询的成本模型。 Agora 价格模型是一系列的语句，它们按照 GraphQL 查询中每个顶层查询的顺序执行。 对于每个顶层查询，第一个与其匹配的语句决定了该查询的价格。

语句由一个用于匹配 GraphQL 查询的谓词和一个成本表达式组成，该表达式在评估时输出一个以十进制 GRT 表示的成本。 查询的命名参数位置中的值可以在谓词中捕获并在表达式中使用。 也可以在表达式中设置全局，并代替占位符。

成本模型示例：

```
# This statement captures the skip value,
# uses a boolean expression in the predicate to match specific queries that use `skip`
# and a cost expression to calculate the cost based on the `skip` value and the SYSTEM_LOAD global
query { pairs(skip: $skip) { id } } when $skip > 2000 => 0.0001 * $skip * $SYSTEM_LOAD;

# This default will match any GraphQL expression.
# It uses a Global substituted into the expression to calculate cost
default => 0.1 * $SYSTEM_LOAD;
```

使用上述模型的查询成本计算示例：

| Query                                                                        | Price   |
| ---------------------------------------------------------------------------- | ------- |
| &#123; pairs(skip: 5000) &#123; id &#125; &#125;                             | 0.5 GRT |
| &#123; tokens &#123; symbol &#125; &#125;                                    | 0.1 GRT |
| &#123; pairs(skip: 5000) &#123; id &#125; tokens &#123; symbol &#125; &#125; | 0.6 GRT |

#### 应用成本模式

成本模型是通过索引人 CLI 应用的，CLI 将它们传递给索引人代理的索引人管理 API，以便存储在数据库中。 然后，索引人服务将接收这些模型，并在网关要求时将成本模型提供给它们。

```sh
indexer cost set variables '{ "SYSTEM_LOAD": 1.4 }'
indexer cost set model my_model.agora
```

## 与网络的交互

### 在协议中进行质押

The first steps to participating in the network as an Indexer are to approve the protocol, stake funds, and (optionally) set up an operator address for day-to-day protocol interactions.

> Note: For the purposes of these instructions Remix will be used for contract interaction, but feel free to use your tool of choice ([OneClickDapp](https://oneclickdapp.com/), [ABItopic](https://abitopic.io/), and [MyCrypto](https://www.mycrypto.com/account) are a few other known tools).

Once an Indexer has staked GRT in the protocol, the [Indexer components](/indexing/overview/#indexer-components) can be started up and begin their interactions with the network.

#### 批准代币

1. Open the [Remix app](https://remix.ethereum.org/) in a browser

2. In the `File Explorer` create a file named **GraphToken.abi** with the [token ABI](https://raw.githubusercontent.com/graphprotocol/contracts/mainnet-deploy-build/build/abis/GraphToken.json).

3. With `GraphToken.abi` selected and open in the editor, switch to the `Deploy and run transactions` section in the Remix interface.

4. Under environment select `Injected Web3` and under `Account` select your Indexer address.

5. Set the GraphToken contract address - Paste the GraphToken contract address (`0xc944E90C64B2c07662A292be6244BDf05Cda44a7`) next to `At Address` and click the `At address` button to apply.

6. Call the `approve(spender, amount)` function to approve the Staking contract. Fill in `spender` with the Staking contract address (`0xF55041E37E12cD407ad00CE2910B8269B01263b9`) and `amount` with the tokens to stake (in wei).

#### 质押代币

1. Open the [Remix app](https://remix.ethereum.org/) in a browser

2. In the `File Explorer` create a file named **Staking.abi** with the staking ABI.

3. With `Staking.abi` selected and open in the editor, switch to the `Deploy and run transactions` section in the Remix interface.

4. Under environment select `Injected Web3` and under `Account` select your Indexer address.

5. Set the Staking contract address - Paste the Staking contract address (`0xF55041E37E12cD407ad00CE2910B8269B01263b9`) next to `At Address` and click the `At address` button to apply.

6. Call `stake()` to stake GRT in the protocol.

7. (Optional) Indexers may approve another address to be the operator for their Indexer infrastructure in order to separate the keys that control the funds from those that are performing day to day actions such as allocating on subgraphs and serving (paid) queries. In order to set the operator call `setOperator()` with the operator address.

8. (Optional) In order to control the distribution of rewards and strategically attract Delegators Indexers can update their delegation parameters by updating their indexingRewardCut (parts per million), queryFeeCut (parts per million), and cooldownBlocks (number of blocks). To do so call `setDelegationParameters()`. The following example sets the queryFeeCut to distribute 95% of query rebates to the Indexer and 5% to Delegators, set the indexingRewardCutto distribute 60% of indexing rewards to the Indexer and 40% to Delegators, and set `thecooldownBlocks` period to 500 blocks.

```
setDelegationParameters(950000, 600000, 500)
```

### Setting delegation parameters

The `setDelegationParameters()` function in the [staking contract](https://github.com/graphprotocol/contracts/blob/main/packages/contracts/contracts/staking/Staking.sol) is essential for Indexers, allowing them to set parameters that define their interactions with Delegators, influencing their reward sharing and delegation capacity.

### How to set delegation parameters

To set the delegation parameters using Graph Explorer interface, follow these steps:

1. Navigate to [Graph Explorer](https://thegraph.com/explorer/).
2. Connect your wallet. Choose multisig (such as Gnosis Safe) and then select mainnet. Note: You will need to repeat this process for Arbitrum One.
3. Connect the wallet you have as a signer.
4. Navigate to the 'Settings' section and select 'Delegation Parameters'. These parameters should be configured to achieve an effective cut within the desired range. Upon entering values in the provided input fields, the interface will automatically calculate the effective cut. Adjust these values as necessary to attain the desired effective cut percentage.
5. Submit the transaction to the network.

> Note: This transaction will need to be confirmed by the multisig wallet signers.

### 分配的生命周期

After being created by an Indexer a healthy allocation goes through two states.

- **Active** - Once an allocation is created onchain ([allocateFrom()](https://github.com/graphprotocol/contracts/blob/main/packages/contracts/contracts/staking/Staking.sol#L316)) it is considered **active**. A portion of the Indexer's own and/or delegated stake is allocated towards a subgraph deployment, which allows them to claim indexing rewards and serve queries for that subgraph deployment. The Indexer agent manages creating allocations based on the Indexer rules.

- **Closed** - An Indexer is free to close an allocation once 1 epoch has passed ([closeAllocation()](https://github.com/graphprotocol/contracts/blob/main/packages/contracts/contracts/staking/Staking.sol#L335)) or their Indexer agent will automatically close the allocation after the **maxAllocationEpochs** (currently 28 days). When an allocation is closed with a valid proof of indexing (POI) their indexing rewards are distributed to the Indexer and its Delegators ([learn more](/indexing/overview/#how-are-indexing-rewards-distributed)).

Indexers are recommended to utilize offchain syncing functionality to sync subgraph deployments to chainhead before creating the allocation onchain. This feature is especially useful for subgraphs that may take longer than 28 epochs to sync or have some chances of failing undeterministically.

---
title: Comment créer un subgraph
---

Un subgraph récupère des données depuis une blockchain, les manipule puis les enregistre afin que ces données soient aisément accessibles via GraphQL.

![Defining a Subgraph](/img/defining-a-subgraph.png)

Un subgraph se constitue des fichiers suivants :

- `subgraph.yaml` : un fichier YAML qui contient le manifeste du subgraph

- `schema.graphql`: un schéma GraphQL qui définit les données stockées pour votre subgraph et comment les interroger via GraphQL

- `Mappages AssemblyScript` : [AssemblyScript](https://github.com/AssemblyScript/assemblyscript) qui traduit les données d'événement en entités définies dans votre schéma (par exemple `mapping.ts` dans ce tutoriel)

> In order to use your subgraph on The Graph's decentralized network, you will need to [create an API key](/deploying/subgraph-studio-faqs/#2-how-do-i-create-an-api-key). It is recommended that you [add signal](/network/curating/#how-to-signal) to your subgraph with at least [10,000 GRT](/network-transition-faq/#how-can-i-ensure-that-my-subgraph-will-be-picked-up-by-indexer-on-the-graph-network).

Avant d'aller en détail à propos du contenu du manifeste, installons l'[interface de ligne de commande de TheGraph](https://github.com/graphprotocol/graph-cli). Nous en aurons besoin pour la création et le déploiement du subgraph.

## Installation du Graph CLI

La CLI Graph est écrite en JavaScript et vous devrez installer soit `yarn` ou `npm` pour l'utiliser ; on suppose que vous avez du fil dans ce qui suit.

Une fois que vous avez `yarn`, installez la CLI Graph en exécutant

**Installation avec yarn :**

```bash
npm install -g @graphprotocol/graph-cli
```

**Installation avec npm :**

```bash
npm install -g @graphprotocol/graph-cli
```

Une fois installée, la commande `graph init` est utilisée pour créer un nouveau projet soit depuis un contrat existant ou un exemple de subgraph. Il vous est possible de créer un subgraph sur Subgraph Studio grâce à `graph init --product subgraph-studio`. Si vous avez déjà déployé un contrat sur le réseau cible, il peut s'avérer judicieux d'utiliser ce contrat comme base pour votre subgraph.

## D'un contrat existant

La commande suivante crée un subgraph qui indexe tous les événements d'un contrat existant. Il essaie de récupérer l'ABI du contrat via Etherscan et utilise un chemin de fichier local en cas d'échec. Si l'un des arguments facultatifs manque, il vous guide à travers un formulaire interactif.

```sh
graph init \
  --product subgraph-studio
  --du-contract <CONTRACT_ADDRESS> \
  [--network <ETHEREUM_NETWORK>] \
  [--abi <FILE>] \
  <SUBGRAPH_SLUG> [<DIRECTORY>]
```

The `<SUBGRAPH_SLUG>` est l'ID de votre subgraph dans Subgraph Studio, il peut être trouvé sur la page d'information de votre subgraph.

## A partir d'un exemple de subgraph

Le second mode `graph init` prend en charge est la création d'un nouveau projet à partir d'un exemple de subgraph. La commande suivante le fait :

```sh
studio graph init --<SUBGRAPH_SLUG>
```

Le subgraph d'exemple est basé sur le contrat Gravity de Dani Grant qui gère les avatars d'utilisateurs et émet des événements `NewGravatar` ou `UpdateGravatar` chaque fois que des avatars sont créés ou mis à jour. Le subgraphe gère ces événements en créant des entités `Gravatar` dans le stockage des nœuds de The Graph et en veillant à ce qu'elles soient mises à jour en fonction des événements. Les sections suivantes décrivent les fichiers qui composent le manifeste de subgraph pour cet exemple.

## Ajouter de nouvelles sources de données à un subgraph existant

Depuis `v0.31.0`, le `graph-cli` prend en charge l'ajout de nouvelles sources de données à un subgraph existant via la commande `graph add`.

```sh
graph add <address> [<subgraph-manifest default: "./subgraph.yaml">]

Options:

      --abi <path>              Path to the contract ABI (default: download from Etherscan)
      --contract-name           Name of the contract (default: Contract)
      --merge-entities          Whether to merge entities with the same name (default: false)
      --network-file <path>     Networks config file path (default: "./networks.json")
```

La commande `add` récupérera l'ABI depuis Etherscan (sauf si un chemin ABI est spécifié avec l'option `--abi`) et créera une nouvelle `dataSource` de la même manière que la commande `graph init` crée un `dataSource` `--from-contract`, mettant à jour le schéma et les mappages en conséquence.

L'option `--merge-entities` identifie la façon dont le développeur souhaite gérer les conflits de noms d'`entité` et d'`événement` :

- Si `true` : le nouveau `dataSource` doit utiliser les `eventHandlers` & `entités`.
- Si `false` : une nouvelle entité & le gestionnaire d'événements doit être créé avec `${dataSourceName}{EventName}`.

L'`adresse` du contrat sera écrite dans le `networks.json` du réseau concerné.

> **Remarque :** Lorsque vous utilisez la Cli interactive, après avoir exécuté avec succès `graph init`, vous serez invité à ajouter une nouvelle `dataSource`.

## Le manifeste du subgraph

Le manifeste du subgraph `subgraph.yaml` définit les contrats intelligents que votre subgraph indexe, les événements de ces contrats auxquels prêter attention et comment mapper les données d'événements aux entités que Graph Node stocke et permet d'interroger. La spécification complète des manifestes de subgraphs peut être trouvée [ici](https://github.com/graphprotocol/graph-node/blob/master/docs/subgraph-manifest.md).

Pour l'exemple de subgraph, `subgraph.yaml` est :

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
repository: https://github.com/graphprotocol/graph-tooling
schema:
  file: ./schema.graphql
dataSources:
  - kind: ethereum/contract
    name: Gravity
    network: mainnet
    source:
      address: '0x2E645469f354BB4F5c8a05B3b30A929361cf77eC'
      abi: Gravity
      startBlock: 6175244
      endBlock: 7175245
    context:
      foo:
        type: Bool
        data: true
      bar:
        type: String
        data: 'bar'
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      entities:
        - Gravatar
      abis:
        - name: Gravity
          file: ./abis/Gravity.json
      eventHandlers:
        - event: NewGravatar(uint256,address,string,string)
          handler: handleNewGravatar
        - event: UpdatedGravatar(uint256,address,string,string)
          handler: handleUpdatedGravatar
      callHandlers:
        - function: createGravatar(string,string)
          handler: handleCreateGravatar
      blockHandlers:
        - handler: handleBlock
        - handler: handleBlockWithCall
          filter:
            kind: call
      file: ./src/mapping.ts
```

Les entrées importantes à mettre à jour pour le manifeste sont :

- `description`: a human-readable description of what the subgraph is. This description is displayed by the Graph Explorer when the subgraph is deployed to the hosted service.

- `repository`: the URL of the repository where the subgraph manifest can be found. This is also displayed by The Graph Explorer.

- `fonctionnalités` : une liste de tous les noms de [fonctionnalités](#experimental-features) utilisés.

- `dataSources.source`: the address of the smart contract the subgraph sources, and the ABI of the smart contract to use. The address is optional; omitting it allows to index matching events from all contracts.

- `dataSources.source` : l'adresse du contrat intelligent, les sources du subgraph, et l'Abi du contrat intelligent à utiliser. L'adresse est facultative ; son omission permet d'indexer les événements correspondants de tous les contrats.

- `dataSources.source.endBlock`: The optional number of the block that the data source stops indexing at, including that block. Minimum spec version required: `0.0.9`.

- `dataSources.context` : paires clé-valeur qui peuvent être utilisées dans les mappages de subgraphs. Prend en charge différents types de données comme `Bool`, `String`, `Int`, `Int8`, `BigDecimal`, `Octets`, `Liste` et `BigInt`. Chaque variable doit spécifier son `type` et ses `données`. Ces variables de contexte sont ensuite accessibles dans les fichiers de mappage, offrant des options plus configurables pour le développement de subgraphs.

- `dataSources.mapping.entities` : les entités que la source de données écrit dans le magasin. Le schéma de chaque entité est défini dans le fichier schema.graphql.

- `dataSources.mapping.abis` : un ou plusieurs fichiers ABI nommés pour le contrat source ainsi que tout autre contrat intelligent avec lequel vous interagissez à partir des mappages.

- `dataSources.mapping.eventHandlers` : répertorie les événements de contrat intelligent auxquels ce subgraph réagit et les gestionnaires du mappage —./src/mapping.ts dans l'exemple qui transforment ces événements en entités dans le magasin.

- `dataSources.mapping.callHandlers`: lists the smart contract functions this subgraph reacts to and handlers in the mapping that transform the inputs and outputs to function calls into entities in the store.

- `dataSources.mapping.blockHandlers`: lists the blocks this subgraph reacts to and handlers in the mapping to run when a block is appended to the chain. Without a filter, the block handler will be run every block. An optional call-filter can be provided by adding a `filter` field with `kind: call` to the handler. This will only run the handler if the block contains at least one call to the data source contract.

Un seul subgraph peut indexer les données de plusieurs contrats intelligents. Ajoutez une entrée pour chaque contrat à partir duquel les données doivent être indexées dans le tableau `dataSources`.

Les déclencheurs d'une source de données au sein d'un bloc sont classés à l'aide du processus suivant :

1. Les déclencheurs d'événements et d'appels sont d'abord classés par index de transaction au sein du bloc.
2. Les déclencheurs d'événements et d'appels au sein d'une même transaction sont classés selon une convention : les déclencheurs d'événements d'abord, puis les déclencheurs d'appel, chaque type respectant l'ordre dans lequel ils sont définis dans le manifeste.
3. Block triggers are run after event and call triggers, in the order they are defined in the manifest.

Ces règles de commande sont susceptibles de changer.

### Getting The ABIs

Le(s) fichier(s) ABI doivent correspondre à votre(vos) contrat(s). Il existe plusieurs façons d'obtenir des fichiers ABI :

- Si vous construisez votre propre projet, vous aurez probablement accès à vos ABI les plus récents.
- Si vous créez un subgraph pour un projet public, vous pouvez télécharger ce projet sur votre ordinateur et obtenir l'ABI en utilisant la [`compilation truffle `](https://truffleframework.com/docs/truffle/overview) ou en utilisant solc pour compiler.
- Vous pouvez également trouver l'ABI sur [Etherscan](https://etherscan.io/), mais ce n'est pas toujours fiable, car l'ABI qui y est téléchargé peut être obsolète. Assurez-vous d'avoir le bon ABI, sinon l'exécution de votre subgraph échouera.

## The GraphQL Schema

Le schéma de votre subgraph se trouve dans le fichier `schema.graphql`. Les schémas GraphQL sont définis à l'aide du langage de définition d'interface GraphQL. Si vous n'avez jamais écrit de schéma GraphQL, il est recommandé de consulter cette introduction sur le système de types GraphQL. La documentation de référence pour les schémas GraphQL est disponible dans la section [API GraphQL](/querying/graphql-api).

## Définir des entités

Avant de définir des entités, il est important de prendre du recul et de réfléchir à la manière dont vos données sont structurées et liées. Toutes les requêtes seront effectuées sur le modèle de données défini dans le schéma du subgraph et les entités indexées par le subgraph. Pour cette raison, il est bon de définir le schéma du subgraph d'une manière qui correspond aux besoins de votre dapp. Il peut être utile d'imaginer les entités comme des « objets contenant des données », plutôt que comme des événements ou des fonctions.

Avec The Graph, vous définissez simplement les types d'entités dans `schema.graphql`, et Graph Node générera des champs de niveau supérieur pour interroger des instances uniques et des collections de ce type d'entité. Chaque type qui doit être une entité doit être annoté avec une directive `@entity`. Par défaut, les entités sont mutables, ce qui signifie que les mappages peuvent charger des entités existantes, les modifier et stocker une nouvelle version de cette entité. La mutabilité a un prix, et pour les types d'entités dont on sait qu'elles ne seront jamais modifiées, par exemple parce qu'elles contiennent simplement des données extraites textuellement de la chaîne, il est recommandé de les marquer comme immuables avec `@entity (immuable : vrai)`. Les mappages peuvent apporter des modifications aux entités immuables tant que ces modifications se produisent dans le même bloc dans lequel l'entité a été créée. Les entités immuables sont beaucoup plus rapides à écrire et à interroger et doivent donc être utilisées autant que possible.

### Bon exemple

L'entité `Gravatar` ci-dessous est structurée autour d'un objet Gravatar et constitue un bon exemple de la façon dont une entité pourrait être définie.

```graphql
tapez Gravatar @entity(immuable : true) {
   identifiant : octets !
   propriétaire : octets
   displayName : chaîne
   imageUrl : chaîne
   accepté : booléen
}
```

### Bad Example

Les exemples d'entités `GravatarAccepted` et `GravatarDeclined` ci-dessous sont basés sur des événements. Il n'est pas recommandé de mapper des événements ou des appels de fonction à des entités 1:1.

```graphql
tapez GravatarAccepted @entity {
   identifiant : octets !
   propriétaire : octets
   displayName : chaîne
   imageUrl : chaîne
}

tapez GravatarDeclined @entity {
   identifiant : octets !
   propriétaire : octets
   displayName : chaîne
   imageUrl : chaîne
}
```

### Champs facultatifs et obligatoires

Les champs d'entité peuvent être définis comme obligatoires ou facultatifs. Les champs obligatoires sont indiqués par le `!` dans le schéma. Si un champ obligatoire n'est pas défini dans le mappage, vous recevrez cette erreur lors de l'interrogation du champ :

```
Null value resolved for non-null field 'name'
```

Each entity must have an `id` field, which must be of type `Bytes!` or `String!`. It is generally recommended to use `Bytes!`, unless the `id` contains human-readable text, since entities with `Bytes!` id's will be faster to write and query as those with a `String!` `id`. The `id` field serves as the primary key, and needs to be unique among all entities of the same type. For historical reasons, the type `ID!` is also accepted and is a synonym for `String!`.

For some entity types the `id` is constructed from the id's of two other entities; that is possible using `concat`, e.g., `let id = left.id.concat(right.id)` to form the id from the id's of `left` and `right`. Similarly, to construct an id from the id of an existing entity and a counter `count`, `let id = left.id.concatI32(count)` can be used. The concatenation is guaranteed to produce unique id's as long as the length of `left` is the same for all such entities, for example, because `left.id` is an `Address`.

### Types scalaires intégrés

#### Scalaires pris en charge par GraphQL

Nous prenons en charge les scalaires suivants dans notre API GraphQL :

| Type | Description |
| --- | --- |
| `Octets` | Byte array, represented as a hexadecimal string. Commonly used for Ethereum hashes and addresses. |
| `String` | Scalaire pour les valeurs `chaîne`. Les caractères nuls ne sont pas pris en charge et sont automatiquement supprimés. |
| `Boolean` | Scalar pour `boolean` values. |
| `Int` | La spécification GraphQL définit `Int` pour avoir une taille de 32 octets. |
| `Int8` | An 8-byte signed integer, also known as a 64-bit signed integer, can store values in the range from -9,223,372,036,854,775,808 to 9,223,372,036,854,775,807. Prefer using this to represent `i64` from ethereum. |
| `BigInt` | Grands entiers. Utilisé pour les types `uint32`, `int64`, `uint64`, ..., `uint256` d'Ethereum. Remarque : Tout ce qui se trouve en dessous de `uint32`, tel que `int32`, `uint24` ou `int8`, est représenté par `i32</. `. |
| `BigDecimal` | `BigDecimal` Décimales de haute précision représentées sous la forme d'une mantisse et d'un exposant. La plage des exposants va de −6143 à +6144. Arrondi à 34 chiffres significatifs. |

#### Enums

You can also create enums within a schema. Enums have the following syntax:

```graphql
enum TokenStatus {
  OriginalOwner
  SecondOwner
  ThirdOwner
}
```

Une fois l'énumération définie dans le schéma, vous pouvez utiliser la représentation sous forme de chaîne de la valeur de l'énumération pour définir un champ d'énumération sur une entité. Par exemple, vous pouvez définir `tokenStatus` sur `SecondOwner` en définissant d'abord votre entité, puis en définissant le champ avec `entity.tokenStatus = "SecondOwner"`. L'exemple ci-dessous montre à quoi ressemblerait l'entité Token avec un champ enum :

Plus de détails sur l'écriture d'énumérations peuvent être trouvés dans la [documentation GraphQL](https://graphql.org/learn/schema/).

#### Entity Relationships

Une entité peut avoir une relation avec une ou plusieurs autres entités de votre schéma. Ces relations pourront être parcourues dans vos requêtes. Les relations dans The Graph sont unidirectionnelles. Il est possible de simuler des relations bidirectionnelles en définissant une relation unidirectionnelle à chaque « extrémité » de la relation.

Les relations sont définies sur les entités comme n'importe quel autre champ sauf que le type spécifié est celui d'une autre entité.

#### Relations individuelles

Définissez un type d'entité `Transaction` avec une relation un-à-un facultative avec un type d'entité `TransactionReceipt` :

```graphql
tapez Transaction @entity (immuable : vrai) {
   identifiant : octets !
   transactionReceipt : TransactionReceipt
}

tapez TransactionReceipt @entity(immuable : true) {
   identifiant : octets !
   transaction : transaction
}
```

#### Relations un-à-plusieurs

Définissez un type d'entité `TokenBalance` avec une relation un-à-plusieurs requise avec un type d'entité Token :

```graphql
tapez Token @entity (immuable : true) {
   identifiant : octets !
}

tapez TokenBalance @entity {
   identifiant : octets !
   montant : Int !
   jeton : Jeton !
}
```

#### Reverse Lookups

Des recherches inversées peuvent être définies sur une entité via le champ `@derivedFrom`. Cela crée un champ virtuel sur l'entité qui peut être interrogé mais ne peut pas être défini manuellement via l'API de mappages. Il découle plutôt de la relation définie sur l’autre entité. Pour de telles relations, il est rarement judicieux de stocker les deux côtés de la relation, et les performances d'indexation et de requête seront meilleures lorsqu'un seul côté est stocké et l'autre est dérivé.

Pour les relations un-à-plusieurs, la relation doit toujours être stockée du côté « un » et le côté « plusieurs » doit toujours être dérivé. Stocker la relation de cette façon, plutôt que de stocker un tableau d'entités du côté « plusieurs », entraînera des performances considérablement meilleures pour l'indexation et l'interrogation du sous-graphe. En général, le stockage de tableaux d’entités doit être évité autant que possible.

#### Exemple

Nous pouvons rendre les soldes d'un jeton accessibles à partir du jeton en dérivant un champ `tokenBalances` :

```graphql
tapez Token @entity (immuable : true) {
   identifiant : octets !
   tokenBalances : [TokenBalance !] ! @derivedFrom(champ : "jeton")
}

tapez TokenBalance @entity {
   identifiant : octets !
   montant : Int !
   jeton : Jeton !
}
```

#### Relations plusieurs-à-plusieurs

Pour les relations plusieurs-à-plusieurs, telles que les utilisateurs pouvant appartenir à un nombre quelconque d'organisations, la manière la plus simple, mais généralement pas la plus performante, de modéliser la relation consiste à créer un tableau dans chacune des deux entités impliquées. Si la relation est symétrique, un seul côté de la relation doit être stocké et l’autre côté peut être dérivé.

#### Exemple

Définissez une recherche inversée d'un type d'entité `Utilisateur` vers un type d'entité `Organisation`. Dans l'exemple ci-dessous, cela est réalisé en recherchant l'attribut `membres` à partir de l'entité `Organisation`. Dans les requêtes, le champ `Organisations` sur `Utilisateur` sera résolu en recherchant toutes les entités `Organisation` qui incluent l'ID de l'utilisateur.

```graphql
tapez Organisation @entité {
   identifiant : octets !
   nom : Chaîne !
   membres : [Utilisateur !] !
}

tapez Utilisateur @entity {
   identifiant : octets !
   nom : Chaîne !
   organisations : [Organisation !] ! @derivedFrom(champ : "membres")
}
```

Un moyen plus performant de stocker cette relation consiste à utiliser une table de mappage qui comporte une entrée pour chaque paire `Utilisateur` / `Organisation` avec un schéma tel que

```graphql
tapez Organisation @entité {
   identifiant : octets !
   nom : Chaîne !
   membres : [UserOrganization !] ! @derivedFrom(champ : "organisation")
}

tapez Utilisateur @entity {
   identifiant : octets !
   nom : Chaîne !
   organisations : [UserOrganization !] @derivedFrom(field : "user")
}

tapez UserOrganization @entity {
   identifiant : octets ! # Défini sur `user.id.concat(organization.id)`
   utilisateur : Utilisateur !
   organisation : Organisation !
}
```

Cette approche nécessite que les requêtes descendent vers un niveau supplémentaire pour récupérer, par exemple, les organisations des utilisateurs :

```graphql
interroger les utilisateursAvecOrganisations {
   utilisateurs {
     organisations {
       # ceci est une entité UserOrganization
       organisation {
        name
      }
     }
   }
}
```

Cette manière plus élaborée de stocker des relations plusieurs-à-plusieurs entraînera moins de données stockées pour le subgraph, et donc vers un subgraph qui est souvent considérablement plus rapide à indexer et à interroger.

#### Ajouter des commentaires au schéma

Conformément à la spécification GraphQL, des commentaires peuvent être ajoutés au-dessus des attributs d'entité de schéma à l'aide de guillemets doubles `""`. Ceci est illustré dans l’exemple ci-dessous :

```graphql
tapez MaPremièreEntité @entité {
   "identifiant unique et clé primaire de l'entité"
   identifiant : octets !
   adresse : octets !
}
```

## Définir les champs de recherche en texte intégral

Les requêtes de recherche en texte intégral filtrent et classent les entités en fonction d'une entrée de recherche de texte. Les requêtes en texte intégral sont capables de renvoyer des correspondances pour des mots similaires en traitant le texte de la requête saisi en radicaux avant de les comparer aux données textuelles indexées.

Une définition de requête en texte intégrale inclut le nom de la requête, le dictionnaire de langue utilisé pour traiter les champs de texte, l'algorithme de classement utilisé pour classer les résultats et les champs inclus dans la recherche. Chaque requête en texte intégral peut s'étendre sur plusieurs champs, mais tous les champs inclus doivent provenir d'un seul type d'entité.

Pour ajouter une requête de texte intégral, incluez un type `_Schema_` avec une directive de texte intégral dans le schéma GraphQL.

```graphql
tapez _Schéma_
   @texte intégral(
     nom : "bandSearch"
     langue: fr
     algorithme : classement
     include : [{ entité : "Band", champs : [{ nom : "nom" }, { nom : "description" }, { nom : "bio" }] }]
   )

tapez Bande @entity {
   identifiant : octets !
   nom : Chaîne !
   description : Ficelle !
   bio : chaîne
   portefeuille : Adresse
   étiquettes : [Étiquette !] !
   discographie : [Album!]!
   membres : [Musicien !] !
}
```

L'exemple de champ `bandSearch` peut être utilisé dans les requêtes pour filtrer les entités `Band` en fonction des documents texte dans `nom`, `description</0. > et <code>bio`. Accédez à [API GraphQL - Requêtes](/querying/graphql-api#queries) pour une description de l'API de recherche en texte intégral et d'autres exemples d'utilisation.

```graphql
requête {
   bandSearch(texte : "breaks & électro & detroit") {
     identifiant
     nom
     description
     portefeuille
   }
}
```

> **[Gestion des fonctionnalités](#experimental-features) :** À partir de `specVersion` `0.0.4` et au-delà, `fullTextSearch` doit être déclaré sous la section `fonctionnalités` dans le manifeste du subgraph.

### Languages supported

Choosing a different language will have a definitive, though sometimes subtle, effect on the fulltext search API. Fields covered by a fulltext query field are examined in the context of the chosen language, so the lexemes produced by analysis and search queries vary from language to language. For example: when using the supported Turkish dictionary "token" is stemmed to "toke" while, of course, the English dictionary will stem it to "token".

Dictionnaires de langues pris en charge :

| Code   | Dictionnaire |
| ------ | ------------ |
| simple | Général      |
| da     | Danois       |
| nl     | Dutch        |
| en     | Anglais      |
| fi     | Finlandais   |
| fr     | Français     |
| de     | Allemand     |
| hu     | Hongrois     |
| it     | Italien      |
| no     | Norvégien    |
| pt     | Portugais    |
| ro     | Roumain      |
| ru     | Russe        |
| es     | Espagnol     |
| sv     | Suédois      |
| tr     | Turc         |

### Algorithmes de classement

Algorithmes de classement:

| Algorithm | Description |
| --- | --- |
| rang | Utilisez la qualité de correspondance (0-1) de la requête en texte intégral pour trier les résultats. |
| proximitéRang | Similaire au classement mais inclut également la proximité des matchs. |

## Écriture de mappages

Les mappages prennent les données d'une source particulière et les transforment en entités définies dans votre schéma. Les mappages sont écrits dans un sous-ensemble de [TypeScript](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes.html) appelé [AssemblyScript](https : //github.com/AssemblyScript/assemblyscript/wiki) qui peut être compilé en WASM ([WebAssembly](https://webassembly.org/)). AssemblyScript est plus strict que TypeScript normal, mais fournit une syntaxe familière.

Pour chaque gestionnaire d'événements défini dans `subgraph.yaml` sous `mapping.eventHandlers`, créez une fonction exportée du même nom. Chaque gestionnaire doit accepter un seul paramètre appelé `event` avec un type correspondant au nom de l'événement qui est géré.

Dans le subgraph d'exemple, `src/mapping.ts` contient des gestionnaires pour les événements `NewGravatar` et `UpdatedGravatar` :

```javascript
import { NewGravatar, UpdatedGravatar } from '../generated/Gravity/Gravity'
import { Gravatar } from '../generated/schema'

export function handleNewGravatar(event: NewGravatar): void {
  let gravatar = new Gravatar(event.params.id)
  gravatar.owner = event.params.owner
  gravatar.displayName = event.params.displayName
  gravatar.imageUrl = event.params.imageUrl
  gravatar.save()
}

export function handleUpdatedGravatar(event: UpdatedGravatar): void {
  let id = event.params.id
  let gravatar = Gravatar.load(id)
  if (gravatar == null) {
    gravatar = new Gravatar(id)
  }
  gravatar.owner = event.params.owner
  gravatar.displayName = event.params.displayName
  gravatar.imageUrl = event.params.imageUrl
  gravatar.save()
}
```

Le premier gestionnaire prend un événement `NewGravatar` et crée une nouvelle entité `Gravatar` avec `new Gravatar(event.params.id.toHex())`, remplissant les champs d'entité en utilisant les paramètres d'événement correspondants. Cette instance d'entité est représentée par la variable `gravatar`, avec une valeur d'identifiant de `event.params.id.toHex()`.

Le deuxième gestionnaire essaie de charger le `Gravatar` existant à partir du magasin Graph Node. S'il n'existe pas encore, il est créé à la demande. L'entité est ensuite mise à jour pour correspondre aux nouveaux paramètres d'événement avant d'être réenregistrée dans le magasin à l'aide de `gravatar.save()`.

### ID recommandés pour la création de nouvelles entités

Every entity has to have an `id` that is unique among all entities of the same type. An entity's `id` value is set when the entity is created. Below are some recommended `id` values to consider when creating new entities. NOTE: The value of `id` must be a `string`.

- `event.params.id.toHex()`
- `event.transaction.from.toHex()`
- `event.transaction.hash.toHex() + "-" + event.logIndex.toString()`

We provide the [Graph Typescript Library](https://github.com/graphprotocol/graph-ts) which contains utilies for interacting with the Graph Node store and conveniences for handling smart contract data and entities. You can use this library in your mappings by importing `@graphprotocol/graph-ts` in `mapping.ts`.

## Code Generation

In order to make it easy and type-safe to work with smart contracts, events and entities, the Graph CLI can generate AssemblyScript types from the subgraph's GraphQL schema and the contract ABIs included in the data sources.

This is done with

```sh
graph codegen [--output-dir <OUTPUT_DIR>] [<MANIFEST>]
```

but in most cases, subgraphs are already preconfigured via `package.json` to allow you to simply run one of the following to achieve the same:

```sh
# Yarn
yarn codegen

# NPM
npm run codegen
```

This will generate an AssemblyScript class for every smart contract in the ABI files mentioned in `subgraph.yaml`, allowing you to bind these contracts to specific addresses in the mappings and call read-only contract methods against the block being processed. It will also generate a class for every contract event to provide easy access to event parameters, as well as the block and transaction the event originated from. All of these types are written to `<OUTPUT_DIR>/<DATA_SOURCE_NAME>/<ABI_NAME>.ts`. In the example subgraph, this would be `generated/Gravity/Gravity.ts`, allowing mappings to import these types with.

```javascript
import {
  // The contract class:
  Gravity,
  // The events classes:
  NewGravatar,
  UpdatedGravatar,
} from '../generated/Gravity/Gravity'
```

De plus, une classe est générée pour chaque type d'entité dans le schéma GraphQL du subgraph. Ces classes fournissent un chargement d'entités de type sécurisé, un accès en lecture et en écriture aux champs d'entité ainsi qu'une méthode `save()` pour écrire les entités à stocker. Toutes les classes d'entités sont écrites dans `<OUTPUT_DIR>/schema.ts`, permettant aux mappages de les importer avec

```javascript
importer { Gravatar } du '../generated/schema'
```

> **Remarque :** La génération de code doit être effectuée à nouveau après chaque modification du schéma GraphQL ou des ABI inclus dans le manifeste. Elle doit également être effectuée au moins une fois avant de construire ou de déployer le subgraph.

Code generation does not check your mapping code in `src/mapping.ts`. If you want to check that before trying to deploy your subgraph to the Graph Explorer, you can run `yarn build` and fix any syntax errors that the TypeScript compiler might find.

## Modèles de sources de données

Un modèle courant dans les contrats intelligents compatibles EVM est l'utilisation de contrats de registre ou d'usine, dans lesquels un contrat crée, gère ou référence un nombre arbitraire d'autres contrats qui ont chacun leur propre état et leurs propres événements.

Les adresses de ces sous-traitants peuvent ou non être connues à l'avance et bon nombre de ces contrats peuvent être créés et/ou ajoutés au fil du temps. C'est pourquoi, dans de tels cas, définir une seule source de données ou un nombre fixe de sources de données est impossible et une approche plus dynamique est nécessaire : des _modèles de sources de données_.

### Source de données pour le contrat principal

Tout d’abord, vous définissez une source de données régulière pour le contrat principal. L'extrait ci-dessous montre un exemple simplifié de source de données pour le contrat d'usine d'échange [Uniswap](https://uniswap.org). Notez le gestionnaire d'événements `NewExchange(address,address)`. Ceci est émis lorsqu'un nouveau contrat d'échange est créé en chaîne par le contrat d'usine.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Factory
    network: mainnet
    source:
      address: '0xc0a47dFe034B400B47bDaD5FecDa2621de6c4d95'
      abi: Factory
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/factory.ts
      entities:
        - Directory
      abis:
        - name: Factory
          file: ./abis/factory.json
      eventHandlers:
        - event: NewExchange(address,address)
          handler: handleNewExchange
```

### Data Source Templates for Dynamically Created Contracts

Then, you add _data source templates_ to the manifest. These are identical to regular data sources, except that they lack a pre-defined contract address under `source`. Typically, you would define one template for each type of sub-contract managed or referenced by the parent contract.

```yaml
les sources de données:
  - genre: ethereum/contrat
    nom: Usine
    # ... autres champs sources du contrat principal ...
modèles:
  - nom: Bourse
    genre: ethereum/contrat
    réseau: réseau principal
    source:
      abi: Échange
    cartographie:
      genre: ethereum/événements
      Version api: 0.0.6
      langage: wasm/assemblyscript
      fichier: ./src/mappings/exchange.ts
      entités:
        - Échange
      abis:
        - nom: Bourse
          fichier: ./abis/exchange.json
      Gestionnaires d'événements:
        - événement: TokenPurchase (adresse, uint256, uint256)
          gestionnaire: handleTokenPurchase
        - événement: EthPurchase (adresse, uint256, uint256)
          gestionnaire: handleEthPurchase
        - événement: AddLiquidity (adresse, uint256, uint256)
          gestionnaire: handleAddLiquidity
        - événement: RemoveLiquidity (adresse, uint256, uint256)
          gestionnaire: handleRemoveLiquidity
```

### Instanciation d'un modèle de source de données

Dans la dernière étape, vous mettez à jour votre mappage de contrat principal pour créer une instance de source de données dynamique à partir de l'un des modèles. Dans cet exemple, vous modifieriez le mappage de contrat principal pour importer le modèle `Exchange` et appeleriez la méthode `Exchange.create(address)` dessus pour commencer à indexer le nouveau contrat d'échange.

```typescript
importer { Exchange } depuis '../generated/templates'

fonction d'exportation handleNewExchange (événement : NewExchange) : void {
   // Commence à indexer l'échange ; `event.params.exchange` est le
   // adresse du nouveau contrat d'échange
   Exchange.create(event.params.exchange)
}
```

> **Remarque :** Une nouvelle source de données traitera uniquement les appels et les événements du bloc dans lequel elle a été créée et de tous les blocs suivants, mais ne traitera pas les données historiques, c'est-à-dire les données. qui est contenu dans les blocs précédents.
>
> Si les blocs précédents contiennent des données pertinentes pour la nouvelle source de données, il est préférable d'indexer ces données en lisant l'état actuel du contrat et en créant des entités représentant cet état au moment de la création de la nouvelle source de données.

### Data Source Context

Les contextes de source de données permettent de transmettre une configuration supplémentaire lors de l'instanciation d'un modèle. Dans notre exemple, disons que les échanges sont associés à une paire de transactions particulière, qui est incluse dans l'événement `NewExchange`. Ces informations peuvent être transmises à la source de données instanciée, comme suit :

```typescript
import { Exchange } from '../generated/templates'

export function handleNewExchange(event: NewExchange): void {
  let context = new DataSourceContext()
  context.setString('tradingPair', event.params.tradingPair)
  Exchange.createWithContext(event.params.exchange, context)
}
```

Inside a mapping of the `Exchange` template, the context can then be accessed:

```typescript
importer { dataSource } depuis '@graphprotocol/graph-ts'

laissez contexte = dataSource.context()
laissez tradingPair = context.getString('tradingPair')
```

Il existe des setters et des getters comme `setString` et `getString` pour tous les types de valeur.

## Blocs de démarrage

Le `startBlock` est un paramètre facultatif qui vous permet de définir à partir de quel bloc de la chaîne la source de données commencera l'indexation. La définition du bloc de départ permet à la source de données d'ignorer potentiellement des millions de blocs non pertinents. En règle générale, un développeur de subgraphs définira `startBlock` sur le bloc dans lequel le contrat intelligent de la source de données a été créé.

```yaml
les sources de données:
   - genre : ethereum/contrat
     nom : ExempleSource
     réseau : réseau principal
     source:
       adresse : '0xc0a47dFe034B400B47bDaD5FecDa2621de6c4d95'
       abi : Exemple de contrat
       bloc de démarrage : 6627917
     cartographie :
       genre : ethereum/événements
       Version api : 0.0.6
       langage : wasm/assemblyscript
       fichier : ./src/mappings/factory.ts
       entités :
         - Utilisateur
       abis :
         - nom : ExempleContrat
           fichier : ./abis/ExampleContract.json
       Gestionnaires d'événements :
         - événement : NewEvent(adresse,adresse)
           gestionnaire : handleNewEvent
```

> **Remarque :** Le bloc de création de contrat peut être rapidement consulté sur Etherscan :
>
> 1. Recherchez le contrat en saisissant son adresse dans la barre de recherche.
> 2. Cliquez sur le hachage de la transaction de création dans la section `Contract Creator`.
> 3. Load the transaction details page where you'll find the start block for that contract.

## Call Handlers

While events provide an effective way to collect relevant changes to the state of a contract, many contracts avoid generating logs to optimize gas costs. In these cases, a subgraph can subscribe to calls made to the data source contract. This is achieved by defining call handlers referencing the function signature and the mapping handler that will process calls to this function. To process these calls, the mapping handler will receive an `ethereum.Call` as an argument with the typed inputs to and outputs from the call. Calls made at any depth in a transaction's call chain will trigger the mapping, allowing activity with the data source contract through proxy contracts to be captured.

Les gestionnaires d'appels ne se déclencheront que dans l'un des deux cas suivants : lorsque la fonction spécifiée est appelée par un compte autre que le contrat lui-même ou lorsqu'elle est marquée comme externe dans Solidity et appelée dans le cadre d'une autre fonction du même contrat.

> **Remarque :** Les gestionnaires d'appels dépendent actuellement de l'API de suivi de parité. Certains réseaux, tels que la chaîne BNB et Arbitrum, ne prennent pas en charge cette API. Si un subgraph indexant l’un de ces réseaux contient un ou plusieurs gestionnaires d’appels, il ne démarrera pas la synchronisation. Les développeurs de subgraphs devraient plutôt utiliser des gestionnaires d'événements. Ceux-ci sont bien plus performants que les gestionnaires d'appels et sont pris en charge sur tous les réseaux evm.

### Définir un gestionnaire d'appels

Pour définir un gestionnaire d'appels dans votre manifeste, ajoutez simplement un tableau `callHandlers` sous la source de données à laquelle vous souhaitez vous abonner.

```yaml
les sources de données:
  - genre: ethereum/contrat
    nom: Gravité
    réseau: réseau principal
    source:
      adresse: '0x731a10897d267e19b34503ad902d0a29173ba4b1'
      abi: Gravité
    cartographie:
      genre: ethereum/événements
      Version api: 0.0.6
      langage: wasm/assemblyscript
      entités: -Gravatar - Transaction
      abis:
        - nom: Gravité
          fichier: ./abis/Gravity.json
      Gestionnaires d'appels:
        - fonction: createGravatar(string,string)
          gestionnaire: handleCreateGravatar
```

La `fonction` est la signature de fonction normalisée permettant de filtrer les appels. La propriété `handler` est le nom de la fonction de votre mappage que vous souhaitez exécuter lorsque la fonction cible est appelée dans le contrat de source de données.

### Fonction de cartographie

Chaque gestionnaire d'appel prend un seul paramètre dont le type correspond au nom de la fonction appelée. Dans l'exemple de subgraph ci-dessus, le mappage contient un gestionnaire lorsque la fonction `createGravatar` est appelée et reçoit un paramètre `CreateGravatarCall` comme argument :

```typescript
importer { CreateGravatarCall } depuis '../generated/Gravity/Gravity'
importer { Transaction } depuis '../generated/schema'

fonction d'exportation handleCreateGravatar (appel : CreateGravatarCall) : void {
   laissez id = call.transaction.hash
   let transaction = nouvelle transaction (id)
   transaction.displayName = call.inputs._displayName
   transaction.imageUrl = call.inputs._imageUrl
   transaction.save()
}
```

La fonction `handleCreateGravatar` prend un nouveau `CreateGravatarCall` qui est une sous-classe de `ethereum. Call`, fournie par `@graphprotocol/graph-ts`, qui inclut les entrées et sorties saisies de l’appel. Le type `CreateGravatarCall` est généré pour vous lorsque vous exécutez `graph codegen`.

## Block Handlers

En plus de s'abonner à des événements de contrat ou à des appels de fonction, un subgraph peut souhaiter mettre à jour ses données à mesure que de nouveaux blocs sont ajoutés à la chaîne. Pour y parvenir, un subgraph peut exécuter une fonction après chaque bloc ou après des blocs correspondant à un filtre prédéfini.

### Supported Filters

#### Call Filter

```yaml
filtre:
  genre: appeler
```

_Le gestionnaire défini sera appelé une fois pour chaque bloc contenant un appel au contrat (source de données) sous lequel le gestionnaire est défini._

> **Remarque :** Le filtre `call` dépend actuellement de l'API de traçage de parité. Certains réseaux, tels que la chaîne BNB et Arbitrum, ne prennent pas en charge cette API. Si un subgraph indexant l'un de ces réseaux contient un ou plusieurs gestionnaires de blocs avec un filtre `call`, il ne démarrera pas la synchronisation.

L'absence de filtre pour un gestionnaire de bloc garantira que le gestionnaire est appelé à chaque bloc. Une source de données ne peut contenir qu'un seul gestionnaire de bloc pour chaque type de filtre.

```yaml
les sources de données:
   - genre : ethereum/contrat
     nom: Gravité
     réseau : développeur
     source:
       adresse : '0x731a10897d267e19b34503ad902d0a29173ba4b1'
       abi : Gravité
     cartographie :
       genre : ethereum/événements
       Version api : 0.0.6
       langage : wasm/assemblyscript
       entités :
         -Gravatar
         - Transaction
       abis :
         - nom : Gravité
           fichier : ./abis/Gravity.json
       gestionnaires de blocs :
         - gestionnaire : handleBlock
         - gestionnaire : handleBlockWithCallToContract
           filtre:
             genre : appele
```

#### Filtre d'interrogation

> **Nécessite `specVersion` >= 0.0.8**

> **Remarque :** Les filtres d'interrogation ne sont disponibles que sur les sources de données de `genre : ethereum`.

```yaml
blockHandlers:
  - handler: handleBlock
    filter:
      kind: polling
      every: 10
```

Le gestionnaire défini sera appelé une fois pour tous les blocs `n`, où `n` est la valeur fournie dans le champ `every`. Cette configuration permet au sugraph d'effectuer des opérations spécifiques à intervalles réguliers.

#### Once Filter

> **Nécessite `specVersion` >= 0.0.8**

> **Remarque :** Les filtres Once ne sont disponibles que sur les sources de données de `genre : Ethereum`.

```yaml
blockHandlers:
  - handler: handleOnce
    filter:
      kind: once
```

The defined handler with the once filter will be called only once before all other handlers run. This configuration allows the subgraph to use the handler as an initialization handler, performing specific tasks at the start of indexing.

```ts
fonction d'exportation handleOnce (bloc : ethereum.Block) : void {
   laissez data = new InitialData(Bytes.fromUTF8('initial'))
   data.data = 'Configurer les données ici'
   data.save()
}
```

### Fonction de cartographie

La fonction de mappage recevra un `ethereum.Block` comme seul argument. Comme les fonctions de mappage pour les événements, cette fonction peut accéder aux entités de subgraphs existantes dans le magasin, appeler des contrats intelligents et créer ou mettre à jour des entités.

```typescript
importer { ethereum } depuis '@graphprotocol/graph-ts'

fonction d'exportation handleBlock (bloc : ethereum.Block) : void {
   laissez l'identifiant = block.hash
   laisser l'entité = nouveau bloc (id)
   entité.save()
}
```

## Événements anonymes

Si vous devez traiter des événements anonymes dans Solidity, cela peut être réalisé en fournissant le sujet 0 de l'événement, comme dans l'exemple :

```yaml
eventHandlers:
  - event: LogNote(bytes4,address,bytes32,bytes32,uint256,bytes)
    topic0: '0x644843f351d3fba4abcd60109eaff9f54bac8fb8ccf0bab941009c21df21cf31'
    handler: handleGive
```

Un événement ne sera déclenché que lorsque la signature et le sujet 0 correspondent. Par défaut, `topic0` est égal au hachage de la signature de l'événement.

## Reçus de transaction dans les gestionnaires d'événements

À partir de `specVersion` `0.0.5` et `apiVersion` `0.0.7`, les gestionnaires d'événements peuvent avoir accès au reçu du transaction qui les a émis.

Pour ce faire, les gestionnaires d'événements doivent être déclarés dans le manifeste du subgraph avec la nouvelle clé `receipt: true`, qui est facultative et vaut par défaut false.

```yaml
gestionnaires d'événements:
  - événement: NewGravatar(uint256,adresse,chaîne,chaîne)
    gestionnaire: handleNewGravatar
    reçu: vrai
```

Dans la fonction de gestionnaire, le reçu est accessible dans le champ `Event.receipt`. Lorsque la clé `receipt` est définie sur `false` ou omise dans le manifeste, une valeur `null` sera renvoyée à la place.

## Fonctionnalités expérimentales

À partir de `specVersion` `0.0.4`, les fonctionnalités de subgraph doivent être explicitement déclarées dans la section `features` au niveau supérieur du fichier manifeste, en utilisant leur `camelCase`, comme indiqué dans le tableau ci-dessous :

| Fonctionnalité | Name |
| --- | --- |
| [Erreurs non fatales](#non-fatal-errors) | `erreursnonfatales` |
| [Recherche en texte intégral](#defining-fulltext-search-fields) | `recherche en texte intégral` |
| [La greffe](#grafting-onto-existing-subgraphs) | `greffage` |
| [IPFS sur les contrats Ethereum](#ipfs-on-ethereum-contracts) | `ipfsOnEthereumContracts` or `nonDeterministicIpfs` |

Par exemple, si un subgraph utilise les fonctionnalités **Recherche en texte intégral** et **Erreurs non fatales** features, le `features` dans le manifeste doit être :

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
features:
  - fullTextSearch
  - nonFatalErrors
dataSources: ...
```

Notez que l'utilisation d'une fonctionnalité sans la déclarer entraînera une **erreur de validation** lors du déploiement du sous-graphe, mais aucune erreur ne se produira si une fonctionnalité est déclarée mais n'est pas utilisée.

### IPFS sur les contrats Ethereum

Un cas d'utilisation courant pour combiner IPFS avec Ethereum est de stocker des données sur IPFS qui seraient trop coûteuses à maintenir en chaîne et de référencer le hachage IPFS dans les contrats Ethereum.

Compte tenu de ces hachages IPFS, les subgraphs peuvent lire les fichiers correspondants depuis IPFS en utilisant `ipfs.cat` et `ipfs.map`. Pour ce faire de manière fiable, il est nécessaire que ces fichiers soient épinglés sur un nœud IPFS à haute disponibilité, afin que le [service hébergé](https://thegraph.com/hosted-service) nœud IPFS peut les retrouver lors de l'indexation.

> **Remarque :** Le réseau Graph ne prend pas encore en charge `ipfs.cat` et `ipfs.map`, et les développeurs ne doivent pas déployer subgraphs utilisant cette fonctionnalité au réseau via le Studio.

> **[Gestion des fonctionnalités](#experimental-features) :** `ipfsOnEthereumContracts` doit être déclaré sous `features</ ` dans le manifeste du subgraph. Pour les chaînes non EVM, l'alias `nonDeterministicIpfs` peut également être utilisé pour le même.

When running a local Graph Node, the `GRAPH_ALLOW_NON_DETERMINISTIC_IPFS` environment variable must be set in order to index subgraphs using this experimental functionality.

### Erreurs non fatales

Les erreurs d'indexation sur les subgraphs déjà synchronisés entraîneront, par défaut, l'échec du subgraph et l'arrêt de la synchronisation. Les subgraphs peuvent également être configurés pour continuer la synchronisation en présence d'erreurs, en ignorant les modifications apportées par le gestionnaire qui a provoqué l'erreur. Cela donne aux auteurs de subgraphs le temps de corriger leurs subgraphs pendant que les requêtes continuent d'être traitées sur le dernier bloc, bien que les résultats puissent être incohérents en raison du bogue à l'origine de l'erreur. Notez que certaines erreurs sont toujours fatales. Pour être non fatale, l'erreur doit être connue pour être déterministe.

> **Note:** The Graph Network does not yet support non-fatal errors, and developers should not deploy subgraphs using that functionality to the network via the Studio.

L'activation des erreurs non fatales nécessite la définition de l'indicateur de fonctionnalité suivant sur le manifeste du subgraph :

```yaml
l'activation des erreurs non fatales nécessite la définition de l'indicateur de fonctionnalité suivant sur le manifeste du subgraph ...
```

La requête doit également choisir d'interroger les données présentant des incohérences potentielles via l'argument `subgraphError`. Il est également recommandé d'interroger `_meta` pour vérifier si le subgraph a ignoré des erreurs, comme dans l'exemple :

```graphql
foos(first: 100, subgraphError: allow) {
  id
}

_meta {
  hasIndexingErrors
}
```

Si le subgraph rencontre une erreur, cette requête renverra à la fois les données et une erreur graphql avec le message `"indexing_error"`, comme dans cet exemple de réponse :

```graphql
"données": {
     "foos": [
         {
           "identifiant": "0xdead"
         }
     ],
     "_meta": {
         "hasIndexingErrors": vrai
     }
},
"les erreurs": [
     {
         "message": "erreur_indexation"
     }
]
```

### Greffe sur des subgraphs existants

> **Remarque :** il n'est pas recommandé d'utiliser le greffage lors de la mise à niveau initiale vers The Graph Network. Apprenez-en plus [ici](/cookbook/grafting/#important-note-on-grafting-when-upgrading-to-the-network).

Lorsqu'un subgraph est déployé pour la première fois, il commence à indexer les événements au niveau du bloc Genesis de la chaîne correspondante (ou au `startBlock` défini avec chaque source de données). Dans certaines circonstances ; il est avantageux de réutiliser les données d'un subgraph existant et de commencer l'indexation à un bloc beaucoup plus tard. Ce mode d'indexation est appelé _Grafting_. Le greffage est, par exemple, utile pendant le développement pour surmonter rapidement de simples erreurs dans les mappages ou pour faire fonctionner à nouveau temporairement un subgraph existant après son échec.

Un subgraph est greffé sur un subgraph de base lorsque le manifeste du soubgraph dans `subgraph.yaml` contient un bloc `graft` au niveau supérieur :

```yaml
description: ...
greffer:
  base: Qm... # ID de subgraph du subgraph de base
  bloc: 7345624 # Numéro de bloc
```

Lorsqu'un subgraph dont le manifeste contient un bloc `graft` est déployé, Graph Node copiera les données du subgraph `base` jusqu'au `bloc` donné inclus. puis continuez à indexer le nouveau subgraph à partir de ce bloc. Le subgraph de base doit exister sur l'instance Graph Node cible et doit avoir été indexé jusqu'au moins au bloc donné. En raison de cette restriction, le greffage ne doit être utilisé que pendant le développement ou en cas d'urgence pour accélérer la production d'un subgraph équivalent non greffé.

Étant donné que le greffage copie plutôt que l'indexation des données de base, il est beaucoup plus rapide d'amener le susgraph dans le bloc souhaité que l'indexation à partir de zéro, bien que la copie initiale des données puisse encore prendre plusieurs heures pour de très gros subgraphs. Pendant l'initialisation du subgraph greffé, le nœud graphique enregistrera des informations sur les types d'entités qui ont déjà été copiés.

Le subgraph greffé peut utiliser un schéma GraphQL qui n'est pas identique à celui du subgraph de base, mais simplement compatible avec celui-ci. Il doit s'agir d'un schéma de subgraph valide à part entière, mais il peut s'écarter du schéma du subgraph de base des manières suivantes :

- Il ajoute ou supprime des types d'entités
- It removes attributes from entity types
- Il ajoute des attributs nullables aux types d'entités
- Il transforme les attributs non nullables en attributs nullables
- Il ajoute des valeurs aux énumérations
- It adds or removes interfaces
- Cela change pour quels types d'entités une interface est implémentée

> **[Gestion des fonctionnalités](#experimental-features) :** le `greffage` doit être déclaré sous `features`dans le manifeste du subgraph.

## Sources de données de fichiers

File data sources are a new subgraph functionality for accessing off-chain data during indexing in a robust, extendable way. File data sources support fetching files from IPFS and from Arweave.

> This also lays the groundwork for deterministic indexing of off-chain data, as well as the potential introduction of arbitrary HTTP-sourced data.

### Aperçu

Plutôt que de récupérer les fichiers "en ligne" pendant l'exécution du gestionnaire, cela introduit des modèles qui peuvent être générés en tant que nouvelles sources de données pour un identifiant de fichier donné. Ces nouvelles sources de données récupèrent les fichiers, réessayent en cas d'échec et exécutent un gestionnaire dédié lorsque le fichier est trouvé.

This is similar to the [existing data source templates](https://thegraph.com/docs/en/developing/creating-a-subgraph/#data-source-templates), which are used to dynamically create new chain-based data sources.

> Cela remplace l'API `ipfs.cat` existante

### Guide de mise à niveau

#### Mettre à jour `graph-ts` et `graph-cli`

Les sources de données de fichiers nécessitent graph-ts >=0.29.0 et graph-cli >=0.33.1

#### Ajouter un nouveau type d'entité qui sera mis à jour lorsque des fichiers seront trouvés

File data sources cannot access or update chain-based entities, but must update file specific entities.

Cela peut impliquer de diviser les champs des entités existantes en entités distinctes, liées entre elles.

Entité combinée d'origine :

```graphql
tapez Jeton @entité {
   je l'ai fait!
   ID de jeton : BigInt !
   tokenURI : chaîne !
   externalURL : chaîne !
   ipfsURI : chaîne !
   image : Ficelle !
   nom : Chaîne !
   description : Ficelle !
   tapez : chaîne !
   updateAtTimestamp : BigInt
   propriétaire : Utilisateur !
}
```

Nouvelle entité scindée :

```graphql
tapez Jeton @entité {
   je l'ai fait!
   ID de jeton : BigInt !
   tokenURI : chaîne !
   ipfsURI : TokenMetadata
   updateAtTimestamp : BigInt
   propriétaire : Chaîne !
}

tapez TokenMetadata @entity {
   je l'ai fait!
   image : Ficelle !
   externalURL : chaîne !
   nom : Chaîne !
   description : Ficelle !
}
```

Si la relation est 1:1 entre l'entité parent et l'entité de source de données de fichier résultante, le modèle le plus simple consiste à lier l'entité parent à une entité de fichier résultante en utilisant le CID IPFS comme recherche. Contactez Discord si vous rencontrez des difficultés pour modéliser vos nouvelles entités basées sur des fichiers !

> Vous pouvez utiliser des [filtres imbriqués](https://thegraph.com/docs/en/querying/graphql-api/#example-for-nested-entity-filtering) pour filtrer les entités parent sur le base de ces entités imbriquées.

#### Ajoutez une nouvelle source de données modélisée avec `kind: file/ipfs` ou `kind: file/arweave`

Il s'agit de la source de données qui sera générée lorsqu'un fichier d'intérêt est identifié.

```yaml
modèles:
  - nom: TokenMetadata
    genre: fichier/ipfs
    cartographie:
      Version api: 0.0.7
      langage: wasm/assemblyscript
      fichier: ./src/mapping.ts
      gestionnaire: handleMetadata
      entités:
        - TokenMétadonnées
      abis:
        - nom: Jeton
          fichier: ./abis/Token.json
```

> Actuellement, les `abis` sont requis, bien qu'il ne soit pas possible d'appeler des contrats à partir de sources de données de fichiers

The file data source must specifically mention all the entity types which it will interact with under `entities`. See [limitations](#Limitations) for more details.

#### Créer un nouveau gestionnaire pour traiter les fichiers

Ce gestionnaire doit accepter un paramètre `Bytes`, qui sera le contenu du fichier, lorsqu'il sera trouvé, qui pourra ensuite être traité. Il s'agira souvent d'un fichier JSON, qui peut être traité avec les assistants `graph-ts` ([documentation](https://thegraph.com/docs/en/developing/assemblyscript-api/#json -api)).

The CID of the file as a readable string can be accessed via the `dataSource` as follows:

```typescript
const cid = dataSource.stringParam()
```

Example handler:

```typescript
import { json, Bytes, dataSource } from '@graphprotocol/graph-ts'
import { TokenMetadata } from '../generated/schema'

export function handleMetadata(content: Bytes): void {
  let tokenMetadata = new TokenMetadata(dataSource.stringParam())
  const value = json.fromBytes(content).toObject()
  if (value) {
    const image = value.get('image')
    const name = value.get('name')
    const description = value.get('description')
    const externalURL = value.get('external_url')

    if (name && image && description && externalURL) {
      tokenMetadata.name = name.toString()
      tokenMetadata.image = image.toString()
      tokenMetadata.externalURL = externalURL.toString()
      tokenMetadata.description = description.toString()
    }

    tokenMetadata.save()
  }
}
```

#### Générer des sources de données de fichiers si nécessaire

Vous pouvez désormais créer des sources de données de fichiers lors de l'exécution de gestionnaires basés sur une chaîne :

- Importez le modèle à partir des `modèles` générés automatiquement
- appeler `TemplateName.create(cid : string)` à partir d'un mappage, où le cid est un identifiant de contenu valide pour IPFS ou Arweave

For IPFS, Graph Node supports [v0 and v1 content identifiers](https://docs.ipfs.tech/concepts/content-addressing/), and content identifers with directories (e.g. `bafyreighykzv2we26wfrbzkcdw37sbrby4upq7ae3aqobbq7i4er3tnxci/metadata.json`).

Pour Arweave, à partir de la version 0.33.0, Graph Node peut récupérer des fichiers stockés sur Arweave en fonction de leur [transaction ID](https://docs.arweave.org/developers/server/http-api#transactions) à partir d'une passerelle Arweave ([fichier exemple](https://bdxujjl5ev5eerd5ouhhs6o4kjrs4g6hqstzlci5pf6vhxezkgaa.arweave.net/CO9EpX0lekJEfXUOeXncUmMuG8eEp5WJHXl9U9yZUYA)). Arweave prend en charge les transactions téléchargées via Bundlr, et Graph Node peut également récupérer des fichiers sur la base des [manifestes Bundlr](https://docs.bundlr.network/learn/gateways#indexing).

Exemple:

```typescript
import { TokenMetadata as TokenMetadataTemplate } from '../generated/templates'

const ipfshash = 'QmaXzZhcYnsisuue5WRdQDH6FDvqkLQX1NckLqBYeYYEfm'
//Cet exemple de code concerne un sous-graphe de Crypto coven. Le hachage ipfs ci-dessus est un répertoire contenant les métadonnées des jetons pour toutes les NFT de l'alliance cryptographique.

export function handleTransfer(event: TransferEvent): void {
  let token = Token.load(event.params.tokenId.toString())
  if (!token) {
    token = new Token(event.params.tokenId.toString())
    token.tokenID = event.params.tokenId

    token.tokenURI = '/' + event.params.tokenId.toString() + '.json'
    const tokenIpfsHash = ipfshash + token.tokenURI
    //Ceci crée un chemin vers les métadonnées pour un seul Crypto coven NFT. Il concatène le répertoire avec "/" + nom de fichier + ".json"

    token.ipfsURI = tokenIpfsHash

    TokenMetadataTemplate.create(tokenIpfsHash)
  }

  token.updatedAtTimestamp = event.block.timestamp
  token.owner = event.params.to.toHexString()
  token.save()
}
```

Cela créera une nouvelle source de données de fichier, qui interrogera le point d'extrémité IPFS ou Arweave configuré du nœud de graphique, en réessayant si elle n'est pas trouvée. Lorsque le fichier est trouvé, le gestionnaire de la source de données de fichier est exécuté.

Cet exemple utilise le CID comme recherche entre l'entité `Token` parent et l'entité `TokenMetadata` résultante.

> Auparavant, c'est à ce stade qu'un développeur de subgraphs aurait appelé `ipfs.cat(CID)` pour récupérer le fichier

Félicitations, vous utilisez des sources de données de fichiers !

#### Deploying your subgraphs

Vous pouvez maintenant `construire` et `déployer` votre subgraph sur n'importe quel nœud de graph >=v0.30.0-rc.0.

#### Limitations

Les entités et les gestionnaires de sources de données de fichiers sont isolés des autres entités du subgraph, ce qui garantit que leur exécution est déterministe et qu'il n'y a pas de contamination des sources de données basées sur des chaînes. Pour être plus précis :

- Les entités créées par les sources de données de fichiers sont immuables et ne peuvent pas être mises à jour
- Les gestionnaires de sources de données de fichiers ne peuvent pas accéder à des entités provenant d'autres sources de données de fichiers
- Les entités associées aux sources de données de fichiers ne sont pas accessibles aux gestionnaires basés sur des chaînes

> Cette contrainte ne devrait pas poser de problème pour la plupart des cas d'utilisation, mais elle peut en compliquer certains. N'hésitez pas à nous contacter via Discord si vous rencontrez des problèmes pour modéliser vos données basées sur des fichiers dans un subgraph !

En outre, il n'est pas possible de créer des sources de données à partir d'une source de données de fichier, qu'il s'agisse d'une source de données onchain ou d'une autre source de données de fichier. Cette restriction pourrait être levée à l'avenir.

#### Best practices

Si vous liez des métadonnées NFT aux jetons correspondants, utilisez le hachage IPFS des métadonnées pour référencer une entité Metadata à partir de l'entité Token. Enregistrez l'entité Metadata en utilisant le hachage IPFS comme identifiant.

Vous pouvez utiliser [Contexte de la source de données](https://thegraph.com/docs/en/developing/assemblyscript-api/#entity-and-data-source-context) lors de la création de sources de données de fichiers pour transmettre des informations supplémentaires qui seront mises à la disposition du gestionnaire de la source de données de fichiers.

Si vous avez des entités qui sont actualisées plusieurs fois, créez des entités uniques basées sur des fichiers en utilisant le hachage & IPFS ; l'ID de l'entité, et référencez-les en utilisant un champ dérivé dans l'entité basée sur la chaîne.

> Nous travaillons à l'amélioration de la recommandation ci-dessus, afin que les requêtes ne renvoient que la version "la plus récente"

#### Problèmes connus

Les sources de données de fichiers nécessitent actuellement des ABI, même si les ABI ne sont pas utilisées ([problème](https://github.com/graphprotocol/graph-cli/issues/961)). La solution consiste à ajouter n'importe quel ABI.

Les gestionnaires des sources de données de fichiers ne peuvent pas se trouver dans des fichiers qui importent des liaisons de contrat `eth_call`, échouant avec "importation inconnue : `ethereum::ethereum.call` n'a pas été défini" ([issue](https://github.com/graphprotocol/graph-cli/issues/4309)). La solution de contournement consiste à créer des gestionnaires de sources de données de fichiers dans un fichier dédié.

#### Exemples

[Crypto Coven Subgraph migration](https://github.com/azf20/cryptocoven-api/tree/file-data-sources-refactor)

#### Les Références

[Sources de données du fichier GIP](https://forum.thegraph.com/t/gip-file-data-sources/2721)

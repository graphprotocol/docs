---
title: FAQ sur les subgraphs alimentés par les sous-flux
---

## Que sont les sous-flux ?

Développé par [StreamingFast] (https://www.streamingfast.io/), Substreams est un moteur de traitement exceptionnellement puissant capable de consommer de riches flux de données blockchain. Substreams vous permet d'affiner et de façonner les données de la blockchain pour une digestion rapide et transparente par les applications des utilisateurs finaux. Plus précisément, Substreams est un moteur agnostique à la blockchain, parallélisé et à flux continu, qui sert de couche de transformation des données de la blockchain. Alimenté par le [Firehose](https://firehose.streamingfast.io/), il permet aux développeurs d'écrire des modules Rust, de s'appuyer sur des modules communautaires, de fournir une indexation extrêmement performante et de [sink] (https://substreams.streamingfast.io/developers-guide/sink-targets) leurs données n'importe où.

Rendez-vous sur le site [Substreams Documentation](/substreams) pour en savoir plus sur Substreams.

## Qu'est-ce qu'un subgraph alimenté par des courants de fond ?

Les [subgraphs alimentés par Substreams](/cookbook/substreams-powered-subgraphs/) combinent la puissance de Substreams avec la capacité d'interrogation des subgraphs. Lors de la publication d'un subgraph alimenté par Substreams, les données produites par les transformations Substreams peuvent [output entity changes] (https://github.com/streamingfast/substreams-sink-entity-changes/blob/develop/substreams-entity-change/src/tables.rs), qui sont compatibles avec les entités du subgraph.

Si vous êtes déjà familiarisé avec le développement de subgraphs, notez que les subgraphs alimentés par Substreams peuvent ensuite être interrogés, comme s'ils avaient été produits par la couche de transformation AssemblyScript, avec tous les avantages de Subgraph, comme la fourniture d'une API GraphQL dynamique et flexible.

## En quoi les subgraphs alimentés par les courants secondaires sont-ils différents des subgraphs ?

Les subgraphs sont constitués de sources de données qui spécifient les événements de la chaîne et la manière dont ces événements doivent être traités par des gestionnaires écrits en Assemblyscript. Ces événements sont traités de manière séquentielle, en fonction de l'ordre dans lequel ils se produisent dans la chaîne.

En revanche, les subgraphs alimentés par des flux secondaires disposent d'une source de données unique référençant un paquet de flux secondaires, qui est traité par le nœud de graphe. Les subgraphs ont accès à des données granulaires supplémentaires sur la chaîne par rapport aux subgraphs conventionnels et peuvent également bénéficier d'un traitement massivement parallélisé, ce qui peut se traduire par des temps de traitement beaucoup plus rapides.

## Quels sont les avantages de l'utilisation de subgraphs alimentés par des courants descendants ?

Les subgraphs alimentés par Substreams combinent tous les avantages de Substreams avec la capacité d'interrogation des subgraphs. Ils apportent au graphe une plus grande composabilité et une indexation très performante. Ils permettent également de nouveaux cas d'utilisation des données ; par exemple, une fois que vous avez construit votre subgraph alimenté par Substreams, vous pouvez réutiliser vos [modules Substreams](https://substreams.streamingfast.io/developers-guide/modules) pour sortir vers différents [sinks] (https://substreams.streamingfast.io/developers-guide/sink-targets) tels que PostgreSQL, MongoDB et Kafka.

## Quels sont les avantages de Substreams ?

L'utilisation de Substreams présente de nombreux avantages, notamment:

- Composable : Vous pouvez empiler les modules Substreams comme des blocs LEGO et construire des modules communautaires pour affiner les données publiques.

- Indexation haute performance : Indexation plus rapide d'un ordre de grandeur grâce à des grappes d'opérations parallèles à grande échelle (comme BigQuery).

- Sortez vos données n'importe où : Transférez vos données où vous le souhaitez : PostgreSQL, MongoDB, Kafka, subgraphs, fichiers plats, Google Sheets.

- Programmable : Utilisez du code pour personnaliser l'extraction, effectuer des agrégations au moment de la transformation et modéliser vos résultats pour plusieurs puits.

- Accès à des données supplémentaires qui ne sont pas disponibles dans le cadre de la RPC JSON

- Tous les avantages du Firehose.

## Tous les avantages du Firehose?

Développé par [StreamingFast] (https://www.streamingfast.io/), le Firehose est une couche d'extraction de données de blockchain conçue à partir de zéro pour traiter l'historique complet des blockchains à des vitesses jusqu'alors inconnues . Obtenez une approche basée sur les fichiers et le streaming, il s'agit d'un composant essentiel de la suite de technologies open-source de StreamingFast et de la base de Substreams.

Consultez la [documentation] (https://firehose.streamingfast.io/) pour en savoir plus sur le Firehose.

## Quels sont les avantages du Firehose ?

L'utilisation de Firehose présente de nombreux avantages, notamment:

- Temps de latence le plus faible et pas d'interrogation : Les nœuds Firehose sont conçus pour faire la course afin de diffuser les données en bloc en premier, selon le principe "streaming-first".

- Prévient les temps d'arrêt : Conçu dès le départ pour une haute disponibilité.

- Ne manquez jamais le rythme : Le curseur du flux Firehose est conçu pour gérer les bifurcations et pour reprendre là où vous vous êtes arrêté dans n'importe quelle condition.

- Modèle de données le plus riche :   Meilleur modèle de données qui inclut les changements de solde, l'arbre d'appel complet, les transactions internes, les journaux, les changements de stockage, les coûts du gaz, etc.

- Exploite les fichiers plats : Les données de la blockchain sont extraites dans des fichiers plats, la ressource informatique la moins chère et la plus optimisée disponible.

## Où les développeurs peuvent-ils trouver plus d'informations sur les subgraphs alimentés par Substreams et sur Substreams ?

La [documentation Substreams](/substreams) vous apprendra à construire des modules Substreams.

La [documentation sur les subgraphs alimentés par des flux partiels] (/cookbook/substreams-powered-subgraphs/) vous montrera comment les emballer pour les déployer sur The Graph.

## Quel est le rôle des modules Rust dans Substreams ?

Les modules Rust sont l'équivalent des mappeurs AssemblyScript dans les subgraphs. Ils sont compilés dans WASM de la même manière, mais le modèle de programmation permet une exécution parallèle. Ils définissent le type de transformations et d'agrégations que vous souhaitez appliquer aux données brutes de la blockchain.

Voir [documentation des modules] (https://substreams.streamingfast.io/developers-guide/modules) pour plus de détails.

## Qu'est-ce qui rend Substreams composable ?

Lors de l'utilisation de Substreams, la composition a lieu au niveau de la couche de transformation, ce qui permet de réutiliser les modules mis en cache.

Par exemple, Alice peut créer un module de prix DEX, Bob peut l'utiliser pour créer un agrégateur de volume pour certains jetons qui l'intéressent, et Lisa peut combiner quatre modules de prix DEX individuels pour créer un oracle de prix. Une seule requête Substreams regroupera tous ces modules individuels, les reliera entre eux, pour offrir un flux de données beaucoup plus raffiné. Ce flux peut ensuite être utilisé pour alimenter un subgraph et être interrogé par les consommateurs.

## Comment pouvez-vous créer et déployer un Subgraph basé sur Substreams ?

Après avoir [defining](/cookbook/substreams-powered-subgraphs/) un Subgraph alimenté par Substreams, vous pouvez utiliser la CLI Graph pour le déployer dans [Subgraph Studio](https://thegraph.com/studio/).

## Où puis-je trouver des exemples de subgraphs et de subgraphs alimentés par des substreams ?

Vous pouvez visiter [ce repo Github] (https://github.com/pinax-network/awesome-substreams) pour trouver des exemples de Substreams et de subgraphs alimentés par Substreams.

## Que signifient les subgraphs et les subgraphs alimentés par des substreams pour le réseau graph ?

L'intégration promet de nombreux avantages, notamment une indexation extrêmement performante et une plus grande composabilité grâce à l'exploitation des modules de la communauté et à leur développement.

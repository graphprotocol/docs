---
title: Vytvoření podgraf
---

Podgraf získává data z blockchain, zpracovává je a ukládá tak, aby se na ně dalo snadno dotazovat prostřednictvím jazyka GraphQL.

![Definování podgrafu](/img/defining-a-subgraph.png)

Definice podgraf se skládá z několika souborů:

- `subgraph.yaml`: soubor YAML obsahující manifest podgraf

- `schema.graphql`: schéma GraphQL, které definuje, jaká data jsou uložena pro váš podgraf a jak se na ně dotazovat prostřednictvím jazyka GraphQL

- `Mapování skriptů sestavy`: [AssemblyScript](https://github.com/AssemblyScript/assemblyscript) kód, který převádí data událostí na entity definované ve vašem schématu (např. `mapping.ts` v tomto tutoriálu)

> In order to use your subgraph on The Graph's decentralized network, you will need to [create an API key](/deploying/subgraph-studio-faqs/#2-how-do-i-create-an-api-key). It is recommended that you [add signal](/network/curating/#how-to-signal) to your subgraph with at least [3,000 GRT](/sunrise/#how-can-i-ensure-high-quality-of-service-and-redundancy-for-subgraphs-on-the-graph-network).

Before you go into detail about the contents of the manifest file, you need to install the [Graph CLI](https://github.com/graphprotocol/graph-tooling) which you will need to build and deploy a subgraph.

## Instalace Graf CLI

Graf CLI je napsáno v jazyce JavaScript a k jeho použití je třeba nainstalovat buď `yarn`, nebo `npm`; v následujícím se předpokládá, že máte yarn.

Jakmile budete mít `yarn`, nainstalujte Graf CLI spuštěním příkazu

**Instalace pomocí yarn:**

```bash
yarn global add @graphprotocol/graph-cli
```

**Instalace pomocí npm:**

```bash
npm install -g @graphprotocol/graph-cli
```

Once installed, the `graph init` command can be used to set up a new subgraph project, either from an existing contract or from an example subgraph. This command can be used to create a subgraph in Subgraph Studio by passing in `graph init --product subgraph-studio`. If you already have a smart contract deployed to your preferred network, bootstrapping a new subgraph from that contract can be a good way to get started.

## Ze stávající smlouvy

Následující příkaz vytvoří podgraf, který indexuje všechny události existující smlouvy. Pokusí se načíst ABI smlouvy z Etherscan a vrátí se k požadavku na cestu k místnímu souboru. Pokud některý z nepovinných argumentů chybí, projde příkaz interaktivním formulářem.

```sh
graph init \
  --product subgraph-studio
  --from-contract <CONTRACT_ADDRESS> \
  [--network <ETHEREUM_NETWORK>] \
  [--abi <FILE>] \
  <SUBGRAPH_SLUG> [<DIRECTORY>]
```

`<SUBGRAPH_SLUG>` je ID vašeho podgraf ve Studio podgraph, najdete ho na stránce s podrobnostmi o podgrafu.

## Z příkladu podgraf

Druhý režim `graf init` podporuje vytvoření nového projektu z příkladového podgraf. To provede následující příkaz:

```sh
graph init --studio <SUBGRAPH_SLUG>
```

The [example subgraph](https://github.com/graphprotocol/example-subgraph) is based on the Gravity contract by Dani Grant that manages user avatars and emits `NewGravatar` or `UpdateGravatar` events whenever avatars are created or updated. The subgraph handles these events by writing `Gravatar` entities to the Graph Node store and ensuring these are updated according to the events. The following sections will go over the files that make up the subgraph manifest for this example.

## Přidání nových zdrojů dat do existujícího podgraf

Od verze `v0.31.0` podporuje `graf-cli` přidávání nových zdrojů dat do existujícího podgrafu pomocí příkazu `graf add`.

```sh
graph add <address> [<subgraph-manifest default: "./subgraph.yaml">]

Možnosti:

      --abi <path> Cesta k ABI smlouvy (výchozí: stažení z Etherscan)
      --contract-name Název kontraktu (výchozí: Contract)
      --merge-entities Zda sloučit entity se stejným názvem (výchozí: false)
      --network-file <path> Cesta ke konfiguračnímu souboru sítě (výchozí: "./networks.json")
```

Příkaz `add` načte ABI z Etherscan (pokud není zadána cesta k ABI pomocí volby `--abi`) a vytvoří nový `dataSource` stejným způsobem jako příkaz `graph init` vytvoří `dataSource` `--from-contract`, přičemž odpovídajícím způsobem aktualizuje schéma a mapování.

Volba `--merge-entities` určuje, jak chce vývojář řešit konflikty názvů `entity` a `event`:

- Pokud `true`: nový `dataSource` by měl používat stávající `eventHandlers` & `entity`.
- Pokud `false`: měla by být vytvořena nová entita & obsluha události s `${dataSourceName}{EventName}`.

Smlouva `adresa` bude zapsána do souboru `networks.json` pro příslušnou síť.

> **Poznámka:** Při použití interaktivního klienta budete po úspěšném spuštění `graf init` vyzváni k přidání nového `dataSource`.

## Manifest podgrafu

Manifest podgrafu `subgraph.yaml` definuje inteligentní smlouvy, které váš podgraf indexuje, kterým událostem z těchto smluv má věnovat pozornost a jak mapovat data událostí na entity, které Graf uzel ukládá a umožňuje dotazovat. Úplnou specifikaci manifestů podgrafu naleznete [zde](https://github.com/graphprotocol/graph-node/blob/master/docs/subgraph-manifest.md).

Pro příklad podgraf `subgraph.yaml` je:

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
repository: https://github.com/graphprotocol/graph-tooling
schema:
  file: ./schema.graphql
indexerHints:
  prune: auto
dataSources:
  - kind: ethereum/contract
    name: Gravity
    network: mainnet
    source:
      address: '0x2E645469f354BB4F5c8a05B3b30A929361cf77eC'
      abi: Gravity
      startBlock: 6175244
      endBlock: 7175245
    context:
      foo:
        type: Bool
        data: true
      bar:
        type: String
        data: 'bar'
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      entities:
        - Gravatar
      abis:
        - name: Gravity
          file: ./abis/Gravity.json
      eventHandlers:
        - event: NewGravatar(uint256,address,string,string)
          handler: handleNewGravatar
        - event: UpdatedGravatar(uint256,address,string,string)
          handler: handleUpdatedGravatar
      callHandlers:
        - function: createGravatar(string,string)
          handler: handleCreateGravatar
      blockHandlers:
        - handler: handleBlock
        - handler: handleBlockWithCall
          filter:
            kind: call
      file: ./src/mapping.ts
```

Důležité položky, které je třeba v manifestu aktualizovat, jsou:

- `specVersion`: a semver version that identifies the supported manifest structure and functionality for the subgraph. The latest version is `1.2.0`. See [specVersion releases](#specversion-releases) section to see more details on features & releases.

- `description`: a human-readable description of what the subgraph is. This description is displayed in Graph Explorer when the subgraph is deployed to Subgraph Studio.

- `repository`: the URL of the repository where the subgraph manifest can be found. This is also displayed in Graph Explorer.

- `features`: seznam všech použitých názvů [feature](#experimental-features).

- `indexerHints.prune`: Definuje uchovávání historických blokových dat pro podgraf. Viz [prune](#prune) v sekci [indexerHints](#indexer-hints).

- `dataSources.source`: adresa inteligentní smlouvy, ze které podgraf pochází, a ABI inteligentní smlouvy, která se má použít. Adresa je nepovinná; její vynechání umožňuje indexovat odpovídající události ze všech smluv.

- `dataSources.source.startBlock`: nepovinné číslo bloku, od kterého zdroj dat začíná indexovat. Ve většině případů doporučujeme použít blok, ve kterém byl kontrakt vytvořen.

- `dataSources.source.endBlock`: Nepovinné číslo bloku, ve kterém zdroj dat přestane indexovat, včetně tohoto bloku. Minimální požadovaná verze specifikace: `0.0.9`.

- `dataSources.context`: páry klíč-hodnota, které lze použít v rámci mapování podgrafů. Podporuje různé datové typy, například `Bool`, `String`, `Int`, `Int8`, `BigDecimal`, `Bytes`, `List` a `BigInt`. U každé proměnné je třeba uvést její `typ` a `údaj`. Tyto kontextové proměnné jsou pak přístupné v mapovacích souborech a nabízejí více konfigurovatelných možností pro vývoj podgrafů.

- `dataSources.mapping.entities`: entity, které zdroj dat zapisuje do úložiště. Schéma pro každou entita je definováno v souboru schema.graphql.

- `dataSources.mapping.abis`: jeden nebo více pojmenovaných souborů ABI pro zdrojový kontrakt a všechny ostatní chytré kontrakty, se kterými se pracuje v rámci mapování.

- `dataSources.mapping.eventHandlers`: uvádí seznam událostí inteligentních smluv, na které tento podgraf reaguje, a obslužných programů v mapování - v příkladu./src/mapping.ts - které tyto události transformují na entity v úložišti.

- `dataSources.mapping.callHandlers`: obsahuje seznam funkcí inteligentních smluv, na které tento podgraf reaguje, a obsluhovače v mapování, které transformují vstupy a výstupy volání funkcí na entity v úložišti.

- `dataSources.mapping.blockHandlers`: seznam bloků, na které tento podgraf reaguje, a obslužných v mapování, které se spustí, když je blok přidán do řetězce. Bez filtru se obsluha bloku spustí každý blok. Volitelný filtr volání lze zadat přidáním </code> field with `filter` druhem: volání</0> k obsluze. Tím se obslužná rutina spustí pouze tehdy, pokud blok obsahuje alespoň jedno volání smlouvy zdroje dat.

Jeden subgraf může indexovat data z více inteligentní smluv. Do pole `dataSources` přidejte položku pro každou smlouvu, ze které je třeba indexovat data.

### Pořadí spouštěcích Handlers

Spouštěče pro zdroj dat v rámci bloku jsou seřazeny podle následujícího postupu:

1. Spouštěče událostí a volání jsou nejprve seřazeny podle indexu transakce v rámci bloku.
2. Spouštěče událostí a volání v rámci jedné transakce jsou seřazeny podle konvence: nejprve spouštěče událostí a poté spouštěče volání, přičemž každý typ dodržuje pořadí, v jakém jsou definovány v manifestu.
3. Spouštěče bloků jsou spuštěny po spouštěčích událostí a volání, v pořadí, v jakém jsou definovány v manifestu.

Tato pravidla objednávání se mohou změnit.

> **Poznámka:** Při vytvoření nového [dynamického zdroje dat](#data-source-templates-for-dynamically-created-contracts) se zpracovatelé definovaní pro dynamické zdroje dat začnou zpracovávat až po zpracování všech existujících zpracovatelů zdrojů dat a budou se opakovat ve stejném pořadí, kdykoli budou spuštěny.

### SpecVersion Releases

| Verze | Poznámky vydání                                                                                                                                                        |
|:-----:| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1.2.0 | Added support for [Indexed Argument Filtering](/#indexed-argument-filters--topic-filters) & declared `eth_call`                                                        |
| 1.1.0 | Supports [Timeseries & Aggregations](#timeseries-and-aggregations). Added support for type `Int8` for `id`.                                                            |
| 1.0.0 | Supports [`indexerHints`](/developing/creating-a-subgraph/#indexer-hints) feature to prune subgraphs                                                                   |
| 0.0.9 | Supports `endBlock` feature                                                                                                                                            |
| 0.0.8 | Added support for polling [Block Handlers](developing/creating-a-subgraph/#polling-filter) and [Initialisation Handlers](developing/creating-a-subgraph/#once-filter). |
| 0.0.7 | Added support for [File Data Sources](developing/creating-a-subgraph/#file-data-sources).                                                                              |
| 0.0.6 | Supports fast [Proof of Indexing](/network/indexing/#what-is-a-proof-of-indexing-poi) calculation variant.                                                             |
| 0.0.5 | Added support for event handlers having access to transaction receipts.                                                                                                |
| 0.0.4 | Added support for managing subgraph features.                                                                                                                          |

### Získání ABI

Soubor(y) ABI se musí shodovat s vaší smlouvou. Soubory ABI lze získat několika způsoby:

- Pokud vytváříte vlastní projekt, budete mít pravděpodobně přístup k nejaktuálnějším ABI.
- Pokud vytváříte podgraf pro veřejný projekt, můžete si tento projekt stáhnout do počítače a získat ABI pomocí [`truffle compile`](https://truffleframework.com/docs/truffle/overview) nebo pomocí solc pro kompilaci.
- ABI můžete také najít na stránce [Etherscan](https://etherscan.io/), ale ta není vždy spolehlivá, protože ABI, které je tam nahráno, může být zastaralé. Ujistěte se, že máte správné ABI, jinak spuštění podgrafu selže.

## Schéma GraphQL

Schéma vašeho podgrafu je v souboru `schema.graphql`. Schémata GraphQL se definují pomocí jazyka pro definici rozhraní GraphQL. Pokud jste ještě nikdy schéma GraphQL nepsali, doporučujeme vám přečíst si tento úvodní článek o systému typů GraphQL. Referenční dokumentaci ke schématům GraphQL naleznete v části [GraphQL API](/querying/graphql-api).

## Definice entit

Před definováním entit je důležité udělat krok zpět a zamyslet se nad tím, jak jsou vaše data strukturována a propojena. Všechny dotazy budou prováděny proti datovému modelu definovanému ve schématu podgrafu a entitám indexovaným podgrafem. Z tohoto důvodu je dobré definovat schéma podgrafu způsobem, který odpovídá potřebám vaší dapp. Může být užitečné představit si entity spíše jako "objekty obsahující data" než jako události nebo funkce.

V nástroji The Graf stačí definovat typy entit v `schema.graphql` a Graf Uzel vygeneruje pole nejvyšší úrovně pro dotazování jednotlivých instancí a kolekcí daného typu entit. Každý typ, který má být entitou, je nutné anotovat direktivou `@entity`. Ve výchozím nastavení jsou entity mutovatelné, což znamená, že mapování může načíst existující entity, upravit je a uložit novou verzi dané entity. Mutabilita má svou cenu a u typů entit, u nichž je známo, že nebudou nikdy modifikovány, například proto, že jednoduše obsahují data doslovně extrahovaná z řetězce, se doporučuje označit je jako neměnné pomocí `@entity(immutable: true)`. Mapování může provádět změny v neměnných entitách, pokud k nim dojde ve stejném bloku, ve kterém byla entita vytvořena. Neměnné entity se mnohem rychleji zapisují a dotazují, a proto by se měly používat, kdykoli je to možné.

### Dobrý příklad

Níže uvedená entita `Gravatar` je strukturována kolem objektu Gravatar a je dobrým příkladem toho, jak lze entitu definovat.

```graphql
type Gravatar @entity(immutable: true) {
  id: Bytes!
  owner: Bytes
  displayName: String
  imageUrl: String
  accepted: Boolean
}
```

### Špatný příklad

Níže uvedené příklady entit `GravatarAccepted` a `GravatarDeclined` jsou založeny na událostech. Nedoporučuje se mapovat události nebo volání funkcí na entity 1:1.

```graphql
type GravatarAccepted @entity {
  id: Bytes!
  owner: Bytes
  displayName: String
  imageUrl: String
}

type GravatarDeclined @entity {
  id: Bytes!
  owner: Bytes
  displayName: String
  imageUrl: String
}
```

### Nepovinná a povinná pole

Pole entit lze definovat jako povinná nebo nepovinná. Povinná pole jsou ve schématu označena `!`. Pokud není povinné pole v mapování nastaveno, zobrazí se při dotazu na toto pole tato chyba:

```
Vyřešení nulové hodnoty pro pole 'name', které není nulové
```

Každá entita musí mít pole `id`, které musí být typu `Bajty!` nebo `Řetězec!`. Obecně se doporučuje používat `Bytes!`, pokud `id` neobsahuje lidsky čitelný text, protože entity s `Bytes!` id se zapisují a dotazují rychleji než entity s `String!` `id`. Pole `id` slouží jako primární klíč a musí být jedinečné mezi všemi entitami stejného typu. Z historických důvodů je akceptován také typ `ID!`, který je synonymem pro `String!`.

U některých typů entit je `id` vytvořeno z id dvou jiných entit; to je možné pomocí `concat`, např. `let id = left.id.concat(right.id)` pro vytvoření id z id `left` a `right`. Podobně lze použít `let id = left.id.concatI32(count)` pro vytvoření id z id existující entity a čítače `count`. Konkatenace zaručeně vytvoří jedinečné id, pokud je délka `left` pro všechny takové entity stejná, například proto, že `left.id` je `Adresa`.

### Vestavěné typy skalárů

#### Podporované skaláry GraphQL

V našem GraphQL API podporujeme následující skaláry:

| Typ          | Popis                                                                                                                                                                                                                                              |
| ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `Bajtů`      | Pole bajtů reprezentované jako hexadecimální řetězec. Běžně se používá pro hashe a adresy Ethereum.                                                                                                                                                |
| `Řetězec`    | Skalár pro hodnoty `řetězce`. Nulové znaky nejsou podporovány a jsou automaticky odstraněny.                                                                                                                                                       |
| `Boolean`    | Skalár pro hodnoty `boolean`.                                                                                                                                                                                                                      |
| `Int`        | Specifikace GraphQL definuje `Int` na velikost 32 bajtů.                                                                                                                                                                                           |
| `Int8`       | Celé číslo se znaménkem o velikosti 8 bajtů, známé také jako 64bitové celé číslo se znaménkem, může uchovávat hodnoty v rozsahu od -9 223 372 036 854 775 808 do 9 223 372 036 854 775 807. Přednostně se používá k reprezentaci `i64` z ethereum. |
| `BigInt`     | Velká celá čísla. Používá se pro typy `uint32`, `int64`, `uint64`, ..., `uint256` společnosti Ethereum. Poznámka: Vše pod `uint32`, jako například `int32`, `uint24` nebo `int8`, je reprezentováno jako `i32`.                                    |
| `BigDecimal` | `BigDecimal` Desetinná čísla s vysokou přesností reprezentovaná jako signifikand a exponent. Rozsah exponentu je od -6143 do +6144. Zaokrouhleno na 34 významných číslic.                                                                          |

#### Enums

Výčty můžete vytvářet také v rámci schématu. Syntaxe enumů je následující:

```graphql
enum TokenStatus {
  OriginalOwner
  SecondOwner
  ThirdOwner
}
```

Jakmile je enum definován ve schématu, můžete použít řetězcovou reprezentaci hodnoty výčtu k nastavení pole výčtu u entity. Například můžete nastavit `tokenStatus` na `SecondOwner` tak, že nejprve definujete svou entitu a následně nastavíte pole pomocí `entity.tokenStatus = "SecondOwner"`. Níže uvedený příklad ukazuje, jak by vypadala entita Token s výčtovým polem:

Podrobnější informace o zápisu enum najdete v dokumentaci [GraphQL](https://graphql.org/learn/schema/).

#### Vztahy entit

Entita může mít vztah k jedné nebo více jiným entitám ve vašem schématu. Tyto vztahy lze procházet v dotazech. Vztahy v Graf jsou jednosměrné. Obousměrné vztahy je možné simulovat definováním jednosměrného vztahu na obou "koncích" vztahu.

Vztahy se definují u entit stejně jako u jiných polí s tím rozdílem, že zadaný typ je typ jiné entity.

#### Vztahy jeden na jednoho

Definujte typ entity `Transaction` s volitelným vztahem jedna ku jedné s typemem entity `TransactionReceipt`:

```graphql
type Transaction @entity(immutable: true) {
  id: Bytes!
  transactionReceipt: TransactionReceipt
}

type TransactionReceipt @entity(immutable: true) {
  id: Bytes!
  transaction: Transaction
}
```

#### Vztahy jeden k mnoha

Definujte typ entity `TokenBalance` s požadovaným vztahem one-to-many s typem entity Token:

```graphql
type Token @entity(immutable: true) {
  id: Bytes!
}

type TokenBalance @entity {
  id: Bytes!
  amount: Int!
  token: Token!
}
```

#### Zpětné vyhledávání

Reverzní vyhledávání lze u entity definovat prostřednictvím pole `@derivedFrom`. Tím se na entitě vytvoří virtuální pole, na které se lze dotazovat, ale které nelze nastavit ručně prostřednictvím API mapování. Spíše je odvozeno ze vztahu definovaného na jiné entitě. U takových vztahů má zřídkakdy smysl ukládat obě strany vztahu a indexace i výkonnost dotazů budou lepší, když bude uložena pouze jedna strana a druhá bude odvozená.

U vztahů typu "jeden k mnoha" by měl být vztah vždy uložen na straně "jeden" a strana "mnoho" by měla být vždy odvozena. Uložení vztahu tímto způsobem namísto uložení pole entit na straně "mnoho" povede k výrazně lepšímu výkonu jak při indexování, tak při dotazování na podgraf. Obecně platí, že ukládání polí entit je třeba se vyhnout, pokud je to praktické.

#### Příklad

Zůstatky token můžeme zpřístupnit z token odvozením pole `tokenBalances`:

```graphql
type Token @entity(immutable: true) {
  id: Bytes!
  tokenBalances: [TokenBalance!]! @derivedFrom(field: "token")
}

type TokenBalance @entity {
  id: Bytes!
  amount: Int!
  token: Token!
}
```

#### Vztahy mnoho k mnoha

Pro vztahy mnoho-více, jako jsou uživatelé, z nichž každý může patřit do libovolného počtu organizací, je nejjednodušší, ale obecně ne nejvýkonnější, modelovat vztah jako pole v každé z obou zúčastněných entit. Pokud je vztah symetrický, je třeba uložit pouze jednu stranu vztahu a druhou stranu lze odvodit.

#### Příklad

Definujte zpětné vyhledávání z typu entity `User` na typ entity `Organization`. V příkladu níže je toho dosaženo vyhledáním atributu `members` z entity `Organization`. V dotazech bude pole `organizations` na `User` vyřešeno vyhledáním všech entit `Organization`, které obsahují ID uživatele.

```graphql
type Organization @entity {
  id: Bytes!
  name: String!
  members: [User!]!
}

type User @entity {
  id: Bytes!
  name: String!
  organizations: [Organization!]! @derivedFrom(field: "members")
}
```

Výkonnějším způsobem uložení tohoto vztahu je mapovací tabulka, která má pro každou dvojici `Uživatel` / `Organizace` jeden záznam se schématem, jako je např

```graphql
type Organization @entity {
  id: Bytes!
  name: String!
  members: [UserOrganization!]! @derivedFrom(field: "organization")
}

type User @entity {
  id: Bytes!
  name: String!
  organizations: [UserOrganization!] @derivedFrom(field: "user")
}

type UserOrganization @entity {
  id: Bytes! # Set to `user.id.concat(organization.id)`
  user: User!
  organization: Organization!
}
```

Tento přístup vyžaduje, aby dotazy sestupovaly do další úrovně, aby bylo možné získat například organizace pro uživatele:

```graphql
query usersWithOrganizations {
  users {
    organizations {
      # this is a UserOrganization entity
      organization {
        name
      }
    }
  }
}
```

Tento propracovanější způsob ukládání vztahů mnoho-více vede k menšímu množství dat uložených pro podgraf, a tedy k podgrafu, který je často výrazně rychlejší při indexování a dotazování.

#### Přidání komentářů do schématu

As per GraphQL spec, comments can be added above schema entity attributes using the hash symble `#`. This is illustrated in the example below:

```graphql
type MyFirstEntity @entity {
  # unique identifier and primary key of the entity
  id: Bytes!
  address: Bytes!
}
```

## Definování polí fulltextového vyhledávání

Fulltextové vyhledávací dotazy filtrují a řadí entity na základě textového vyhledávacího vstupu. Fulltextové dotazy jsou schopny vracet shody podobných slov tím, že zpracovávají vstupní text dotazu do kmenů před jejich porovnáním s indexovanými textovými daty.

Definice fulltextového dotazu obsahuje název dotazu, jazykový slovník použitý ke zpracování textových polí, algoritmus řazení použitý k seřazení výsledků a pole zahrnutá do vyhledávání. Každý fulltextový dotaz může zahrnovat více polí, ale všechna zahrnutá pole musí být z jednoho typu entity.

Chcete-li přidat fulltextový dotaz, zahrňte do schématu GraphQL typ `_Schema_` s direktivou fulltext.

```graphql
type _Schema_
  @fulltext(
    name: "bandSearch"
    language: en
    algorithm: rank
    include: [{ entity: "Band", fields: [{ name: "name" }, { name: "description" }, { name: "bio" }] }]
  )

type Band @entity {
  id: Bytes!
  name: String!
  description: String!
  bio: String
  wallet: Address
  labels: [Label!]!
  discography: [Album!]!
  members: [Musician!]!
}
```

Příklad pole `bandSearch` lze použít v dotazech k filtrování entit `Band` na základě textových dokumentů v polích `name`, `description` a `bio`. Přejděte na [GraphQL API - dotazy](/querying/graphql-api#queries), kde najdete popis API pro fulltextové vyhledávání a další příklady použití.

```graphql
query {
  bandSearch(text: "breaks & electro & detroit") {
    id
    name
    description
    wallet
  }
}
```

> **[Správa funkcí](#experimental-features):** Od `specVersion` `0.0.4` musí být `fullTextSearch` deklarováno v sekci `features` v manifestu podgrafů.

### Podporované jazyky

Výběr jiného jazyka bude mít na rozhraní API fulltextového vyhledávání rozhodující, i když někdy nenápadný vliv. Pole zahrnutá do pole fulltextového dotazu jsou zkoumána v kontextu zvoleného jazyka, takže lexémy vytvořené analýzou a vyhledávacími dotazy se v jednotlivých jazycích liší. Například: při použití podporovaného tureckého slovníku je "token" odvozeno od "toke", zatímco anglický slovník jej samozřejmě odvozuje od "token".

Podporované jazykové slovníky:

| Kód        | Slovník    |
| ---------- | ---------- |
| jednoduchý | Obecné     |
| da         | Danish     |
| nl         | Dutch      |
| en         | English    |
| fi         | Finnish    |
| fr         | French     |
| de         | German     |
| hu         | Hungarian  |
| it         | Italian    |
| no         | Norwegian  |
| pt         | Portuguese |
| ro         | Romanian   |
| ru         | Russian    |
| es         | Spanish    |
| sv         | Swedish    |
| tr         | Turkish    |

### Algoritmy řazení

Podporované algoritmy pro řazení výsledků:

| Algoritmus    | Popis                                                                    |
| ------------- | ------------------------------------------------------------------------ |
| hodnost       | Pro seřazení výsledků použijte kvalitu shody (0-1) fulltextového dotazu. |
| proximityRank | Podobně jako pořadí, ale zahrnuje také blízkost zápasů.                  |

## Psát mapování

Mapování přebírá data z určitého zdroje a transformuje je na entity definované ve vašem schématu. Mapování jsou zapsána v podmnožině jazyka [TypeScript](https://www.typescriptlang.org/docs/handbook/typescript-in-5-minutes.html) nazvané [AssemblyScript](https://github.com/AssemblyScript/assemblyscript/wiki), kterou lze zkompilovat do jazyka WASM ([WebAssembly](https://webassembly.org/)). AssemblyScript je přísnější než běžný TypeScript, přesto poskytuje známou syntaxi.

Pro každou obsluhu události definovanou v souboru `subgraph.yaml` v části `mapping.eventHandlers` vytvořte exportovanou funkci stejného jména. Každá obslužná funkce musí přijímat jeden parametr nazvaný `událost` s typem odpovídajícím názvu události, která je obsluhována.

V příkladovém podgrafu `src/mapping.ts` obsahuje obsluhy událostí `NewGravatar` a `UpdatedGravatar`:

```javascript
import { NewGravatar, UpdatedGravatar } from '../generated/Gravity/Gravity'
import { Gravatar } from '../generated/schema'

export function handleNewGravatar(event: NewGravatar): void {
  let gravatar = new Gravatar(event.params.id)
  gravatar.owner = event.params.owner
  gravatar.displayName = event.params.displayName
  gravatar.imageUrl = event.params.imageUrl
  gravatar.save()
}

export function handleUpdatedGravatar(event: UpdatedGravatar): void {
  let id = event.params.id
  let gravatar = Gravatar.load(id)
  if (gravatar == null) {
    gravatar = new Gravatar(id)
  }
  gravatar.owner = event.params.owner
  gravatar.displayName = event.params.displayName
  gravatar.imageUrl = event.params.imageUrl
  gravatar.save()
}
```

První obslužný program přijme událost `NewGravatar` a vytvoří novou entitu `Gravatar` s `new Gravatar(event.params.id.toHex())`, přičemž pole entity vyplní pomocí odpovídajících parametrů události. Tato instance entity je reprezentována proměnnou `gravatar` s hodnotou id `event.params.id.toHex()`.

Druhá obslužná rutina se pokusí načíst existující `Gravatar` z úložiště Graf Uzel. Pokud ještě neexistuje, je vytvořen na vyžádání. Entita je poté aktualizována tak, aby odpovídala novým parametrům události, a poté je uložena zpět do úložiště pomocí `gravatar.save()`.

### Doporučené IDa pro vytváření nových Entity

Důrazně se doporučuje používat typ `Bajtes` pro pole `id` a typ `String` používat pouze pro atributy, které skutečně obsahují lidsky čitelný text, například název tokenu. Níže jsou uvedeny některé doporučené hodnoty `id`, které je třeba zvážit při vytváření nových entit.

- `transfer.id = event.transaction.hash`

- `let id = event.transaction.hash.concatI32(event.logIndex.toI32())`

- Pro entity, které ukládají agregovaná data, např. denní objemy obchodů, obvykle obsahuje `id` číslo dne, Zde je výhodné použít `Bytes` jako `id`. Určení `id` by vypadalo takto

```typescript
let dayID = event.block.timestamp.toI32() / 86400
let id = Bytes.fromI32(dayID)
```

- Převod konstantních adres na `Bajty`.

`const id = Bytes.fromHexString('0xdead...beef')`

There is a [Graph Typescript Library](https://github.com/graphprotocol/graph-tooling/tree/main/packages/ts) which contains utilities for interacting with the Graph Node store and conveniences for handling smart contract data and entities. It can be imported into `mapping.ts` from `@graphprotocol/graph-ts`.

### Zpracování entit se stejnými ID

Pokud při vytváření a ukládání nové entity již existuje entita se stejným ID, jsou při slučování vždy upřednostněny vlastnosti nové entity. To znamená, že existující entita bude aktualizována hodnotami z nové entity.

Pokud je pro pole v nové entitě se stejným ID záměrně nastavena nulová hodnota, bude stávající entita aktualizována s nulovou hodnotou.

Pokud není pro pole v nové entitě se stejným ID nastavena žádná hodnota, bude pole rovněž nulové.

## Generování kódu

Aby byla práce s inteligentními smlouvami, událostmi a entitami snadná a typově bezpečná, může Graf CLI generovat typy AssemblyScript ze schématu GraphQL podgrafu a ABI smluv obsažených ve zdrojích dat.

To se provádí pomocí

```sh
graph codegen [--output-dir <OUTPUT_DIR>] [<MANIFEST>]
```

ale ve většině případů jsou podgrafy již předkonfigurovány prostřednictvím souboru `package.json`, takže pro dosažení téhož stačí spustit jeden z následujících příkazů:

```sh
# Yarn
yarn codegen

# NPM
npm run codegen
```

Tím se vygeneruje třída AssemblyScript pro každou chytrou smlouvu v souborech ABI uvedených v `subgraph.yaml`, což vám umožní svázat tyto smlouvy s konkrétními adresami v mapování a volat metody smlouvy pouze pro čtení proti zpracovávanému bloku. Pro každou událost kontraktu také vygeneruje třídu, která umožní snadný přístup k parametrům události a také k bloku a transakci, ze které událost pochází. Všechny tyto typy se zapisují do souboru `<OUTPUT_DIR>/<DATA_SOURCE_NAME>/<ABI_NAME>.ts`. V příkladovém podgrafu by to bylo `generated/Gravity/Gravity.ts`, což umožňuje mapování, kterým lze tyto typy importovat.

```javascript
import {
  // The contract class:
  Gravity,
  // The events classes:
  NewGravatar,
  UpdatedGravatar,
} from '../generated/Gravity/Gravity'
```

Kromě toho je pro každý typ entity ve schématu GraphQL podgrafu vygenerována jedna třída. Tyto třídy zajišťují typově bezpečné načítání entit, přístup k polím entit pro čtení a zápis a také metodu `save()` pro zápis entit do úložiště. Všechny třídy entit jsou zapsány do souboru `<OUTPUT_DIR>/schema.ts`, což umožňuje mapování importovat je pomocí funkce

```javascript
import { Gravatar } from '../generated/schema'
```

> **Poznámka:** Po každé změně schématu jazyka GraphQL nebo ABI obsažených v manifestu je nutné provést generování kódu znovu. Musí být také provedeno alespoň jednou před sestavením nebo nasazením podgrafu.

Code generation does not check your mapping code in `src/mapping.ts`. If you want to check that before trying to deploy your subgraph to Graph Explorer, you can run `yarn build` and fix any syntax errors that the TypeScript compiler might find.

## Šablony zdrojů dat

Běžným vzorem v inteligentních smlouvách kompatibilních s EVM je používání registrů nebo továrních smluv, kdy jedna smlouva vytváří, spravuje nebo odkazuje na libovolný počet dalších smluv, z nichž každá má svůj vlastní stav a události.

Adresy těchto dílčích smluv mohou, ale nemusí být známy předem a mnoho z těchto smluv může být vytvořeno a/nebo přidáno v průběhu času. Proto v takových případech není možné definovat jediný zdroj dat nebo pevný počet zdrojů dat a je zapotřebí dynamičtější přístup: _šablony zdrojů dat_.

### Zdroj dat pro hlavní smlouvu

Nejprve definujete běžný zdroj dat pro hlavní smlouvu. Níže uvedený úryvek ukazuje zjednodušený příklad zdroje dat pro smlouvu [Uniswap](https://uniswap.org) exchange factory. Všimněte si obsluhy události `NewExchange(address,address)`. Ta je emitována, když je v řetězci vytvořena nová směnná smlouva tovární smlouvou.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Factory
    network: mainnet
    source:
      address: '0xc0a47dFe034B400B47bDaD5FecDa2621de6c4d95'
      abi: Factory
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/factory.ts
      entities:
        - Directory
      abis:
        - name: Factory
          file: ./abis/factory.json
      eventHandlers:
        - event: NewExchange(address,address)
          handler: handleNewExchange
```

### Šablony zdrojů dat pro dynamicky vytvářené smlouvy

Poté do manifestu přidáte _šablony datových zdrojů_. Ty jsou totožné s běžnými zdroji dat, pouze postrádají předdefinovanou adresu smlouvy v položce `zdroj`. Obvykle byste definovali jednu šablonu pro každý typ dílčí smlouvy spravované nebo odkazované nadřazenou smlouvou.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Factory
    # ... other source fields for the main contract ...
templates:
  - name: Exchange
    kind: ethereum/contract
    network: mainnet
    source:
      abi: Exchange
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/exchange.ts
      entities:
        - Exchange
      abis:
        - name: Exchange
          file: ./abis/exchange.json
      eventHandlers:
        - event: TokenPurchase(address,uint256,uint256)
          handler: handleTokenPurchase
        - event: EthPurchase(address,uint256,uint256)
          handler: handleEthPurchase
        - event: AddLiquidity(address,uint256,uint256)
          handler: handleAddLiquidity
        - event: RemoveLiquidity(address,uint256,uint256)
          handler: handleRemoveLiquidity
```

### Instancování šablony zdroje dat

V posledním kroku aktualizujete mapování hlavní smlouvy a vytvoříte dynamickou instanci zdroje dat z jedné ze šablon. V tomto příkladu byste změnili mapování hlavní smlouvy tak, abyste importovali šablonu `Exchange` a zavolali na ní metodu `Exchange.create(address)`, abyste zahájili indexování nové smlouvy exchange.

```typescript
import { Exchange } from '../generated/templates'

export function handleNewExchange(event: NewExchange): void {
  // Start indexing the exchange; `event.params.exchange` is the
  // address of the new exchange contract
  Exchange.create(event.params.exchange)
}
```

> **Poznámka:** Nový zdroj dat bude zpracovávat pouze volání a události pro blok, ve kterém byl vytvořen, a všechny následující bloky, ale nebude zpracovávat historická data, tj. data obsažená v předchozích blocích.
> 
> Pokud předchozí bloky obsahují data relevantní pro nový zdroj dat, je nejlepší tato data indexovat načtením aktuálního stavu smlouvy a vytvořením entit reprezentujících tento stav v době vytvoření nového zdroje dat.

### Kontext zdroje dat

Kontexty zdrojů dat umožňují předávat další konfiguraci při instanci šablony. V našem příkladu řekněme, že burzy jsou spojeny s konkrétním obchodním párem, který je obsažen v události `NewExchange`. Tuto informaci lze předat do instancovaného zdroje dat takto:

```typescript
import { Exchange } from '../generated/templates'

export function handleNewExchange(event: NewExchange): void {
  let context = new DataSourceContext()
  context.setString('tradingPair', event.params.tradingPair)
  Exchange.createWithContext(event.params.exchange, context)
}
```

Uvnitř mapování šablony `výměna` lze pak přistupovat ke kontextu:

```typescript
import { dataSource } from '@graphprotocol/graph-ts'

let context = dataSource.context()
let tradingPair = context.getString('tradingPair')
```

Pro všechny typy hodnot existují setter a getter jako `setString` a `getString`.

## Výchozí bloky

`startBlock` je volitelné nastavení, které umožňuje určit, od kterého bloku v řetězci začne zdroj dat indexovat. Nastavení počátečního bloku umožňuje zdroji dat přeskočit potenciálně miliony bloků, které jsou irelevantní. Typicky vývojář podgrafu nastaví `startBlock` na blok, ve kterém byl vytvořen inteligentní kontrakt zdroje dat.

```yaml
dataSources:
  - kind: ethereum/contract
    name: ExampleSource
    network: mainnet
    source:
      address: '0xc0a47dFe034B400B47bDaD5FecDa2621de6c4d95'
      abi: ExampleContract
      startBlock: 6627917
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      file: ./src/mappings/factory.ts
      entities:
        - User
      abis:
        - name: ExampleContract
          file: ./abis/ExampleContract.json
      eventHandlers:
        - event: NewEvent(address,address)
          handler: handleNewEvent
```

> **Poznámka:** Blok pro vytvoření smlouvy lze rychle vyhledat v Etherscan:
> 
> 1. Vyhledejte smlouvu zadáním její adresy do vyhledávacího řádku.
> 2. Klikněte na hash transakce vytvoření v sekci `Tvůrce smlouvy`.
> 3. Načtěte stránku s podrobnostmi o transakci, kde najdete počáteční blok pro danou smlouvu.

## Tipy indexátor

Nastavení `indexerHints` v manifestu podgrafu poskytuje směrnice pro indexátory ohledně zpracování a správy podgrafu. Ovlivňuje provozní rozhodnutí v oblasti manipulace s daty, strategií indexace a optimalizací. V současné době obsahuje možnost `prune` pro správu uchovávání nebo odstraňování historických dat.

> This feature is available from `specVersion: 1.0.0`

### Prořezávat

`indexerHints.prune`: Definuje zachování historických blokových dat pro podgraf. Mezi možnosti patří:

1. `"nikdy"`: Žádné ořezávání historických dat; zachovává celou historii.
2. `"auto"`: Zachovává minimální potřebnou historii nastavenou indexátorem, čímž optimalizuje výkon dotazu.
3. Konkrétní číslo: Nastaví vlastní limit počtu historických bloků, které se mají zachovat.

```
 indexerHints:
  prune: auto
```

> The term "history" in this context of subgraphs is about storing data that reflects the old states of mutable entities.

History as of a given block is required for:

- [Time travel queries](/querying/graphql-api/#time-travel-queries), which enable querying the past states of these entities at specific blocks throughout the subgraph's history
- Using the subgraph as a [graft base](/developing/creating-a-subgraph/#grafting-onto-existing-subgraphs) in another subgraph, at that block
- Rewinding the subgraph back to that block

If historical data as of the block has been pruned, the above capabilities will not be available.

> Použití `"auto"` se obecně doporučuje, protože maximalizuje výkon dotazu a je dostačující pro většinu uživatelů, kteří nevyžadují přístup k rozsáhlým historickým datům.

U podgrafů využívajících [dotazy na cestování v čase](/querying/graphql-api/#time-travel-queries) je vhodné buď nastavit určitý počet bloků pro uchovávání historických dat, nebo použít `prune: never` pro uchování všech historických stavů entit. Níže jsou uvedeny příklady, jak obě možnosti nakonfigurovat v nastavení podgrafu:

Uchování určitého množství historických dat:

```
 indexerHints:
  prune: 1000 # Nahraďte 1000 požadovaným počtem bloků, které chcete zachovat
```

Zachování kompletní historie entitních států:

```
indexerHints:
  prune: never
```

You can check the earliest block (with historical state) for a given subgraph by querying the [Indexing Status API](/deploying/deploying-a-subgraph-to-hosted/#checking-subgraph-health):

```
{
  indexingStatuses(subgraphs: ["Qm..."]) {
    subgraph
    synced
    health
    chains {
      earliestBlock {
        number
      }
      latestBlock {
        number
      }
      chainHeadBlock { number }
    }
  }
}
```

Note that the `earliestBlock` is the earliest block with historical data, which will be more recent than the `startBlock` specified in the manifest, if the subgraph has been pruned.

## Event Handlers

Event handlers in a subgraph react to specific events emitted by smart contracts on the blockchain and trigger handlers defined in the subgraph's manifest. This enables subgraphs to process and store event data according to defined logic.

### Defining an Event Handler

An event handler is declared within a data source in the subgraph's YAML configuration. It specifies which events to listen for and the corresponding function to execute when those events are detected.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Gravity
    network: dev
    source:
      address: '0x731a10897d267e19b34503ad902d0a29173ba4b1'
      abi: Gravity
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      entities:
        - Gravatar
        - Transaction
      abis:
        - name: Gravity
          file: ./abis/Gravity.json
      eventHandlers:
        - event: Approval(address,address,uint256)
          handler: handleApproval
        - event: Transfer(address,address,uint256)
          handler: handleTransfer
          topic1: ['0xd8dA6BF26964aF9D7eEd9e03E53415D37aA96045', '0xc8dA6BF26964aF9D7eEd9e03E53415D37aA96325'] # Optional topic filter which filters only events with the specified topic.
```

### Indexed Argument Filters / Topic Filters

> **Requires `specVersion` >= 1.2.0**

Topic filters, also known as indexed argument filters, are a powerful feature in subgraphs that allow for precise filtering of blockchain events based on the values of their indexed arguments. These filters are particularly useful for isolating specific events of interest from the vast stream of events on the blockchain, enabling subgraphs to operate more efficiently by focusing only on relevant data. This can be incredibly useful for usecases like creating personal subgraphs that track specific addresses and their interactions with various smart contracts on the blockchain.

#### How Topic Filters Work

When a smart contract emits an event, any arguments that are marked as indexed can be used as filters in a subgraph's manifest. This allows the subgraph to listen selectively for events that match these indexed arguments. The event's first indexed argument corresponds to `topic1`, the second to `topic2`, and so on, up to `topic3`, since the Ethereum Virtual Machine (EVM) allows up to three indexed arguments per event.

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

contract Token {
    // Event declaration with indexed parameters for addresses
    event Transfer(address indexed from, address indexed to, uint256 value);

    // Function to simulate transferring tokens
    function transfer(address to, uint256 value) public {
        // Emitting the Transfer event with from, to, and value
        emit Transfer(msg.sender, to, value);
    }
}
```

In this example:

- The `Transfer` event is used to log transactions of tokens between addresses.
- The `from` and `to` parameters are indexed, which allows event listeners to filter and monitor transfers involving specific addresses.
- The `transfer` function is a simple representation of a token transfer action, emitting the Transfer event whenever it is called.

#### Configuration in Subgraphs

Topic filters are defined directly within the event handler configuration in the subgraph manifest. Here is how they are configured:

```yaml
eventHandlers:
  - event: SomeEvent(indexed uint256, indexed address, indexed uint256)
    handler: handleSomeEvent
    topic1: ['0xValue1', '0xValue2']
    topic2: ['0xAddress1', '0xAddress2']
    topic3: ['0xValue3']
```

In this setup:

- `topic1` corresponds to the first indexed argument of the event, `topic2` to the second, and `topic3` to the third.
- Each topic can have one or more values, and an event is only processed if it matches one of the values in each specified topic.

##### Filter Logic

- Within a Single Topic: The logic functions as an OR condition. The event will be processed if it matches any one of the listed values in a given topic.
- Between Different Topics: The logic functions as an AND condition. An event must satisfy all specified conditions across different topics to trigger the associated handler.

### Example 1: Tracking a Single Address's Transfer Transactions

```yaml
eventHandlers:
  - event: Transfer(indexed address,indexed address,uint256)
    handler: handleTransfer
    topic1: ['0xSpecificAddress']
  - event: Transfer(indexed address,indexed address,uint256)
    handler: handleTransfer
    topic2: ['0xSpecificAddress']
```

In this configuration:

- `topic1` filters Transfer events based on the from address, and `topic2` filters based on the to address.
- The subgraph will index transactions where the specified address is involved either as a sender or a receiver.

### Example 2: Tracking Direct Transfers from Address A to Address B

```yaml
eventHandlers:
  - event: Transfer(indexed address,indexed address,uint256)
    handler: handleDirectedTransfer
    topic1: ['0xAddressA'] # Sender Address
    topic2: ['0xAddressB'] # Receiver Address
```

In this configuration:

- `topic1` is configured to filter `Transfer` events where `0xAddressA` is the sender.
- `topic2` is configured to filter `Transfer` events where `0xAddressB` is the receiver.
- The subgraph will only index transactions that occur directly from `0xAddressA` to `0xAddressB`.

### Example 3: Tracking Transactions in Either Direction Between Two Addresses

```
eventHandlers:
  - event: Transfer(indexed address,indexed address,uint256)
    handler: handleTransferToOrFrom
    topic1: ["0xAddressA"]  # Sender or Receiver Address
    topic2: ["0xAddressB"]  # Sender or Receiver Address
```

In this configuration:

- `topic1` is configured to filter `Transfer` events where `0xAddressA` is either the sender or the receiver.
- `topic2` is configured to filter `Transfer` events where `0xAddressB` is either the sender or the receiver.
- The subgraph will index transactions that occur in either direction between `0xAddressA` and `0xAddressB`, allowing for comprehensive monitoring of interactions involving both addresses.

## Zpracovatelé hovorů

Události sice představují účinný způsob, jak shromažďovat relevantní změny stavu smlouvy, ale mnoho smluv se vyhýbá generování protokolů, aby se optimalizovaly náklady na plyn. V těchto případech se dílčí graf může přihlásit k odběru volání provedených na smlouvu se zdrojem dat. Toho lze dosáhnout definováním obsluhy volání odkazující na signaturu funkce a obsluhu mapování, která bude zpracovávat volání této funkce. Pro zpracování těchto volání obdrží mapovací obsluha jako argument `ethereum.Call` s typizovanými vstupy do volání a výstupy z volání. Volání uskutečněná v libovolné hloubce řetězce volání transakce spustí mapování, což umožní zachytit aktivitu se smlouvou zdroje dat prostřednictvím proxy smluv.

Obsluhy volání se spustí pouze v jednom ze dvou případů: když je zadaná funkce volána jiným účtem než samotnou smlouvou nebo když je v Solidity označena jako externí a volána jako součást jiné funkce ve stejné smlouvě.

> **Poznámka:** Zpracovatelé volání jsou v současné době závislí na API pro sledování parity. Některé sítě, například řetězec BNB a Arbitrum, toto API nepodporují. Pokud podgraf indexující některou z těchto sítí obsahuje jeden nebo více zpracovatelů volání, nezačne se synchronizovat. Vývojáři podgrafů by místo toho měli používat obsluhy událostí. Ty jsou mnohem výkonnější než obsluhy volání a jsou podporovány v každé síti evm.

### Definice obsluhy volání

Chcete-li v manifestu definovat obsluhu volání, jednoduše přidejte pole `callHandlers` pod zdroj dat, ke kterému se chcete přihlásit.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Gravity
    network: mainnet
    source:
      address: '0x731a10897d267e19b34503ad902d0a29173ba4b1'
      abi: Gravity
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      entities:
        - Gravatar
        - Transaction
      abis:
        - name: Gravity
          file: ./abis/Gravity.json
      callHandlers:
        - function: createGravatar(string,string)
          handler: handleCreateGravatar
```

`funkce` je normalizovaná signatura funkce, podle které se filtrují volání. Vlastnost `handler` je název funkce ve vašem mapování, kterou chcete spustit při volání cílové funkce v kontraktu zdroje dat.

### Funkce mapování

Každá obslužná funkce volání přijímá jeden parametr, který má typ odpovídající názvu volané funkce. Ve výše uvedeném příkladu podgraf obsahuje mapování obslužnou rutinu pro případ, kdy je volána funkce `createGravatar` a jako argument přijímá parametr `CreateGravatarCall`:

```typescript
import { CreateGravatarCall } from '../generated/Gravity/Gravity'
import { Transaction } from '../generated/schema'

export function handleCreateGravatar(call: CreateGravatarCall): void {
  let id = call.transaction.hash
  let transaction = new Transaction(id)
  transaction.displayName = call.inputs._displayName
  transaction.imageUrl = call.inputs._imageUrl
  transaction.save()
}
```

Funkce `handleCreateGravatar` přebírá novou `CreateGravatarCall`, což je podtřída `ethereum.Call`, kterou poskytuje `@graphprotocol/graph-ts`, která obsahuje typizované vstupy a výstupy volání. Typ `CreateGravatarCall` je pro vás vygenerován při spuštění `graph codegen`.

## Obsluha bloků

Kromě přihlášení k událostem smlouvy nebo volání funkcí může podgraf chtít aktualizovat svá data, když jsou do řetězce přidány nové bloky. Za tímto účelem může podgraf spustit funkci po každém bloku nebo po blocích, které odpovídají předem definovanému filtru.

### Podporované filtry

#### Filtr volání

```yaml
filter:
  kind: call
```

_Definovat obslužná rutina bude zavolána jednou pro každý blok, který obsahuje volání smlouvy (zdroje dat), pod kterou je rutina definovát._

> **Poznámka:** Filtr `call` v současné době závisí na API pro sledování parity. Některé sítě, například řetězec BNB a Arbitrum, toto API nepodporují. Pokud podgraf indexující jednu z těchto sítí obsahuje jeden nebo více blokových manipulátorů s filtrem `call`, nezačne se synchronizovat.

Protože pro obsluhu bloku neexistuje žádný filtr, zajistí, že obsluha bude volána každý blok. Zdroj dat může obsahovat pouze jednu blokovou obsluhu pro každý typ filtru.

```yaml
dataSources:
  - kind: ethereum/contract
    name: Gravity
    network: dev
    source:
      address: '0x731a10897d267e19b34503ad902d0a29173ba4b1'
      abi: Gravity
    mapping:
      kind: ethereum/events
      apiVersion: 0.0.6
      language: wasm/assemblyscript
      entities:
        - Gravatar
        - Transaction
      abis:
        - name: Gravity
          file: ./abis/Gravity.json
      blockHandlers:
        - handler: handleBlock
        - handler: handleBlockWithCallToContract
          filter:
            kind: call
```

#### Filtr dotazování

> **Vyžaduje `specVersion`&#062 >= 0.0.8**

> **Poznámka:** Filtry zdroj dat jsou k dispozici pouze pro zdroje dat `druhu: ethereum`.

```yaml
blockHandlers:
  - handler: handleBlock
    filter:
      kind: polling
      every: 10
```

Definovaný obslužná rutina bude zavolána jednou pro každých `n` bloků, kde `n` je hodnota uvedená v poli `every`. Tato konfigurace umožňuje dílčímu graf provádět specifické operace v pravidelných intervalech bloků.

#### Jednou Filtr

> **Vyžaduje `specVersion`&#062 >= 0.0.8**

> **Poznámka:** Jednou použité filtry jsou dostupné pouze pro zdroje dat `druhu: ethereum`.

```yaml
blockHandlers:
  - handler: handleOnce
    filter:
      kind: once
```

Definovaný obslužná rutina s filtrem once bude zavolána pouze jednou před spuštěním všech ostatních rutin. Tato konfigurace umožňuje, aby podgraf používal obslužný program jako inicializační obslužný, který provádí specifické úlohy na začátku indexování.

```ts
export function handleOnce(block: ethereum.Block): void {
  let data = new InitialData(Bytes.fromUTF8('initial'))
  data.data = 'Setup data here'
  data.save()
}
```

### Funkce mapování

Funkce mapování obdrží jako jediný argument `ethereum.Block`. Stejně jako mapovací funkce pro události může tato funkce přistupovat k existujícím entitám subgrafu v úložišti, volat chytré kontrakty a vytvářet nebo aktualizovat entity.

```typescript
import { ethereum } from '@graphprotocol/graph-ts'

export function handleBlock(block: ethereum.Block): void {
  let id = block.hash
  let entity = new Block(id)
  entity.save()
}
```

## Anonymní události

Pokud potřebujete v Solidity zpracovávat anonymní události, lze toho dosáhnout zadáním tématu 0 události, jak je uvedeno v příkladu:

```yaml
eventHandlers:
  - event: LogNote(bytes4,address,bytes32,bytes32,uint256,bytes)
    topic0: '0x644843f351d3fba4abcd60109eaff9f54bac8fb8ccf0bab941009c21df21cf31'
    handler: handleGive
```

Událost se spustí pouze tehdy, když se shoduje signatura i téma 0. Ve výchozím nastavení se `téma0` rovná hash signatury události.

## Potvrzení transakcí v obslužných rutinách událostí

Počínaje `specVersion` `0.0.5` a `apiVersion` `0.0.7` mohou mít obsluhy událostí přístup k potvrzení transakce, která je vyvolala.

Za tímto účelem musí být obsluhy událostí deklarovány v manifestu podgrafů pomocí nového klíče `receipt: true`, který je nepovinný a výchozí hodnota je není pravda.

```yaml
eventHandlers:
  - event: NewGravatar(uint256,address,string,string)
    handler: handleNewGravatar
    receipt: true
```

Uvnitř obslužné funkce je příjem přístupný v poli `Event.receipt`. Pokud je klíč `receipt` nastaven na `false` nebo je v manifestu vynechán, bude místo něj vrácena hodnota `null`.

## Experimentální funkce

Počínaje `specVersion` `0.0.4` musí být funkce podgrafů explicitně deklarovány v sekci `features` na nejvyšší úrovni souboru manifestu s použitím jejich názvu `camelCase`, jak je uvedeno v následující tabulce:

| Vlastnosti                                                  | Název                                               |
| ----------------------------------------------------------- | --------------------------------------------------- |
| [Nefatální](#non-fatal-errors)                              | `nonFatalErrors`                                    |
| [Fulltextové vyhledávání](#defining-fulltext-search-fields) | `fullTextSearch`                                    |
| [Štěpování](#grafting-onto-existing-subgraphs)              | `štěpování`                                         |
| [IPFS na smlouvách Ethereum](#ipfs-on-ethereum-contracts)   | `ipfsOnEthereumContracts` or `nonDeterministicIpfs` |

Pokud například dílčí graf používá funkce **Plnotextové vyhledávání** a **Nefatální chyby**, pole ` Vlastnosti ` v manifestu by mělo být:

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
features:
  - fullTextSearch
  - nonFatalErrors
dataSources: ...
```

Všimněte si, že použití funkce bez její deklarace způsobí při nasazení podgraf chybu **validace**, ale pokud je funkce deklarována, ale není použita, k žádné chybě nedojde.

### IPFS na smlouvách Ethereum

Běžným případem použití kombinace IPFS a Ethereum je ukládání dat na IPFS, jejichž údržba v řetězci by byla příliš nákladná, a odkazování na hash IPFS v kontrakty Ethereum.

Vzhledem k těmto hashům IPFS mohou dílčí grafy číst odpovídající soubory ze IPFS pomocí `ipfs.cat` a `ipfs.map`. Aby to bylo možné spolehlivě provést, je nutné, aby tyto soubory byly připnuty k uzlu IPFS s vysokou dostupností, aby je uzel [hostované služby](https://thegraph.com/hosted-service) IPFS mohl při indexování najít.

> **Poznámka:** Síť grafů zatím nepodporuje `ipfs.cat` a `ipfs.map` a vývojáři by neměli do sítě nasazovat podgrafy využívající tyto funkce prostřednictvím Studio.

> **[Správa funkcí](#experimental-features):** `ipfsOnEthereumContracts` musí být deklarováno v podgraf manifestu pod `funkcemi`. Pro řetězce, které nejsou EVM, lze ke stejnému účelu použít také alias `nonDeterministicIpfs`.

Při spuštění místního uzlu Graf Uzel musí být nastavena proměnná prostředí `GRAPH_ALLOW_NON_DETERMINISTIC_IPFS`, aby bylo možné indexovat podgrafy pomocí této í funkce.

### Nefatální

Chyby indexování v již synchronizovaných podgrafech ve výchozím nastavení způsobí selhání podgrafy a zastavení synchronizace. Podgrafy lze alternativně nakonfigurovat tak, aby pokračovaly v synchronizaci i při přítomnosti chyb, a to ignorováním změn provedených obslužnou rutinou, která chybu vyvolala. To dává autorům podgrafů čas na opravu jejich podgrafů, zatímco dotazy jsou nadále obsluhovány proti poslednímu bloku, ačkoli výsledky mohou být nekonzistentní kvůli chybě, která chybu způsobila. Všimněte si, že některé chyby jsou stále fatální. Aby chyba nebyla fatální, musí být známo, že je deterministická.

> **Poznámka:** Síť grafů zatím nepodporuje nefatální chyby a vývojáři by neměli do sítě nasazovat podgrafy využívající tuto funkci prostřednictvím Studio.

Povolení nefatálních chyb vyžaduje nastavení následujícího příznaku funkce v manifestu podgraf:

```yaml
specVersion: 0.0.4
description: Gravatar for Ethereum
features:
    - nonFatalErrors
    ...
```

Dotaz se také musí přihlásit k dotazování na data s potenciálními nekonzistencemi prostřednictvím argumentu `subgraphError`. Doporučuje se také dotazovat se pomocí `_meta`, aby bylo možné zkontrolovat, zda podgraf nepřeskočil chyby, jako v příkladu:

```graphql
foos(first: 100, subgraphError: allow) {
  id
}

_meta {
  hasIndexingErrors
}
```

Pokud podgraf narazí na chybu, vrátí tento dotaz jak data, tak chybu graphql se zprávou `"indexing_error"`, jako v tomto příkladu odpovědi:

```graphql
"data": {
    "foos": [
        {
          "id": "0xdead"
        }
    ],
    "_meta": {
        "hasIndexingErrors": true
    }
},
"errors": [
    {
        "message": "indexing_error"
    }
]
```

### Roubování na existující podgrafy

> **Poznámka:** při počátečním upgrade na Síť graf se nedoporučuje používat roubování. Více informací se dozvíte [zde](/cookbook/grafting/#important-note-on-grafting-when-upgrading-to-the-network).

Při prvním nasazení podgrafu se události začnou indexovat v bloku geneze příslušného řetězce (nebo v bloku `startBlock` definovaném u každého zdroje dat). Za určitých okolností je výhodné znovu použít data z existujícího podgrafu a začít indexovat v mnohem pozdějším bloku. Tento způsob indexování se nazývá _roubování_. roubování je užitečné například během vývoje, abyste se rychle dostali přes jednoduché chyby v mapování nebo abyste dočasně znovu zprovoznili existující podgraf poté, co selhal.

Podgraf je naroubován na základní podgraf, pokud manifest podgrafu v souboru `subgraph.yaml` obsahuje blok `graft` na nejvyšší úrovni:

```yaml
description: ...
graft:
  base: Qm... # Subgraph ID of base subgraph
  block: 7345624 # Block number
```

Když je nasazen podgraf, jehož manifest obsahuje blok `graft`, Graf Uzel zkopíruje data `základního` podgrafu až do daného `bloku` včetně a poté pokračujte v indexování nového podgrafu od tohoto bloku dále. Základní podgraf musí existovat v cílové instanci Graph Node a musí být indexován alespoň do daného bloku. Kvůli tomuto omezení by se roubování mělo používat pouze během vývoje nebo během nouzového stavu, aby se urychlila tvorba ekvivalentního neroubovaného podgrafu.

Protože se při roubování základní data spíše kopírují než indexují, je mnohem rychlejší dostat podgraf do požadovaného bloku než při indexování od nuly, i když počáteční kopírování dat může u velmi velkých podgrafů trvat i několik hodin. Během inicializace roubovaného podgrafu bude uzel Graf Uzel zaznamenávat informace o typů entit, které již byly zkopírovány.

Roubované podgraf může používat schéma GraphQL, které není totožné se schématem základního podgrafu, ale je s ním pouze kompatibilní. Musí to být platné schéma podgrafu jako takové, ale může se od schématu základního podgrafu odchýlit následujícími způsoby:

- Přidává nebo odebírá typy entit
- Odstraňuje atributy z typů entit
- Přidává nulovatelné atributy k typům entit
- Mění nenulovatelné atributy na nulovatelné atributy
- Přidává hodnoty de enums
- Přidává nebo odebírá rozhraní
- Mění se, pro které typy entit je rozhraní implementováno

> **[Feature Management](#experimental-features):** `grafting` musí být deklarováno v `features` v manifestu podgrafů.

## Zdroje dat souborů

Zdroje dat souborů jsou novou funkcí podgrafu pro přístup k datům mimo řetězec během indexování robustním a rozšiřitelným způsobem. Zdroje souborových dat podporují načítání souborů ze systému IPFS a z Arweave.

> To také vytváří základ pro deterministické indexování dat mimo řetězec a potenciální zavedení libovolných dat ze zdrojů HTTP.

### Přehled

Namísto načítání souborů "in line" během provádění obslužných rutin se zavádějí šablony, které lze spouštět jako nové zdroje dat pro daný identifikátor souboru. Tyto nové zdroje dat načítají soubory a v případě neúspěchu se pokoušejí o opětovné načtení a po nalezení souboru spustí vyhrazenou obslužnou rutinu.

This is similar to the [existing data source templates](/developing/creating-a-subgraph/#data-source-templates), which are used to dynamically create new chain-based data sources.

> Nahrazuje stávající API `ipfs.cat`

### Průvodce upgradem

#### Aktualizace `graph-ts` a `graph-cli`

Souborové zdroje dat vyžadují graph-ts >=0.29.0 a graph-cli >=0.33.1

#### Přidání nového typu entity, který bude aktualizován při nalezení souborů

Zdroje dat souborů nemohou přistupovat k entitám založeným na řetězci ani je aktualizovat, ale musí aktualizovat entity specifické pro soubor.

To může znamenat rozdělení polí ze stávajících entit do samostatných entit, které budou vzájemně propojeny.

Původní kombinovaný entita:

```graphql
type Token @entity {
  id: ID!
  tokenID: BigInt!
  tokenURI: String!
  externalURL: String!
  ipfsURI: String!
  image: String!
  name: String!
  description: String!
  type: String!
  updatedAtTimestamp: BigInt
  owner: User!
}
```

Nové, rozdělená entit:

```graphql
type Token @entity {
  id: ID!
  tokenID: BigInt!
  tokenURI: String!
  ipfsURI: TokenMetadata
  updatedAtTimestamp: BigInt
  owner: String!
}

type TokenMetadata @entity {
  id: ID!
  image: String!
  externalURL: String!
  name: String!
  description: String!
}
```

Pokud je vztah mezi nadřazenou entitou a entitou výsledného zdroje dat souboru 1:1, je nejjednodušším vzorem propojení nadřazené entity s entitou výsledného souboru pomocí CID IPFS jako vyhledávacího prvku. Pokud máte potíže s modelováním nových entit založených na souborech, ozvěte se na Discord!

> You can use [nested filters](/querying/graphql-api/#example-for-nested-entity-filtering) to filter parent entities on the basis of these nested entities.

#### Přidání nového šablony zdroje dat s `druhem: file/ipfs` nebo `druhem: file/arweave`

Jedná se o zdroj dat, který bude vytvořen při identifikaci souboru zájmu.

```yaml
templates:
  - name: TokenMetadata
    kind: file/ipfs
    mapping:
      apiVersion: 0.0.7
      language: wasm/assemblyscript
      file: ./src/mapping.ts
      handler: handleMetadata
      entities:
        - TokenMetadata
      abis:
        - name: Token
          file: ./abis/Token.json
```

> V současné době jsou vyžadovány `abis`, ačkoli není možné volat smlouvy ze zdrojů dat souborů

The file data source must specifically mention all the entity types which it will interact with under `entities`. See [limitations](#limitations) for more details.

#### Vytvoření nové obslužné pro zpracování souborů

This handler should accept one `Bytes` parameter, which will be the contents of the file, when it is found, which can then be processed. This will often be a JSON file, which can be processed with `graph-ts` helpers ([documentation](/developing/assemblyscript-api/#json-api)).

CID souboru jako čitelný řetězec lze získat prostřednictvím `dataSource` následujícím způsobem:

```typescript
const cid = dataSource.stringParam()
```

Příklad

```typescript
import { json, Bytes, dataSource } from '@graphprotocol/graph-ts'
import { TokenMetadata } from '../generated/schema'

export function handleMetadata(content: Bytes): void {
  let tokenMetadata = new TokenMetadata(dataSource.stringParam())
  const value = json.fromBytes(content).toObject()
  if (value) {
    const image = value.get('image')
    const name = value.get('name')
    const description = value.get('description')
    const externalURL = value.get('external_url')

    if (name && image && description && externalURL) {
      tokenMetadata.name = name.toString()
      tokenMetadata.image = image.toString()
      tokenMetadata.externalURL = externalURL.toString()
      tokenMetadata.description = description.toString()
    }

    tokenMetadata.save()
  }
}
```

#### Spawn zdrojů dat souborů v případě potřeby

Nyní můžete vytvářet zdroje dat souborů během provádění obslužných založených na řetězci:

- Import šablony z automaticky generovaných `šablon`
- volání `TemplateName.create(cid: string)` z mapování, kde cid je platný identifikátor obsahu pro IPFS nebo Arweave

Pro systém IPFS podporuje Graf Uzel identifikátory obsahu [v0 a v1](https://docs.ipfs.tech/concepts/content-addressing/) a identifikátory obsahu s adresáři (např. `bafyreighykzv2we26wfrbzkcdw37sbrby4upq7ae3aqobbq7i4er3tnxci/metadata.json`).

For Arweave, as of version 0.33.0 Graph Node can fetch files stored on Arweave based on their [transaction ID](https://docs.arweave.org/developers/arweave-node-server/http-api#transactions) from an Arweave gateway ([example file](https://bdxujjl5ev5eerd5ouhhs6o4kjrs4g6hqstzlci5pf6vhxezkgaa.arweave.net/CO9EpX0lekJEfXUOeXncUmMuG8eEp5WJHXl9U9yZUYA)). Arweave supports transactions uploaded via Irys (previously Bundlr), and Graph Node can also fetch files based on [Irys manifests](https://docs.irys.xyz/overview/gateways#indexing).

Příklad:

```typescript
import { TokenMetadata as TokenMetadataTemplate } from '../generated/templates'

const ipfshash = 'QmaXzZhcYnsisuue5WRdQDH6FDvqkLQX1NckLqBYeYYEfm'
//This example code is for a Crypto coven subgraph. The above ipfs hash is a directory with token metadata for all crypto coven NFTs.

export function handleTransfer(event: TransferEvent): void {
  let token = Token.load(event.params.tokenId.toString())
  if (!token) {
    token = new Token(event.params.tokenId.toString())
    token.tokenID = event.params.tokenId

    token.tokenURI = '/' + event.params.tokenId.toString() + '.json'
    const tokenIpfsHash = ipfshash + token.tokenURI
    //This creates a path to the metadata for a single Crypto coven NFT. It concats the directory with "/" + filename + ".json"

    token.ipfsURI = tokenIpfsHash

    TokenMetadataTemplate.create(tokenIpfsHash)
  }

  token.updatedAtTimestamp = event.block.timestamp
  token.owner = event.params.to.toHexString()
  token.save()
}
```

Tím se vytvoří nový zdroj dat souborů, který bude dotazovat nakonfigurovaný koncový bod IPFS nebo Arweave grafického uzlu a v případě nenalezení se pokusí o opakování. Když je soubor nalezen, spustí se obslužná zdroje dat souboru.

Tento příklad používá CID jako vyhledávání mezi nadřazenou entitou `Token` a výslednou entitou `TokenMetadata`.

> Dříve by vývojář podgrafu zavolal `ipfs.cat(CID)` a načetl by soubor

Gratulujeme, používáte souborové zdroje dat!

#### Nasazení podgrafů

Nyní můžete `sestavit` a `rozšířit` svůj podgraf do libovolného uzlu Graf >=v0.30.0-rc.0.

#### Omezení

Zpracovatelé a entity zdrojů dat souborů jsou izolovány od ostatních entit podgrafů, což zajišťuje, že jsou při provádění deterministické a nedochází ke kontaminaci zdrojů dat založených na řetězci. Přesněji řečeno:

- Entity vytvořené souborovými zdroji dat jsou neměnné a nelze je aktualizovat
- Obsluhy zdrojů dat souborů nemohou přistupovat k entita z jiných zdrojů dat souborů
- K entita přidruženým k datovým zdrojům souborů nelze přistupovat pomocí zpracovatelů založených na řetězci

> Ačkoli by toto omezení nemělo být pro většinu případů použití problematické, pro některé může představovat složitost. Pokud máte problémy s modelováním dat založených na souborech v podgrafu, kontaktujte nás prosím prostřednictvím služby Discord!

Kromě toho není možné vytvářet zdroje dat ze zdroje dat souborů, ať už se jedná o zdroj dat v řetězci nebo jiný zdroj dat souborů. Toto omezení může být v budoucnu zrušeno.

#### Osvědčené postupy

Pokud propojovat metadata NFT s odpovídajícími tokeny, použijte hash IPFS metadat k odkazu na entita Metadata z entity Token. Uložte entitu Metadata s použitím hashe IPFS jako ID.

You can use [DataSource context](/developing/graph-ts/api/#entity-and-datasourcecontext) when creating File Data Sources to pass extra information which will be available to the File Data Source handler.

Pokud máte entity, které se obnovují vícekrát, vytvořte jedinečné entity založené na souborech pomocí hash & IPFS; ID entity a odkazujte na ně pomocí odvozeného pole v entitě založené na řetězci.

> Pracujeme na zlepšení výše uvedeného doporučení, aby dotazy vracely pouze "nejnovější" verzi

#### Známé problémy

Souborové zdroje dat v současné době vyžadují ABI, i když se ABI nepoužívá ([problém](https://github.com/graphprotocol/graph-cli/issues/961)). Řešením je přidání libovolného ABI.

Handlers for File Data Sources cannot be in files which import `eth_call` contract bindings, failing with "unknown import: `ethereum::ethereum.call` has not been defined" ([issue](https://github.com/graphprotocol/graph-node/issues/4309)). Workaround is to create file data source handlers in a dedicated file.

#### Příklady

[Migrace podgrafů Crypto Coven](https://github.com/azf20/cryptocoven-api/tree/file-data-sources-refactor)

#### Odkazy:

[Zdroje dat souborů GIP](https://forum.thegraph.com/t/gip-file-data-sources/2721)

## Timeseries and Aggregations

### Přehled

Timeseries and aggregations enable your subgraph to track statistics like daily average price, hourly total transfers, etc.

This feature introduces two new types of subgraph entity. Timeseries entities record data points with timestamps. Aggregation entities perform pre-declared calculations on the Timeseries data points on an hourly or daily basis, then store the results for easy access via GraphQL.

#### Example Schema

```graphql
type Data @entity(timeseries: true) {
  id: Int8!
  timestamp: Timestamp!
  price: BigDecimal!
}

type Stats @aggregation(intervals: ["hour", "day"], source: "Data") {
  id: Int8!
  timestamp: Timestamp!
  sum: BigDecimal! @aggregate(fn: "sum", arg: "price")
}
```

### Defining Timeseries and Aggregations

Timeseries entities are defined with `@entity(timeseries: true)` in schema.graphql. Every timeseries entity must have a unique ID of the int8 type, a timestamp of the Timestamp type, and include data that will be used for calculation by aggregation entities. These Timeseries entities can be saved in regular trigger handlers, and act as the “raw data” for the Aggregation entities.

Aggregation entities are defined with `@aggregation` in schema.graphql. Every aggregation entity defines the source from which it will gather data (which must be a Timeseries entity), sets the intervals (e.g., hour, day), and specifies the aggregation function it will use (e.g., sum, count, min, max, first, last). Aggregation entities are automatically calculated on the basis of the specified source at the end of the required interval.

#### Available Aggregation Intervals

- `hour`: sets the timeseries period every hour, on the hour.
- `day`: sets the timeseries period every day, starting and ending at 00:00.

#### Available Aggregation Functions

- `sum`: Total of all values.
- `count`: Number of values.
- `min`: Minimum value.
- `max`: Maximum value.
- `first`: First value in the period.
- `last`: Last value in the period.

#### Example Aggregations Query

```graphql
{
  stats(interval: "hour", where: { timestamp_gt: 1704085200 }) {
    id
    timestamp
    sum
  }
}
```

Note:

To use Timeseries and Aggregations, a subgraph must have a spec version ≥1.1.0. Note that this feature might undergo significant changes that could affect backward compatibility.

[Read more](https://github.com/graphprotocol/graph-node/blob/master/docs/aggregations.md) about Timeseries and Aggregations.

---
title: Graph-Knoten
---

Graph Node ist die Komponente, die Subgraphen indiziert und die daraus resultierenden Daten zur Abfrage über eine GraphQL-API bereitstellt. Als solche ist sie ein zentraler Bestandteil des Indexer-Stacks, und der korrekte Betrieb von Graph Node ist entscheidend für den erfolgreichen Betrieb eines Indexers.

Dies bietet einen kontextbezogenen Überblick über Graph Node und einige der erweiterten Optionen, die Indexern zur Verfügung stehen. Ausführliche Dokumentation und Anleitungen finden Sie im [Graph Node repository](https://github.com/graphprotocol/graph-node).

## Graph-Knoten

[Graph Node] (https://github.com/graphprotocol/graph-node) ist die Referenzimplementierung für die Indizierung von Subgraphen auf The Graph Network, die Verbindung zu Blockchain-Clients, die Indizierung von Subgraphen und die Bereitstellung indizierter Daten für Abfragen.

Graph Node (und der gesamte Indexer-Stack) kann sowohl auf Bare Metal als auch in einer Cloud-Umgebung betrieben werden. Diese Flexibilität der zentralen Indexer-Komponente ist entscheidend für die Robustheit von The Graph Protocol. Ebenso kann Graph Node [aus dem Quellcode gebaut] werden (https://github.com/graphprotocol/graph-node), oder Indexer können eines der [bereitgestellten Docker Images] verwenden (https://hub.docker.com/r/graphprotocol/graph-node).

### PostgreSQL-Datenbank

Der Hauptspeicher für den Graph Node. Hier werden die Subgraph-Daten, Metadaten über Subgraphs und Subgraph-agnostische Netzwerkdaten wie der Block-Cache und der eth_call-Cache gespeichert.

### Netzwerk-Clients

Um ein Netzwerk zu indizieren, benötigt Graph Node Zugriff auf einen Netzwerk-Client über einen EVM-kompatiblen JSON-RPC API. Dieser RPC kann sich mit einem einzelnen Client verbinden oder es könnte sich um ein komplexeres Setup handeln, das die Last auf mehrere verteilt.

Während einige Subgraphen nur einen vollständigen Knoten benötigen, können einige Indizierungsfunktionen haben, die zusätzliche RPC-Funktionalität erfordern. Insbesondere Subgraphen, die `eth_calls` als Teil der Indizierung machen, benötigen einen Archivknoten, der [EIP-1898](https://eips.ethereum.org/EIPS/eip-1898) unterstützt, und Subgraphen mit `callHandlers` oder `blockHandlers` mit einem `call`-Filter benötigen `trace_filter`-Unterstützung ([siehe Trace-Modul-Dokumentation hier](https://openethereum.github.io/JSONRPC-trace-module)).

**Network Firehoses** - ein Firehose ist ein gRPC-Dienst, der einen geordneten, aber forkfähigen Strom von Blöcken bereitstellt, der von den Kernentwicklern von The Graph entwickelt wurde, um eine performante Indexierung in großem Umfang zu unterstützen. Dies ist derzeit keine Voraussetzung für Indexer, aber Indexer werden ermutigt, sich mit dieser Technologie vertraut zu machen, bevor die volle Netzwerkunterstützung zur Verfügung steht. Erfahren Sie mehr über den Firehose [hier](https://firehose.streamingfast.io/).

### IPFS-Knoten

Die Metadaten für den Einsatz von Subgraphen werden im IPFS-Netzwerk gespeichert. Der Graph Node greift während des Einsatzes von Subgraphen primär auf den IPFS-Knoten zu, um das Subgraphen-Manifest und alle verknüpften Dateien abzurufen. Netzwerkindizierer müssen keinen eigenen IPFS-Knoten hosten. Ein IPFS-Knoten für das Netzwerk wird auf https://ipfs.thegraph.com gehostet.

### Prometheus-Metrikserver

Um Überwachung und Berichterstellung zu ermöglichen, kann Graph Node optional Metriken auf einem Prometheus-Metrikserver protokollieren.

### Einstieg in den Sourcecode

#### Installieren Sie die Voraussetzungen

- **Rust**

- **PostgreSQL**

- **IPFS**

- **Zusätzliche Anforderungen für Ubuntu-Benutzer** - Um einen Graph Node unter Ubuntu zu betreiben, sind möglicherweise einige zusätzliche Pakete erforderlich.

```sh
sudo apt-get install -y clang libpg-dev libssl-dev pkg-config
```

#### Konfiguration

1. Starten Sie einen PostgreSQL-Datenbankserver

```sh
initdb -D .postgres
pg_ctl -D .postgres -l logfile start
createdb graph-node
```

2. Klonen Sie das [Graph-Knoten](https://github.com/graphprotocol/graph-node)-Repo und erstellen Sie den Sourcecode durch Ausführen von `cargo build`

3. Nachdem alle Abhängigkeiten eingerichtet sind, starten Sie den Graph Node:

```sh
cargo run -p graph-node --release -- \
  --postgres-url postgresql://[USERNAME]:[PASSWORD]@localhost:5432/graph-node \
  --ethereum-rpc [NETWORK_NAME]:[URL] \
  --ipfs https://ipfs.thegraph.com
```

### Erste Schritte mit Kubernetes

Eine vollständige Datenbeispiel-Konfiguration für Kubernetes ist im [indexer repository](https://github.com/graphprotocol/indexer/tree/main/k8s) zu finden.

### Ports

Wenn es ausgeführt wird, stellt Graph Node die folgenden Ports zur Verfügung:

| Port | Verwendungszweck | Routen | CLI-Argument | Umgebungsvariable |
| --- | --- | --- | --- | --- |
| 8000 | GraphQL HTTP Server<br />(für Subgraph-Abfragen) | /subgraphs/id/...<br />/subgraphs/name/.../... | \--http-port | - |
| 8001 | GraphQL WS<br />(für Subgraphen-Abonnements) | /subgraphs/id/...<br />/subgraphs/name/.../... | \--ws-port | - |
| 8020 | JSON-RPC<br />(zum Verwalten von Deployments) | / | \--admin-port | - |
| 8030 | Status der Indizierung von Subgraphen API | /graphql | \--index-node-port | - |
| 8040 | Prometheus-Metriken | /metrics | \--metrics-port | - |

> **Wichtig**: Seien Sie vorsichtig damit, Ports öffentlich zugänglich zu machen - **Verwaltungsports** sollten unter Verschluss gehalten werden. Dies gilt auch für den Graph Node JSON-RPC Endpunkt.

## Erweiterte Graph-Knoten-Konfiguration

In seiner einfachsten Form kann Graph Node mit einer einzelnen Instanz von Graph Node, einer einzelnen PostgreSQL-Datenbank, einem IPFS-Knoten und den Netzwerk-Clients betrieben werden, die für die zu indizierenden Subgraphen erforderlich sind.

Dieses Setup kann horizontal skaliert werden, indem mehrere Graph Nodes und mehrere Datenbanken zur Unterstützung dieser Graph Nodes hinzugefügt werden. Fortgeschrittene Benutzer möchten vielleicht einige der horizontalen Skalierungsmöglichkeiten von Graph Node sowie einige der erweiterten Konfigurationsoptionen über die Datei „config.toml“ und die Umgebungsvariablen von Graph Node nutzen.

### `config.toml`

Eine [TOML](https://toml.io/en/)-Konfigurationsdatei kann verwendet werden, um komplexere Konfigurationen als die in der Befehlszeile angezeigten festzulegen. Der Speicherort der Datei wird mit dem Befehlszeilenschalter --config übergeben.

> Bei Verwendung einer Konfigurationsdatei ist es nicht möglich, die Optionen --postgres-url, --postgres-secondary-hosts und --postgres-host-weights zu verwenden.

Eine minimale `config.toml`-Datei kann angegeben werden; die folgende Datei entspricht der Verwendung der Befehlszeilenoption --postgres-url:

```toml
[store]
[store.primary]
connection="<.. postgres-url argument ..>"
[deployment]
[[deployment.rule]]
indexers = [ "<.. list of all indexing nodes ..>" ]
```

Eine vollständige Dokumentation von `config.toml` findet sich in den [Graph Node docs](https://github.com/graphprotocol/graph-node/blob/master/docs/config.md).

#### Mehrere Graph-Knoten

Die Indizierung von Graph Node kann horizontal skaliert werden, indem mehrere Instanzen von Graph Node ausgeführt werden, um die Indizierung und Abfrage auf verschiedene Knoten aufzuteilen. Dies kann einfach durch die Ausführung von Graph Nodes erfolgen, die beim Start mit einer anderen `node_id` konfiguriert werden (z. B. in der Docker Compose-Datei). Diese kann dann in der Datei `config.toml` verwendet werden, um [dedizierte Abfrageknoten](#dedicated-query-nodes), [Block-Ingestoren](#dedicated-block-ingestion) und die Aufteilung von Subgraphen über Knoten mit [Einsatzregeln](#deployment-rules) zu spezifizieren.

> Beachten Sie darauf, dass mehrere Graph-Knoten so konfiguriert werden können, dass sie dieselbe Datenbank verwenden, die ihrerseits durch Sharding horizontal skaliert werden kann.

#### Bereitstellungsregeln

Bei mehreren Graph-Knoten ist es notwendig, den Einsatz von neuen Subgraphen zu verwalten, damit derselbe Subgraph nicht von zwei verschiedenen Knoten indiziert wird, was zu Kollisionen führen würde. Dies kann durch die Verwendung von Einsatzregeln geschehen, die auch angeben können, in welchem „Shard“ die Daten eines Subgraphen gespeichert werden sollen, wenn ein Datenbank-Sharding verwendet wird. Einsatzregeln können den Namen des Subgraphen und das Netzwerk, das der Einsatz indiziert, abgleichen, um eine Entscheidung zu treffen.

Example deployment rule configuration:

```toml
[deployment]
[[deployment.rule]]
match = { name = „(vip|important)/.*“ }
shard = „vip“
indexers = [ „index_node_vip_0“, „index_node_vip_1“ ]
[[deployment.rule]]
match = { network = „kovan“ }
# Kein Shard, also verwenden wir den Standard-Shard namens 'primary'
indexers = [ „index_node_kovan_0“ ]
[[deployment.rule]]
match = { network = [ „xdai“, „poa-core“ ] }
indexers = [ „index_node_other_0“ ]
[[deployment.rule]]
# Es gibt kein 'match', also passt jeder Subgraph
shards = [ „sharda“, „shardb“ ]
indexers = [
    „index_node_community_0“,
    „index_node_community_1“, [ ‚index_node_community_1‘,
    „index_node_community_2“,
    „index_node_community_3“,
    „index_node_community_4“,
    „index_node_community_5“
  ]
```

Lesen Sie mehr über die Einsatzregeln [hier] (https://github.com/graphprotocol/graph-node/blob/master/docs/config.md#controlling-deployment).

#### Dedizierte Abfrageknoten

Knoten können explizit als Abfrageknoten konfiguriert werden, indem Sie Folgendes in die Konfigurationsdatei aufnehmen:

```toml
[general]
query = "<regular expression>"
```

Jeder Knoten, dessen --node-id mit dem regulären Ausdruck übereinstimmt, wird so eingerichtet, dass er nur auf Abfragen antwortet.

#### Datenbankskalierung durch Sharding

Für die meisten Anwendungsfälle reicht eine einzelne Postgres-Datenbank aus, um eine Graph-Node-Instanz zu unterstützen. Wenn eine Graph-Node-Instanz aus einer einzelnen Postgres-Datenbank herauswächst, ist es möglich, die Speicherung der Daten des Graph-Nodes auf mehrere Postgres-Datenbanken aufzuteilen. Alle Datenbanken zusammen bilden den Speicher der Graph-Node-Instanz. Jede einzelne Datenbank wird als Shard bezeichnet.

Shards können verwendet werden, um Subgraph-Einsätze auf mehrere Datenbanken aufzuteilen, und sie können auch verwendet werden, um Replikate zu verwenden, um die Abfragelast auf die Datenbanken zu verteilen. Dazu gehört auch die Konfiguration der Anzahl der verfügbaren Datenbankverbindungen, die jeder „Graph-Knoten“ in seinem Verbindungspool für jede Datenbank vorhalten soll, was zunehmend wichtiger wird, je mehr Subgraphen indiziert werden.

Sharding wird nützlich, wenn Ihre vorhandene Datenbank nicht mit der Last Schritt halten kann, die Graph Node ihr auferlegt, und wenn es nicht mehr möglich ist, die Datenbankgröße zu erhöhen.

> Im Allgemeinen ist es besser, eine einzelne Datenbank so groß wie möglich zu machen, bevor man mit Shards beginnt. Eine Ausnahme ist, wenn der Abfrageverkehr sehr ungleichmäßig auf die Subgraphen verteilt ist; in solchen Situationen kann es sehr hilfreich sein, wenn die hochvolumigen Subgraphen in einem Shard und alles andere in einem anderen aufbewahrt wird, weil es dann wahrscheinlicher ist, dass die Daten für die hochvolumigen Subgraphen im db-internen Cache verbleiben und nicht durch Daten ersetzt werden, die von den niedrigvolumigen Subgraphen nicht so häufig benötigt werden.

Was das Konfigurieren von Verbindungen betrifft, beginnen Sie mit max_connections in postgresql.conf, das auf 400 (oder vielleicht sogar 200) eingestellt ist, und sehen Sie sich die Prometheus-Metriken store_connection_wait_time_ms und store_connection_checkout_count an. Spürbare Wartezeiten (alles über 5 ms) sind ein Hinweis darauf, dass zu wenige Verbindungen verfügbar sind; hohe Wartezeiten werden auch dadurch verursacht, dass die Datenbank sehr ausgelastet ist (z. B. hohe CPU-Last). Wenn die Datenbank jedoch ansonsten stabil erscheint, weisen hohe Wartezeiten darauf hin, dass die Anzahl der Verbindungen erhöht werden muss. In der Konfiguration ist die Anzahl der Verbindungen, die jede Graph-Knoten-Instanz verwenden kann, eine Obergrenze, und der Graph-Knoten hält Verbindungen nicht offen, wenn er sie nicht benötigt.

Lesen Sie mehr über Lesen Sie [hier] mehr über die Store-Konfiguration [hier] (https://github.com/graphprotocol/graph-node/blob/master/docs/config.md#configuring-multiple-databases).

#### Dedizierte Blockaufnahme

Wenn mehrere Knoten konfiguriert sind, muss ein Knoten angegeben werden, der für die Aufnahme neuer Blöcke verantwortlich ist, damit nicht alle konfigurierten Indexer-Knoten den Kettenkopf abfragen. Dies geschieht als Teil des `chains`-Namensraumes, indem die `node_id` angegeben wird, die für die Aufnahme von Blöcken verwendet werden soll:

```toml
[chains]
ingestor = "block_ingestor_node"
```

#### Unterstützung mehrerer Netzwerke

Das Graph Protocol erhöht die Anzahl der Netzwerke, die für die Indizierung von Belohnungen unterstützt werden, und es gibt viele Subgraphen, die nicht unterstützte Netzwerke indizieren, die ein Indexer gerne verarbeiten würde. Die Datei `config.toml` ermöglicht eine ausdrucksstarke und flexible Konfiguration von:

- Mehrere Netzwerke
- Mehrere Anbieter pro Netzwerk (dies kann eine Aufteilung der Last auf Anbieter ermöglichen und kann auch die Konfiguration von vollständigen Knoten sowie Archivknoten ermöglichen, wobei Graph Node günstigere Anbieter bevorzugt, wenn eine bestimmte Arbeitslast dies zulässt).
- Zusätzliche Anbieterdetails, wie Funktionen, Authentifizierung und Anbietertyp (für experimentelle Firehose-Unterstützung)

Der Abschnitt `[chains]` steuert die Ethereum-Provider, mit denen sich graph-node verbindet, und wo Blöcke und andere Metadaten für jede Kette gespeichert werden. Das folgende Datenbeispiel konfiguriert zwei Ketten, Mainnet und Kovan, wobei die Blöcke für mainnet im vip-Shard und die Blöcke für kovan im primary-Shard gespeichert werden. Die Mainnet-Kette kann zwei verschiedene Anbieter verwenden, während Kovan nur einen Anbieter hat.

```toml
[chains]
ingestor = "block_ingestor_node"
[chains.mainnet]
shard = "vip"
provider = [
  { label = "mainnet1", url = "http://..", features = [], headers = { Authorization = "Bearer foo" } },
  { label = "mainnet2", url = "http://..", features = [ "archive", "traces" ] }
]
[chains.kovan]
shard = "primary"
provider = [ { label = "kovan", url = "http://..", features = [] } ]
```

Lesen Sie mehr über die Providerkonfiguration [hier] (https://github.com/graphprotocol/graph-node/blob/master/docs/config.md#configuring-ethereum-providers).

### Umgebungsvariablen

Graph Node unterstützt eine Reihe von Umgebungsvariablen, die Funktionen aktivieren oder das Verhalten von Graph Node ändern können. Diese sind [hier] dokumentiert (https://github.com/graphprotocol/graph-node/blob/master/docs/environment-variables.md).

### Kontinuierlicher Einsatz

Benutzer, die ein skaliertes Indizierungs-Setup mit erweiterter Konfiguration betreiben, können von der Verwaltung ihrer Graph-Knoten mit Kubernetes profitieren.

- Das Indexer-Repository hat eine [Beispiel-Kubernetes-Referenz](https://github.com/graphprotocol/indexer/tree/main/k8s)
- [Launchpad] (https://docs.graphops.xyz/launchpad/intro) ist ein Toolkit für den Betrieb eines Graph Protocol Indexer auf Kubernetes, das von GraphOps gepflegt wird. Es bietet eine Reihe von Helm-Diagrammen und eine CLI zur Verwaltung eines Graph Node- Deployments.

### Verwaltung von Graph Knoten

Bei einem laufenden Graph Node (oder Graph Nodes!) besteht die Herausforderung darin, die eingesetzten Subgraphen über diese Nodes hinweg zu verwalten. Graph Node bietet eine Reihe von Tools, die bei der Verwaltung von Subgraphen helfen.

#### Protokollierung

Die Protokolle von Graph Node können nützliche Informationen zur Fehlersuche und Optimierung von Graph Node und bestimmten Untergraphen liefern. Graph Node unterstützt verschiedene Log-Ebenen über die Umgebungsvariable `GRAPH_LOG`, mit den folgenden Ebenen: error, warn, info, debug oder trace.

Wenn Sie außerdem `GRAPH_LOG_QUERY_TIMING` auf `gql` setzen, erhalten Sie mehr Details darüber, wie GraphQL-Abfragen ausgeführt werden (allerdings wird dadurch eine große Menge an Protokollen erzeugt).

#### Überwachung und Alarmierung

Graph Node stellt die Metriken standardmäßig durch den Prometheus-Endpunkt am Port 8040 bereit. Grafana kann dann zur Visualisierung dieser Metriken verwendet werden.

Das Indexer Repository bietet eine [Beispiel-Grafana-Konfiguration](https://github.com/graphprotocol/indexer/blob/main/k8s/base/grafana.yaml).

#### Graphman

`graphman` ist ein Wartungswerkzeug für Graph Node, das bei der Diagnose und Lösung verschiedener alltäglicher und außergewöhnlicher Aufgaben hilft.

Der Befehl graphman ist in den offiziellen Containern enthalten, und Sie können ihn mit docker exec in Ihrem graph-node-Container ausführen. Er erfordert eine Datei `config.toml`.

Eine vollständige Dokumentation der `graphman`-Befehle ist im Graph Node Repository verfügbar. Siehe [/docs/graphman.md] (https://github.com/graphprotocol/graph-node/blob/master/docs/graphman.md) im Graph Node `/docs`

### Arbeiten mit Subgraphen

#### Indizierungsstatus-API

Die API für den Indizierungsstatus ist standardmäßig an Port 8030/graphql verfügbar und bietet eine Reihe von Methoden zur Überprüfung des Indizierungsstatus für verschiedene Subgraphen, zur Überprüfung von Indizierungsnachweisen, zur Inspektion von Subgraphen-Features und mehr.

Das vollständige Schema ist [hier] verfügbar (https://github.com/graphprotocol/graph-node/blob/master/server/index-node/src/schema.graphql).

#### Indizierungsleistung

Es gibt drei separate Teile des Indizierungsprozesses:

- Abrufen von interessanten Ereignissen vom Anbieter
- Verarbeiten von Ereignissen in der Reihenfolge mit den entsprechenden Handlern (dies kann das Aufrufen der Kette für den Zustand und das Abrufen von Daten aus dem Speicher beinhalten)
- Schreiben der Ergebnisdaten in den Speicher

Diese Phasen sind in einer Pipeline angeordnet (d.h. sie können parallel ausgeführt werden), aber sie sind voneinander abhängig. Wenn die Indizierung von Subgraphen langsam ist, hängt die Ursache dafür von dem jeweiligen Subgraphen ab.

Häufige Ursachen für eine langsame Indizierung:

- Zeit, die benötigt wird, um relevante Ereignisse aus der Kette zu finden (insbesondere Call-Handler können langsam sein, da sie auf `trace_filter` angewiesen sind)
- Durchführen einer großen Anzahl von „eth_calls“ als Teil von Handlern
- Eine große Anzahl von Store-Interaktionen während der Ausführung
- Eine große Datenmenge, die im Speicher gespeichert werden soll
- Eine große Anzahl von Ereignissen, die verarbeitet werden müssen
- Lange Datenbankverbindungszeit für überfüllte Knoten
- Der Anbieter selbst fällt dem Kettenkopf hinterher
- Langsamkeit beim Abrufen neuer Einnahmen am Kettenkopf vom Anbieter

Metriken zur Indizierung von Subgraphen können dabei helfen, die Ursache für die Langsamkeit der Indizierung zu ermitteln. In einigen Fällen liegt das Problem am Subgraph selbst, in anderen Fällen können verbesserte Netzwerkanbieter, geringere Datenbankkonflikte und andere Konfigurationsverbesserungen die Indizierungsleistung deutlich verbessern.

#### Fehlerhafte Subgraphen

Während der Indizierung können Subgraphen fehlschlagen, wenn sie auf unerwartete Daten stoßen, wenn eine Komponente nicht wie erwartet funktioniert oder wenn es einen Fehler in den Event-Handlern oder der Konfiguration gibt. Es gibt zwei allgemeine Arten von Fehlern:

- Deterministische Fehler: Dies sind Fehler, die nicht durch Wiederholungsversuche behoben werden können
- Nicht deterministische Fehler: Diese können auf Probleme mit dem Anbieter oder auf einen unerwarteten Graph-Knoten-Fehler zurückzuführen sein. Wenn ein nicht deterministischer Fehler auftritt, versucht Graph Node die fehlgeschlagenen Handler erneut und nimmt im Laufe der Zeit einen Rückzieher.

In einigen Fällen kann ein Fehler durch den Indexer behoben werden (z. B. wenn der Fehler darauf zurückzuführen ist, dass nicht die richtige Art von Anbieter vorhanden ist, kann durch Hinzufügen des erforderlichen Anbieters die Indizierung fortgesetzt werden). In anderen Fällen ist jedoch eine Änderung des Subgraph-Codes erforderlich.

> Deterministische Fehler werden als „endgültig“ betrachtet, wobei für den fehlgeschlagenen Block ein Indizierungsnachweis generiert wird, während nicht-deterministische Fehler nicht als solche betrachtet werden, da es dem Subgraphen gelingen kann, „nicht zu versagen“ und die Indizierung fortzusetzen. In einigen Fällen ist die nicht-deterministische Kennzeichnung falsch, und der Subgraph wird den Fehler nie überwinden; solche Fehler sollten als Probleme im Graph Node Repository gemeldet werden.

#### Cache blockieren und aufrufen

Graph Node speichert bestimmte Daten im Zwischenspeicher, um ein erneutes Abrufen vom Anbieter zu vermeiden. Blöcke werden zwischengespeichert, ebenso wie die Ergebnisse von `eth_calls` (letztere werden ab einem bestimmten Block zwischengespeichert). Diese Zwischenspeicherung kann die Indizierungsgeschwindigkeit bei der „Neusynchronisierung“ eines leicht geänderten Untergraphen drastisch erhöhen.

Wenn jedoch ein Ethereum-Knoten über einen bestimmten Zeitraum falsche Daten geliefert hat, können diese in den Cache gelangen und zu falschen Daten oder fehlgeschlagenen Subgraphen führen. In diesem Fall können Indexer `graphman` verwenden, um den vergifteten Cache zu löschen und dann die betroffenen Subgraphen neu zu spulen, die dann frische Daten von dem (hoffentlich) gesunden Anbieter holen werden.

Wenn eine Block-Cache-Inkonsistenz vermutet wird, z. B. ein Ereignis „TX-Empfang fehlt“:

1. `graphman chain list`, um den Namen der Kette zu finden.
2. `graphman chain check-blocks <CHAIN> by-number <NUMBER>` prüft, ob der zwischengespeicherte Block mit dem Anbieter übereinstimmt, und löscht den Block aus dem Cache, wenn dies nicht der Fall ist.
   1. Wenn es einen Unterschied gibt, kann es sicherer sein, den gesamten Cache mit `graphman chain truncate <CHAIN>` abzuschneiden.
   2. Wenn der Block mit dem Anbieter übereinstimmt, kann das Problem direkt beim Anbieter gedebuggt werden.

#### Abfragen von Problemen und Fehlern

Sobald ein Subgraph indiziert wurde, können Indexierer erwarten, dass Abfragen über den dedizierten Abfrageendpunkt des Subgraphen bedient werden. Wenn der Indexer hofft, ein erhebliches Abfragevolumen zu bedienen, wird ein dedizierter Abfrageknoten empfohlen. Im Falle eines sehr hohen Abfragevolumens möchten Indexer möglicherweise Replikatshards konfigurieren, damit Abfragen den Indexierungsprozess nicht beeinträchtigen.

Aber selbst mit einem dedizierten Abfrageknoten und Replikaten kann die Ausführung bestimmter Abfragen lange dauern und in einigen Fällen die Speichernutzung erhöhen und die Abfragezeit für andere Benutzer negativ beeinflussen.

Es gibt nicht die eine Wunderwaffe, sondern eine Reihe von Tools zur Vorbeugung, Diagnose und Behandlung langsamer Abfragen.

##### Abfrage-Caching

Graph Node zwischenspeichert GraphQL-Abfragen standardmäßig, was die Datenbanklast erheblich reduzieren kann. Dies kann mit den Einstellungen `GRAPH_QUERY_CACHE_BLOCKS` und `GRAPH_QUERY_CACHE_MAX_MEM` weiter konfiguriert werden - lesen Sie mehr [hier](https://github.com/graphprotocol/graph-node/blob/master/docs/environment-variables.md#graphql-caching).

##### Analysieren von Abfragen

Problematische Abfragen treten meist auf zwei Arten auf. In einigen Fällen melden die Benutzer selbst, dass eine bestimmte Abfrage langsam ist. In diesem Fall besteht die Herausforderung darin, den Grund für die Langsamkeit zu diagnostizieren - ob es sich um ein allgemeines Problem oder um ein spezifisches Problem für diesen Untergraphen oder diese Abfrage handelt. Und dann natürlich, wenn möglich, das Problem zu beheben.

In anderen Fällen kann der Auslöser eine hohe Speicherauslastung auf einem Abfrageknoten sein. In diesem Fall besteht die Herausforderung darin, zuerst die Abfrage zu identifizieren, die das Problem verursacht.

Indexer können [qlog](https://github.com/graphprotocol/qlog/) verwenden, um die Abfrageprotokolle von Graph Node zu verarbeiten und zusammenzufassen. `GRAPH_LOG_QUERY_TIMING` kann auch aktiviert werden, um langsame Abfragen zu identifizieren und zu debuggen.

Bei einer langsamen Abfrage haben Indexierer einige Optionen. Natürlich können sie ihr Kostenmodell ändern, um die Kosten für das Senden der problematischen Anfrage erheblich zu erhöhen. Dies kann zu einer Verringerung der Häufigkeit dieser Abfrage führen. Dies behebt jedoch häufig nicht die Ursache des Problems.

##### Account-ähnliche Optimierung

Datenbanktabellen, die Entitäten speichern, scheinen im Allgemeinen in zwei Varianten zu existieren: „transaktionsähnlich“, bei denen Entitäten, sobald sie erstellt wurden, nie aktualisiert werden, d. h. sie speichern so etwas wie eine Liste von Finanztransaktionen, und „kontoähnlich“, bei denen Entitäten sehr oft aktualisiert werden, d. h. sie speichern so etwas wie Finanzkonten, die jedes Mal geändert werden, wenn eine Transaktion aufgezeichnet wird. Kontenähnliche Tabellen zeichnen sich dadurch aus, dass sie eine große Anzahl von Entitätsversionen, aber relativ wenige eindeutige Entitäten enthalten. In solchen Tabellen beträgt die Anzahl der unterschiedlichen Entitäten häufig 1 % der Gesamtzahl der Zeilen (Entitätsversionen).

Für kontoähnliche Tabellen kann `graph-node` Abfragen generieren, die sich die Details zunutze machen, wie Postgres Daten mit einer so hohen Änderungsrate speichert, nämlich dass alle Versionen für die jüngsten Blöcke in einem kleinen Teil des Gesamtspeichers für eine solche Tabelle liegen.

Der Befehl `graphman stats show <sgdNNNN>` zeigt für jeden Entitätstyp/jede Tabelle in einem Einsatz an, wie viele unterschiedliche Entitäten und wie viele Entitätsversionen jede Tabelle enthält. Diese Daten beruhen auf Postgres-internen Schätzungen und sind daher notwendigerweise ungenau und können um eine Größenordnung abweichen. Ein `-1` in der Spalte `entities` bedeutet, dass Postgres davon ausgeht, dass alle Zeilen eine eindeutige Entität enthalten.

Im Allgemeinen sind Tabellen, bei denen die Anzahl der unterschiedlichen Entitäten weniger als 1 % der Gesamtzahl der Zeilen/Entitätsversionen beträgt, gute Kandidaten für die kontoähnliche Optimierung. Wenn die Ausgabe von `graphman stats show` darauf hindeutet, dass eine Tabelle von dieser Optimierung profitieren könnte, führt `graphman stats show <sgdNNN> <table>` eine vollständige Zählung der Tabelle durch - das kann langsam sein, liefert aber ein genaues Maß für das Verhältnis von eindeutigen Entitäten zu den gesamten Entitätsversionen.

Sobald eine Tabelle als „kontoähnlich“ eingestuft wurde, wird durch die Ausführung von `graphman stats account-like <sgdNNN>.<table>` die kontoähnliche Optimierung für Abfragen auf diese Tabelle aktiviert. Die Optimierung kann mit `graphman stats account-like --clear <sgdNNN>.<table>` wieder ausgeschaltet werden. Es dauert bis zu 5 Minuten, bis die Abfrageknoten merken, dass die Optimierung ein- oder ausgeschaltet wurde. Nach dem Einschalten der Optimierung muss überprüft werden, ob die Abfragen für diese Tabelle durch die Änderung nicht tatsächlich langsamer werden. Wenn Sie Grafana für die Überwachung von Postgres konfiguriert haben, würden langsame Abfragen in `pg_stat_activity` in großer Zahl angezeigt werden und mehrere Sekunden dauern. In diesem Fall muss die Optimierung wieder abgeschaltet werden.

For Uniswap-like Subgraphs, the `pair` and `token` tables are prime candidates for this optimization, and can have a dramatic effect on database load.

#### Entfernen von Subgraphen

> This is new functionality, which will be available in Graph Node 0.29.x

Irgendwann möchte ein Indexer vielleicht einen bestimmten Subgraph entfernen. Dies kann einfach mit `graphman drop` gemacht werden, welches einen Einsatz und alle indizierten Daten löscht. Der Einsatz kann entweder als Name eines Subgraphen, als IPFS-Hash `Qm..` oder als Datenbank-Namensraum `sgdNNN` angegeben werden. Weitere Dokumentation ist [hier](https://github.com/graphprotocol/graph-node/blob/master/docs/graphman.md#-drop) verfügbar.

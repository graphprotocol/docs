---
title: Індексація
---

Індексатори - це оператори нод у The Graph Network, які стейкають токени Graph (GRT), щоб надавати послуги з індексування та обробки запитів. За свої послуги індексатори отримують плату за запити та винагороду за індексацію. Вони також заробляють комісію за запити, яка повертається відповідно до експоненціальної функції компенсації.

GRT, які застейкані в протоколі, підлягають періоду "розблокування" і можуть бути порізані (slashing), якщо індексатори є шкідливими та надають некоректні дані додаткам або якщо вони неправильно індексують. Індексатори також отримують винагороду за стейк, який вони отримують від делегатів, щоб зробити свій внесок у розвиток мережі.

Індексатори вибирають підграфи для індексування на основі сигналу від кураторів, де куратори стейкають GRT, щоб вказати, які підграфи є якісними та мають бути пріоритетними. Споживачі (наприклад, додатки) також можуть задавати параметри, за якими індексатори обробляють запити до їхніх підграфів, і встановлювати налаштування щодо оплати за запити.

<Difficulty level="ADVANCED" />

## Поширені запитання

### Яка мінімальна кількість GRT необхідна для того, щоб стати індексатором в мережі?

Мінімальна кількість для індексатора наразі встановлена на рівні 100 тис. GRT.

### Які джерела доходу для індексатора?

**Отримання комісії за опрацювання запитів** - Платежі за обслуговування запитів у мережі. Ці платежі здійснюються через відповідні канали між індексатором та сіткою. Кожен запит містить платіж, а відповідна відповідь - доказ правдивості результату запиту.

**Винагорода за індексацію** - Винагорода за індексацію, що генерується шляхом 3% річної інфляції в масштабі всього протоколу, розподіляється серед індексаторів, які індексують розгортання підграфів для мережі.

### Як розподіляються винагороди за індексацію?

Винагорода за індексацію надходить від інфляції протоколу, яка встановлена на рівні 3% річної емісії. Вони розподіляються між підграфами на основі частки всіх кураторських сигналів на кожному, а потім розподіляються пропорційно між індексаторами на основі їхнього виділеного стейку на відповідному підграфі. **Щоб мати право на винагороду, розподіл має бути закрито за допомогою доказу індексації (proof of indexing - POI), яке відповідає стандартам, установленим арбітражним регламентом.**

Numerous tools have been created by the community for calculating rewards; you'll find a collection of them organized in the [Community Guides collection](https://www.notion.so/Community-Guides-abbb10f4dba040d5ba81648ca093e70c). You can also find an up to date list of tools in the #Delegators and #Indexers channels on the [Discord server](https://discord.gg/graphprotocol). Here we link a [recommended allocation optimiser](https://github.com/graphprotocol/AllocationOpt.jl) integrated with the indexer software stack.

### Що за доказ індексації (POI)?

POI використовуються в мережі для перевірки того, що Індексатор індексує підграфи, на які вони були розподілені. POI для першого блоку поточної епохи має бути надісланий при закритті розподілу, щоб цей розподіл мав право на винагороду за індексацію. POI для блоку - це дайджест усіх транзакцій сховища об'єктів для певного розгортання підграфів до цього блоку включно.

### Коли розподіляються винагороди за індексацію?

Винагороди безперервно накопичуються, поки алокації активні та розподілені протягом 28 періодів. Винагороди збираються Індексаторами та розподіляються щоразу, коли їхні розподіли закриваються. Це відбувається або вручну, коли Індексатор хоче примусово закрити їх, або після 28 епох, делегат може закрити розподіл для Індексатора, але це не призводить до отримання винагороди. 28 епох - це максимальний час роботи розподілів (зараз одна епоха триває ~24 години).

### Чи можна відстежувати винагороди за індексацію, що очікують на розгляд?

Контракт RewardsManager має функцію [getRewards](https://github.com/graphprotocol/contracts/blob/master/contracts/rewards/RewardsManager.sol#L317), доступну тільки для читання, яку можна використовувати для перевірки очікуваних винагород для конкретного розподілу.

Багато інформаційних панелей, створених спільнотою, містять очікувані значення винагород, і їх можна легко перевірити вручну, виконавши ці кроки:

1. Надішліть запит на [підграф в основній мережі](https://thegraph.com/hosted-service/subgraph/graphprotocol/graph-network-mainnet), щоб отримати ідентифікатори всіх активних розподілів:

```graphql
запит indexerAllocations {
  indexer(id: "<INDEXER_ADDRESS>") { { } }) { indexer(id: "<INDEXER_ADDRESS>")
    allocations {
      activeForIndexer {
        allocations { id
          id
        }
      }
    }
  }
}
```

Використовуйте Etherscan для виклику `getRewards()`:

- Перейдіть до [EtherScan інтерфейсу, потім до контракту Rewards](https://etherscan.io/address/0x9Ac758AB77733b4150A901ebd659cbF8cB93ED66#readProxyContract)

* Оберіть `getRewards()`:
  - Відкрийте список **10. getRewards**.
  - Введіть **allocationID** у вхідних даних.
  - Натисніть кнопку **Query**.

### Що таке спори (disputes) та де я можу їх переглянути?

Запити індексатора та розподіли можуть бути оскаржені на Graph протягом відповідного періоду оскарження. Цей період варіюється в залежності від типу спору. Для запитів/атестацій вікно спору триває 7 епох, тоді як для розподілів - 56. Після закінчення цих періодів спори не можуть бути відкриті ні проти розподілів, ні проти запитів. При відкритті спору учасник повинен внести депозит у розмірі не менше 10 000 GRT, який буде заблокований до завершення спору і винесення рішення по ній. Fisherman (рибалка) - це будь-який учасник мережі, який відкриває спори.

Спори мають **три** можливих результати, так само як і депозит учасників.

- Якщо спір буде відхилено, GRT, внесений в якості депозиту, буде спалено, а Індексатор не буде порізаний.
- Якщо суперечка буде вирішена внічию, депозит користувача буде повернуто, а індексатора не буде порізано.
- Якщо спір буде задоволено, GRT, внесений учасником, буде повернуто, Індексатора буде порізано, а рибалка отримає 50% від GRT, які були порізані.

Спори можна переглянути в інтерфейсі на сторінці профілю індексатора у вкладці `Disputes`.

### Що за комісії за опрацювання запитів і коли вони розподіляються?

Query fees are collected by the gateway and distributed to indexers according to the exponential rebate function (see GIP [here](https://forum.thegraph.com/t/gip-0051-exponential-query-fee-rebates-for-indexers/4162)). The exponential rebate function is proposed as a way to ensure indexers achieve the best outcome by faithfully serving queries. It works by incentivizing Indexers to allocate a large amount of stake (which can be slashed for erring when serving a query) relative to the amount of query fees they may collect.

Після закриття розподілу виплати можуть бути отримані індексатором. Після клейму, комісії за запити розподіляються між індексатором та його делегатами на основі зниження цін за запити та експоненціальної функції повернень.

### Що таке query fee cut і indexing reward cut?

Значення `queryFeeCut` і `indexingRewardCut` є параметрами делегування, які Індексатор може встановлювати разом із cooldownBlocks, щоб контролювати розподіл GRT між Індексатором і його Делегатами. Перегляньте останні кроки в розділі [Staking in the Protocol](/network/indexing#stake-in-the-protocol), щоб отримати інструкції щодо встановлення параметрів делегування.

- **queryFeeCut** - відсоток від комісій за опрацювання запитів, який буде розподілено між Індексатором та Делегатами. Якщо цей параметр встановлено на рівні в 95%, індексатор отримає 95% від комісій за запити, зароблених при закритті розподілу, а решта 5% підуть Делегатам.

- **indexingRewardCut** - відсоток від винагород за індексацію, який буде розподілено між Індексатором та Делегатами. Якщо цей параметр встановлено на рівні в 95%, індексатор отримає 95% винагороди за індексацію, коли розподіл буде закрито, а делегати розділять між собою решту 5%.

### Як індексатори знають, які підграфи індексувати?

Індексатори можуть відрізнятися один від одного, застосовуючи передові методи для прийняття рішень щодо індексування підграфів, але для того, щоб дати загальне уявлення, ми обговоримо кілька ключових метрик, які використовуються для оцінки підграфів у мережі:

- **Сигнали від кураторів ** - якщо велика частка від загальної кількості сигналів у мережі припадає на певний підграф, то це є хорошим показником інтересу до цього підграфа, особливо під час фази бутстрапу, коли обсяг запитів зростає.

- **Збори за запити** - Історичні дані про обсяг зборів за запити, зібрані для певного підграфа, є хорошим індикатором майбутнього попиту.

- **Кількість застейканих токенів** - Спостереження за поведінкою інших індексаторів або аналіз пропорцій від загального стейку токенів, виділених на конкретні підграфи, може дозволити індексатору відстежувати попит на запити до підграфів, щоб виявити підграфи, яким мережа довіряє, або підграфи, які можуть показати потребу в більшій кількості токенів.

- **Підграфи без винагороди за індексування** - Деякі підграфи не отримують винагороди за індексування переважно через те, що вони використовують непідтримувані можливості, такі як IPFS, або тому, що вони запитують іншу мережу за межами основної мережі. Ви побачите повідомлення про те, що підграф не генерує винагороду за індексацію.

### Які вимоги до апаратного обладнання?

- **Small** - достатній для початку індексування декількох підграфів, ймовірно, потрібно буде розширити.
- **Standard** - налаштування за замовчуванням, це те, що використовується у прикладі маніфестів розгортання k8s/terraform.
- **Medium** - продуктивний індексатор, що підтримує 100 підграфів і 200-500 запитів на секунду.
- **Large** - підготовлений для індексації всіх підграфів, що використовуються наразі, і обслуговування запитів на відповідний трафік.

| Налаштування | Postgres<br />(CPU) | Postgres<br />(пам'ять в GB) | Postgres<br />(диск у ТБ) | VMs<br />(Центральні CPU) | VMs<br />(пам'ять у ГБ) |
| --- | :-: | :-: | :-: | :-: | :-: |
| Small | 4 | 8 | 1 | 4 | 16 |
| Standard | 8 | 30 | 1 | 12 | 48 |
| Medium | 16 | 64 | 2 | 32 | 64 |
| Large | 72 | 468 | 3.5 | 48 | 184 |

### Яких основних заходів безпеки повинен дотримуватися індексатор?

- **Operator wallet**. Налаштування гаманця оператора є важливим запобіжним заходом, оскільки він дозволяє Індексатору підтримувати відокремлення між своїми ключами, які контролюють застейкані токени, і тими, які використовуються для щоденних операцій. Інструкції див. у розділі [Stake in Protocol](/network/indexing#stake-in-the-protocol).

- **Firewall** - Публічно доступною має бути лише сервіс-індексатор, і особливу увагу слід приділити блокуванню портів адміністратора і доступу до бази даних: не слід відкривати кінцеву точку JSON-RPC Graph Node (порт за замовчуванням: 8030), кінцеву точку API управління індексатором (порт за замовчуванням: 18000) і кінцеву точку бази даних Postgres (порт за замовчуванням: 5432).

## Інфраструктура

Центром інфраструктури індексатора є Graph Node, яка відстежує індексовані мережі, вибирає і завантажує дані відповідно до визначення підграфів і слугує як [GraphQL API](/about/#how-the-graph-works). Graph Node має бути підключена до кінцевої точки, яка надає дані з кожної проіндексованої мережі; ноди IPFS для отримання даних; бази даних PostgreSQL для їх зберігання; і компонентів індексатора, які полегшують його взаємодію з мережею.

- **PostgreSQL database** - основне сховище для Graph Node, саме тут зберігаються дані підграфів. Сервіс-індексатор та агент також використовують базу даних для зберігання даних каналів стану, моделей витрат, правил індексації та дій з розподілу.

- **Data endpoint** - Для EVM-сумісних мереж Graph Node має бути підключена до кінцевої точки, який надає EVM-сумісний JSON-RPC API. Це може бути як один клієнт, так і більш складне налаштування, яке розподіляє навантаження між кількома. Важливо знати, що певні підграфи потребують особливих можливостей клієнта, таких як режим архівування та/або API відстеження парності.

- **Нода IPFS (версія менше ніж 5)** - метадані розгортання підграфів зберігаються у мережі IPFS. Graph Node звертається до вузла IPFS під час розгортання підграфів, щоб отримати маніфест підграфів і всі пов'язані файли. Індексаторам в мережі не потрібно запускати власну ноду IPFS, ноду IPFS для мережі розміщено на https://ipfs.network.thegraph.com.

- **Indexer service** - виконує всі необхідні зовнішні комунікації з мережею. Обмінюється моделями витрат і статусами індексації, передає запити від шлюзів до Graph Node, а також керує оплатою запитів через відповідні канали зі шлюзом.

- **Indexer agent** - полегшує взаємодію індексаторів в мережі, включаючи реєстрацію у мережі, керування розгортанням підграфів у Graph Node/-ах та керуванням розподілами.

- **Сервер метрик Prometheus** - Компоненти Graph Node та індексаторів реєструють свої метрики на відповідному на сервері.

Примітка: Для підтримки гнучкого масштабування рекомендується розділити завдання запитів та індексації між різними наборами нод: нодами запитів та нодами індексації.

### Огляд портів

> **Важливо**: Будьте обережні з публічним відкриттям портів - **адміністративні порти** слід тримати закритими. Це стосується і JSON-RPC Graph Node та кінцевих точок керування індексатором, описаних нижче.

#### Graph Node

| Порт | Призначення | Розташування | Аргумент CLI | Перемінна оточення |
| --- | --- | --- | --- | --- |
| 8000 | HTTP-сервер GraphQL<br />(для запитів до підграфів) | /subgraphs/id/...<br />/subgraphs/name/.../... | --http-порт | - |
| 8001 | GraphQL WS<br />(для підписок на підграфи) | /subgraphs/id/...<br />/subgraphs/name/.../... | --ws-port | - |
| 8020 | JSON-RPC<br />(для керування розгортаннями) | / | --admin-port | - |
| 8030 | API стану індексації підграфів | /graphql | --index-node-port | - |
| 8040 | Метрики Prometheus | /metrics | --metrics-port | - |

#### Служба індексації

| Порт | Призначення | Розташування | Аргумент CLI | Перемінна оточення |
| --- | --- | --- | --- | --- |
| 7600 | HTTP-сервер GraphQL<br />(для платних запитів до підграфів) | /subgraphs/id/...<br />/status<br />/channel-messages-inbox | --port | `INDEXER_SERVICE_PORT` |
| 7300 | Метрики Prometheus | /metrics | --metrics-port | - |

#### Агент індексації

| Порт | Призначення | Розташування | Аргумент CLI | Перемінна оточення |
| --- | --- | --- | --- | --- |
| 8000 | API для керування індексатором | / | --indexer-management-port | `INDEXER_AGENT_INDEXER_MANAGEMENT_PORT` |

### Налаштування серверної інфраструктури з використанням Terraform на Google Cloud

> Примітка: Індексатори можуть альтернативно використовувати AWS, Microsoft Azure або Alibaba.

#### Встановіть необхідні умови

- Google Cloud SDK
- Kubectl - інструмент командного рядка
- Terraform

#### Створіть проєкт на Google Cloud

- Клонуйте або перейдіть до репозиторію індексатора.

- Перейдіть до каталогу ./terraform, саме тут слід виконати всі команди.

```sh
cd terraform
```

- Авторизуйтесь у Google Cloud і створіть новий проєкт.

```sh
gcloud auth login
project=<PROJECT_NAME>
gcloud projects create --enable-cloud-apis $project
```

- Використовуйте сторінку виставлення рахунків у Google Cloud Console, щоб увімкнути виставлення рахунків для нового проєкту.

- Створіть конфігурацію Google Cloud.

```sh
proj_id=$(gcloud projects list --format='get(project_id)' --filter="name=$project")
gcloud config configurations create $project
gcloud config set project "$proj_id"
gcloud config set compute/region us-central1
gcloud config set compute/zone us-central1-a
```

- Увімкніть необхідні Google Cloud API.

```sh
gcloud services enable compute.googleapis.com
gcloud services enable container.googleapis.com
gcloud services enable servicenetworking.googleapis.com
gcloud services enable sqladmin.googleapis.com
```

- Створіть обліковий запис сервісу.

```sh
svc_name=<SERVICE_ACCOUNT_NAME>
gcloud iam service-accounts create $svc_name \
  --description="Service account for Terraform" \
  --display-name="$svc_name"
gcloud iam service-accounts list
# Get the email of the service account from the list
svc=$(gcloud iam service-accounts list --format='get(email)'
--filter="displayName=$svc_name")
gcloud iam service-accounts keys create .gcloud-credentials.json \
  --iam-account="$svc"
gcloud projects add-iam-policy-binding $proj_id \
  --member serviceAccount:$svc \
  --role roles/editor
```

- Увімкніть взаємодію між базою даних і кластером Kubernetes, який буде створено на наступному кроці.

```sh
gcloud compute addresses create google-managed-services-default \
  --prefix-length=20 \
  --purpose=VPC_PEERING \
  --network default \
  --global \
  --description 'IP Range for peer networks.'
gcloud services vpc-peerings connect \
  --network=default \
  --ranges=google-managed-services-default
```

- Створіть мінімальний конфігураційний файл terraform (оновлюйте за потреби).

```sh
indexer=<INDEXER_NAME>
cat > terraform.tfvars <<EOF
project = "$proj_id"
indexer = "$indexer"
database_password = "<database passowrd>"
EOF
```

#### Використовуйте Terraform для створення інфраструктури

Перед виконанням будь-яких команд прочитайте [variables.tf](https://github.com/graphprotocol/indexer/blob/main/terraform/variables.tf) і створіть файл `terraform .tfvars` у цьому каталозі (або змініть той, який ми створили на останньому кроці). Для кожної змінної, де ви бажаєте замінити значення за замовчуванням або де вам потрібно встановити значення, введіть параметр у `terraform.tfvars`.

- Запустіть наступні команди, щоб створити інфраструктуру.

```sh
# Встановіть необхідні плагіни
terraform init

# Переглянути план для ресурсів, які будуть створені
terraform plan

# Створіть ресурси (очікується, що це займе до 30 хвилин)
terraform apply
```

Завантажте облікові дані нового кластера до `~/.kube/config` і встановіть його як контекст за замовчуванням.

```sh
gcloud container clusters get-credentials $indexer
kubectl config use-context $(kubectl config get-contexts --output='name'
| grep $indexer)
```

#### Створення компонентів Kubernetes для індексатора

- Скопіюйте каталог `k8s/overlays` до нового каталогу `$dir,` і налаштуйте запис `bases` у `$dir/kustomization.yaml< /code>, щоб він вказував на каталог <code>k8s/base`.

- Прочитайте всі файли в `$dir` і змініть будь-які значення, як зазначено в коментарях.

Установіть усі ресурси за допомогою `kubectl apply -k $dir`.

### Graph Node

[Graph Node](https://github.com/graphprotocol/graph-node) - це реалізація Rust з відкритим вихідним кодом, яка використовує події блокчейну Ethereum для детермінованого оновлення сховища даних, які можна запитувати через кінцеву точку GraphQL. Розробники використовують підграфи для визначення своєї схеми та набір відображень для перетворення даних, отриманих з блоків мережі, а Graph Node займається синхронізацією всієї мережі, моніторингом нових блоків і обслуговуванням їх через кінцеву точку GraphQL.

#### Початок роботи з базового коду

#### Встановіть необхідні умови

- **Rust**

- **PostgreSQL**

- **IPFS**

- **Додаткові вимоги для користувачів Ubuntu** - Для запуску Graph Node на Ubuntu може знадобитися декілька додаткових програм.

```sh
sudo apt-get install -y clang libpg-dev libssl-dev pkg-config
```

#### Налаштування

1. Запуск сервера бази даних PostgreSQL

```sh
initdb -D .postgres
pg_ctl -D .postgres -l logfile start
createdb graph-node
```

2. Клонуйте [Graph Node](https://github.com/graphprotocol/graph-node) репозиторій і створіть базовий код, запустивши `cargo build`

3. Тепер, коли всі необхідні складові налаштовано, запустіть Graph Node:

```sh
cargo run -p graph-node --release -- \
  --postgres-url postgresql://[USERNAME]:[PASSWORD]@localhost:5432/graph-node \
  --ethereum-rpc [NETWORK_NAME]:[URL] \
  --ipfs https://ipfs.network.thegraph.com
```

#### Початок роботи з Docker

#### Передумови

- **Нода Ethereum**. За замовчуванням, docker compose використовуватиме основну мережу: [http:// host.docker.internal:8545](http://host.docker.internal:8545) для підключення до ноди Ethereum на вашій основній машині. Ви можете замінити це ім’я та Url-адресу мережі, оновивши `docker-compose.yaml`.

#### Налаштування

1. Клонуйте Graph Node і перейдіть до каталогу Docker:

```sh
git clone https://github.com/graphprotocol/graph-node
cd graph-node/docker
```

2. Лише для користувачів Linux – використовуйте IP-адресу хоста замість `host.docker.internal` у `docker-compose.yaml` за допомогою доданого скрипта:

```sh
./setup.sh
```

3. Запустіть локальну Graph Node, яка буде підключена до вашої кінцевої точки Ethereum:

```sh
docker-compose up
```

### Компоненти індексатора

Для успішної участі в мережі потрібен майже постійний моніторинг і взаємодію, тому ми створили набір додатків Typescript для полегшення участі в мережі індексаторів. Існує три компоненти Індексатора:

- **Indexer agent** - Агент відстежує мережу та власну інфраструктуру індексатора і керує розгортаннями підграфів, які індексуються та розподіляються в мережі, а також визначає, скільки ресурсів виділяється для кожного з них.

- **Indexer service** - Єдиний компонент, який потрібно виставляти назовні, сервіс передає запити підграфів до graph node, керує каналами стану для оплати запитів, ділиться важливою інформацією для прийняття рішень з клієнтами, такими як шлюзи.

- **Indexer CLI** - інтерфейс командного рядка для керування агентом індексатора. Він дозволяє індексаторам керувати моделями витрат, ручним розподілом, чергою дій та правилами індексування.

#### Початок роботи

The Indexer agent and Indexer service should be co-located with your Graph Node infrastructure. There are many ways to set up virtual execution environments for your Indexer components; here we'll explain how to run them on baremetal using NPM packages or source, or via kubernetes and docker on the Google Cloud Kubernetes Engine. If these setup examples do not translate well to your infrastructure there will likely be a community guide to reference, come say hi on [Discord](https://discord.gg/graphprotocol)! Remember to [stake in the protocol](/network/indexing#stake-in-the-protocol) before starting up your Indexer components!

#### З NPM-пакетів

```sh
npm install -g @graphprotocol/indexer-service
npm install -g @graphprotocol/indexer-agent

# Indexer CLI is a plugin for Graph CLI, so both need to be installed:
npm install -g @graphprotocol/graph-cli
npm install -g @graphprotocol/indexer-cli

# Indexer service
graph-indexer-service start ...

# Indexer agent
graph-indexer-agent start ...

# Indexer CLI
#Forward the port of your agent pod if using Kubernetes
kubectl port-forward pod/POD_ID 18000:8000
graph indexer connect http://localhost:18000/
graph indexer ...
```

#### З базового коду

```sh
# From Repo root directory
yarn

# Indexer Service
cd packages/indexer-service
./bin/graph-indexer-service start ...

# Indexer agent
cd packages/indexer-agent
./bin/graph-indexer-service start ...

# Indexer CLI
cd packages/indexer-cli
./bin/graph-indexer-cli indexer connect http://localhost:18000/
./bin/graph-indexer-cli indexer ...
```

#### Використання docker

- Витягнути images з реєстру

```sh
docker pull ghcr.io/graphprotocol/indexer-service:latest
docker pull ghcr.io/graphprotocol/indexer-agent:latest
```

Або створіть images локально з базового коду

```sh
# Indexer service
docker build \
  --build-arg NPM_TOKEN=<npm-token> \
  -f Dockerfile.indexer-service \
  -t indexer-service:latest \
# Indexer agent
docker build \
  --build-arg NPM_TOKEN=<npm-token> \
  -f Dockerfile.indexer-agent \
  -t indexer-agent:latest \
```

- Запустіть компоненти

```sh
docker run -p 7600:7600 -it indexer-service:latest ...
docker run -p 18000:8000 -it indexer-agent:latest ...
```

**ПРИМІТКА**. Після запуску контейнерів сервіс-індексатора повинен бути доступний за адресою [http://localhost:7600](http://localhost:7600), а агент індексатора повинен виставляти API управління індексатором за адресою [http://localhost:18000/](http://localhost:18000/).

#### Використання K8 та Terraform

Див. розділ [Налаштування серверної інфраструктури з використанням Terraform на Google Cloud](/network/indexing#setup-server-infrastructure-using-terraform-on-google-cloud)

#### Використання

> **ПРИМІТКА**. Усі змінні конфігурації середовища виконання можна застосовувати як параметри до команди під час запуску або за допомогою змінних середовища у форматі `COMPONENT_NAME_VARIABLE_NAME`(наприклад, `INDEXER_AGENT_ETHEREUM`).

#### Indexer agent

```sh
graph-indexer-agent start \
  --ethereum <MAINNET_ETH_ENDPOINT> \
  --ethereum-network mainnet \
  --mnemonic <MNEMONIC> \
  --indexer-address <INDEXER_ADDRESS> \
  --graph-node-query-endpoint http://localhost:8000/ \
  --graph-node-status-endpoint http://localhost:8030/graphql \
  --graph-node-admin-endpoint http://localhost:8020/ \
  --public-indexer-url http://localhost:7600/ \
  --indexer-geo-coordinates <YOUR_COORDINATES> \
  --index-node-ids default \
  --indexer-management-port 18000 \
  --metrics-port 7040 \
  --network-subgraph-endpoint https://gateway.network.thegraph.com/network \
  --default-allocation-amount 100 \
  --register true \
  --inject-dai true \
  --postgres-host localhost \
  --postgres-port 5432 \
  --postgres-username <DB_USERNAME> \
  --postgres-password <DB_PASSWORD> \
  --postgres-database indexer \
  --allocation-management auto \
  | pino-pretty
```

#### Indexer service

```sh
SERVER_HOST=localhost \
SERVER_PORT=5432 \
SERVER_DB_NAME=is_staging \
SERVER_DB_USER=<DB_USERNAME> \
SERVER_DB_PASSWORD=<DB_PASSWORD> \
graph-indexer-service start \
  --ethereum <MAINNET_ETH_ENDPOINT> \
  --ethereum-network mainnet \
  --mnemonic <MNEMONIC> \
  --indexer-address <INDEXER_ADDRESS> \
  --port 7600 \
  --metrics-port 7300 \
  --graph-node-query-endpoint http://localhost:8000/ \
  --graph-node-status-endpoint http://localhost:8030/graphql \
  --postgres-host localhost \
  --postgres-port 5432 \
  --postgres-username <DB_USERNAME> \
  --postgres-password <DB_PASSWORD> \
  --postgres-database is_staging \
  --network-subgraph-endpoint https://gateway.network.thegraph.com/network \
  | pino-pretty
```

#### Indexer CLI

Indexer CLI — це плагін для [`@graphprotocol/graph-cli`](https://www.npmjs.com/package/@graphprotocol/graph-cli) доступного у терміналі в `graph indexer`.

```sh
graph indexer connect http://localhost:18000
graph indexer status
```

#### Керування індексатором за допомогою Indexer CLI

Пропонованим інструментом для взаємодії з **API керування індексатором** є **Indexer CLI**, розширення **Graph CLI**. Агенту потрібні дані від індексатора, щоб автономно взаємодіяти з мережею від імені індексатора. Механізмом визначення поведінки агента індексатора є режим **керування розподілом** і **правила індексування**. У автоматичному режимі індексатор може використовувати **правила індексування**, щоб застосувати свою конкретну стратегію вибору підграфів для індексування та обслуговування запитів. Правила керуються через GraphQL API, який обслуговує агент і відомий як Indexer Management API. У ручному режимі індексатор може створювати дії розподілу за допомогою **черги дій** і явно затверджувати їх перед виконанням. У режимі нагляду **правила індексування** використовуються для заповнення **черги дій** і також вимагають явного схвалення для виконання.

#### Використання

**Indexer CLI** з'єднується з агентом індексатора, як правило, за допомогою переадресації портів, тому CLI не потрібно запускати на тому ж сервері або кластері. Щоб допомогти вам розпочати роботу і надати деякий контекст, тут буде коротко описано CLI.

- `graph indexer connect <url>` – приєднатися до API керування індексатором. Зазвичай підключення до сервера відкривається через перенаправлення портів, тому CLI можна легко керувати віддалено. (Приклад: `kubectl port-forward pod/<indexer-agent-pod> 8000:8000`)

- `graph indexer rules get [options] <deployment-id> [<key1> ...]` - отримайте одне або кілька правил індексування, використовуючи `all` як `<deployment-id>`, щоб отримати всі правила, або `global`, щоб отримати глобальні значення за замовчуванням. Додатковий аргумент `--merged` можна використовувати, щоб вказати, що правила розгортання об’єднуються з глобальним правилом. Ось як вони застосовуються в агенті індексатора.

- `graph indexer rules set [options] <deployment-id> <key1> <value1> ...` - задати одне або декілька правил індексування.

- `graph indexer rules start [options] <deployment-id>` – почніть індексувати розгортання підграфа, якщо доступно, і встановіть для його `decisionBasis` значення `always`, тому агент індексатора завжди вирішить індексувати його. Якщо для глобального правила встановлено значення завжди, усі доступні підграфи в мережі будуть проіндексовані.

- `graph indexer rules stop [options] <deployment-id>` – зупиніть індексацію розгортання та встановіть для параметра `decisionBasis` значення «never», тому він пропустить це розгортання при прийнятті рішення про те, які розгортання індексувати.

- `graph indexer rules maybe [options] <deployment-id>` — установіть `decisionBasis` для розгортання на `rules`, щоб агент індексатора використовував правила індексування, щоб вирішити, чи індексувати це розгортання.

- `graph indexer actions get [options] <action-id>` - отримання однієї або декількох дій за допомогою `all` або можливість залишити `action-id` пустим, щоб отримати всі дії. Додатковий аргумент `--status` можна використовувати для виведення всіх дій певного статусу.

- `graph indexer action queue allocate <deployment-id> <allocation-amount>` – розподіл черги

- `graph indexer action queue reallocate <deployment-id> <allocation-id> <allocationAmount>` – перерозподіл черги

- `graph indexer action queue unallocate <deployment-id> <allocation-id>` – скасування розподілу черги

- `graph indexer actions cancel [<action-id> ...]` - скасувати всі дії в черзі, якщо ідентифікатор не вказано, інакше скасувати масив ідентифікаторів із пробілом у якості розмежувача

- `graph indexer actions approve [<action-id> ...]` - затвердити кілька дій для виконання

- `graph indexer actions execute approve` - змусити виконавця негайно виконати затверджені дії

Усі команди, які відображають правила у виводі, можуть вибирати між підтримуваними форматами виводу (`table`, `yaml` та `json`) за допомогою `- output` аргументу.

#### Правила індексації

Правила індексування можуть бути застосовані як глобальні за замовчуванням або для конкретних розгортань підграфів, використовуючи їхні ідентифікатори. Поля `deployment` і `decisionBasis` є обов’язковими, тоді як усі інші поля необов’язкові. Якщо правило індексування має `rules` як `decisionBasis`, тоді агент індексатора порівнює ненульові порогові значення цього правила зі значеннями, отриманими з мережі для відповідного розгортання. Якщо розгортання підграфа має значення вище (або нижче) будь-якого з порогів, його буде вибрано для індексування.

Наприклад, якщо глобальне правило має значення `minStake` в **5** (GRT), будь-яке розгортання підграфа, що має 5 (GRT) в стейкінгу, буде проіндексоване. Порогові правила включають `maxAllocationPercentage`, `minSignal`, `maxSignal`, `minStake`, та `minAverageQueryFees`.

Модель даних:

```graphql
type IndexingRule {
    identifier: string
    identifierType: IdentifierType
    decisionBasis: IndexingDecisionBasis!
    allocationAmount: number | null
    allocationLifetime: number | null
    autoRenewal: boolean
    parallelAllocations: number | null
    maxAllocationPercentage: number | null
    minSignal: string | null
    maxSignal: string | null
    minStake: string | null
    minAverageQueryFees: string | null
    custom: string | null
    requireSupported: boolean | null
  }

IdentifierType {
  deployment
  subgraph
  group
}

IndexingDecisionBasis {
  rules
  never
  always
  offchain
}
```

Приклад використання правила індексації:

```
graph indexer rules offchain QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK

graph indexer rules set QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK decisionBasis always allocationAmount 123321 allocationLifetime 14 autoRenewal false requireSupported false

graph indexer rules stop QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK

graph indexer rules delete QmZfeJYR86UARzp9HiXbURWunYgC9ywvPvoePNbuaATrEK
```

#### Actions queue CLI

indexer-cli надає модуль `actions` для ручної роботи з чергою дій. Для взаємодії з чергою дій він використовує **Graphql API**, розміщений на сервері керування індексатором.

Виконавець дії буде брати елементи з черги на виконання, тільки якщо вони мають `ActionStatus = accepted`. У рекомендованому шляху дії додаються до черги зі статусом ActionStatus = queued, тому вони повинні бути схвалені, щоб бути виконаними в мережі. Загальний потік буде виглядати так:

- Дія, додана до черги стороннім оптимізатором або користувачем indexer-cli
- Індексатор може використовувати `indexer-cli` для перегляду всіх дій у черзі
- Індексатор (або інша програма) може затверджувати або скасовувати дії у черзі за допомогою `indexer-cli`. Команди затвердження та скасування приймають на вхід масив ідентифікаторів дій.
- Виконавець регулярно проводить опитування черги на предмет схвалення дій. Він бере `approved` дії з черги, пробує виконати їх і потім оновлює значення в db в залежності від статусу виконання до `success` або `failed`.
- Якщо дія успішна, виконавець забезпечить наявність правила індексації, яке підкаже агенту, як керувати розподілом далі, що корисно при виконанні ручних дій під час перебування агента в режимі `auto` або ` oversight`.
- Індексатор може стежити за чергою дій, щоб бачити історію виконання дій і при необхідності повторно затверджувати та оновлювати елементи дій, якщо вони не були виконані. У черзі дій відображається історія всіх дій, поставлених у чергу і виконаних.

Модель даних:

```graphql
Type ActionInput {
    status: ActionStatus
    type: ActionType
    deploymentID: string | null
    allocationID: string | null
    amount: string | null
    poi: string | null
    force: boolean | null
    source: string
    reason: string | null
    priority: number | null
}

ActionStatus {
  queued
  approved
  pending
  success
  failed
  canceled
}

ActionType {
  allocate
  unallocate
  reallocate
  collect
}
```

Приклад використання:

```bash
graph indexer actions get all

graph indexer actions get --status queued

graph indexer actions queue allocate QmeqJ6hsdyk9dVbo1tvRgAxWrVS3rkERiEMsxzPShKLco6 5000

graph indexer actions queue reallocate QmeqJ6hsdyk9dVbo1tvRgAxWrVS3rkERiEMsxzPShKLco6 0x4a58d33e27d3acbaecc92c15101fbc82f47c2ae5 55000

graph indexer actions queue unallocate QmeqJ6hsdyk9dVbo1tvRgAxWrVS3rkERiEMsxzPShKLco6 0x4a58d33e27d3acbaecc92c15101fbc82f47c2ae

graph indexer actions cancel

graph indexer actions approve 1 3 5

graph indexer actions execute approve
```

Зверніть увагу, що підтримувані типи дій для управління розподілами мають різні вимоги до вхідних даних:

- `Allocate` - розподілити стейк на конкретне розгортання підграфа

  - необхідні параметри:
    - deploymentID
    - amount

- `Unallocate` - закритий розподіл, що звільняє стейк для перерозподілу в інше місце

  - необхідні параметри:
    - allocationID
    - deploymentID
  - необов'язкові параметри:
    - poi
    - force (змушує використовувати наданий POI, навіть якщо він не збігається з тим, що надає graph-node)

- `Reallocate` - автоматично закриваємо розподіл і відкриває новий для того ж розгортання підграфа

  - необхідні параметри:
    - allocationID
    - deploymentID
    - amount
  - необов'язкові параметри:
    - poi
    - force (змушує використовувати наданий POI, навіть якщо він не збігається з тим, що надає graph-node)

#### Моделі витрат

Моделі витрат забезпечують динамічне ціноутворення для запитів на основі атрибутів ринку і запиту. Сервіс-індексатора ділиться моделлю вартості зі шлюзами для кожного підграфа, для якого вони мають намір відповідати на запити. Шлюзи, і собі, використовують модель вартості для прийняття рішень про вибір індексатора для кожного запиту і для обговорень про оплату з обраними індексаторами.

#### Agora

Мова Agora надає гнучкий формат для оголошення цінових моделей для запитів. Цінова модель Agora - це послідовність операторів, які виконуються по черзі для кожного запиту верхнього рівня в запиті GraphQL. Для кожного запиту верхнього рівня перший оператор, який йому відповідає, визначає ціну для цього запиту.

Оператор складається з параметра, який використовується для зіставлення запитів GraphQL, і виразу вартості, який при обчисленні виводить вартість у десяткових GRT. Значення в позиції іменованого аргументу запиту можуть бути перехоплені в пропозицію і використані у виразі. Globals також можна встановлювати та підставляти замість символів-замінників у виразі.

Приклад моделі витрат:

```
# This statement captures the skip value,
# uses a boolean expression in the predicate to match specific queries that use `skip`
# and a cost expression to calculate the cost based on the `skip` value and the SYSTEM_LOAD global
query { pairs(skip: $skip) { id } } when $skip > 2000 => 0.0001 * $skip * $SYSTEM_LOAD;

# This default will match any GraphQL expression.
# It uses a Global substituted into the expression to calculate cost
default => 0.1 * $SYSTEM_LOAD;
```

Приклад розрахунку вартості запиту за наведеною вище моделлю:

| Запит                                                                        | Ціна    |
| ---------------------------------------------------------------------------- | ------- |
| &#123; pairs(skip: 5000) &#123; id &#125; &#125;                             | 0.5 GRT |
| &#123; tokens &#123; symbol &#125; &#125;                                    | 0.1 GRT |
| &#123; pairs(skip: 5000) &#123; id &#123; tokens &#125; symbol &#125; &#125; | 0.6 GRT |

#### Застосування вартісної моделі

Моделі витрат застосовуються за допомогою Indexer CLI, яка передає їх до Indexer Management API агента індексатора для зберігання в базі даних. Потім сервіс-індексатора забирає їх і надає моделі витрат шлюзам, коли вони їх запитують.

```sh
indexer cost set variables '{ "SYSTEM_LOAD": 1.4 }'
indexer cost set model my_model.agora
```

## Взаємодія з мережею

### Стейкінг в протоколі

Перші кроки до участі в мережі в якості індексатора — це затвердження протоколу, стейкінгу коштів і (за бажанням) встановлення адреси оператора для щоденної взаємодії протоколу. _ **Примітка**. Для цілей цих інструкцій Remix використовуватиметься для взаємодії за контрактом, але не соромтеся використовувати інструмент за вибором ([OneClickDapp](https:// oneclickdapp.com/), [ABItopic](https://abitopic.io/) і [MyCrypto](https://www.mycrypto.com/account) – це ще кілька відомих інструментів)._

Після того, як індексатор застейкав GRT токени у протоколі, [Indexer components](/network/indexing#indexer-components) можна запустити та почати взаємодію з мережею.

#### Approve токенів

1. Відкрийте [програму Remix](https://remix.ethereum.org/) у браузері

2. У `File Explorer` створіть файл під назвою **GraphToken.abi** з [токен ABI](https://raw.githubusercontent.com/graphprotocol /contracts/mainnet-deploy-build/build/abis/GraphToken.json).

3. Вибравши `GraphToken.abi` та відкривши його в редакторі, перейдіть до розділу Deploy і `Run Transactions` в інтерфейсі Remix.

4. У розділі середовища виберіть `Injected Web3`, а в розділі `Account` виберіть свою адресу індексатора.

5. Установіть адресу контракту GraphToken. Вставте адресу контракту GraphToken (`0xc944E90C64B2c07662A292be6244BDf05Cda44a7`) поруч із полем `At Address` та натисніть кнопку `At Address`, щоб застосувати.

6. Виберіть функцію `approve(spender, amount)`, для схвалення транзакції про взаємодію зі стейкінг контрактом. Заповніть поле `spender` адресою стейкінг контракта (`0xF55041E37E12cD407ad00CE2910B8269B01263b9`) і поле `amount` кількістю токенів, які буду використані для стейка (у wei).

#### Стейкінг токенів

1. Відкрийте [програму Remix](https://remix.ethereum.org/) у браузері

2. У `File Explorer` створіть файл під назвою **Staking.abi** зі стейкінгом ABI.

3. Вибравши `Staking.abi` та відкривши його в редакторі, перейдіть до розділу `Deploy` і `Run Transactions` в інтерфейсі Remix.

4. У розділі середовища виберіть `Injected Web3`, а в розділі `Account` виберіть свою адресу індексатора.

5. Установіть адресу стейкінг контракта. Вставте цю адресу (`0xF55041E37E12cD407ad00CE2910B8269B01263b9`) поруч із полем `At Address` та натисніть кнопку `At Address`, щоб застосувати.

6. Викличте `stake()`, щоб застейкати токени GRT у протоколі.

7. (Необов’язково) Індексатори можуть схвалити іншу адресу як оператора своєї інфраструктури індексатора, щоб відокремити ключі, які контролюють кошти, від тих, які виконують щоденні дії, такі як розподіл на підграфах і обслуговування (оплачених) запитів. Щоб встановити оператора, викликайте `setOperator()` з адресою оператора.

8. (Необов'язково) Для того, щоб контролювати розподіл винагород і стратегічно залучати делегатів, індексатори можуть оновлювати свої параметри делегування, змінюючи indexingRewardCut (частини на мільйон), queryFeeCut (частини на мільйон) і cooldownBlocks (кількість блоків). Для цього викличте `setDelegationParameters()`. У наступному прикладі queryFeeCut налаштовує на розподіл 95% комісії за запити для Індексатора та 5% для Делегатів, та встановлює indexingRewardCutto розподіляти 60% винагород за індексування для Індексатора та 40% для Делегатів, і встановлює `thecooldownBlocks` період до 500 блоків.

```
setDelegationParameters(950000, 600000, 500)
```

### Термін розподілу

Після створення індексатором правильний розподіл проходить через чотири стани.

- **Active** – після створення розподілу в мережі ([allocateFrom()](https://github.com/graphprotocol/contracts/blob/master/contracts/staking/ Staking.sol#L873)) вважається **активним**. Частина власного та/або делегованого стейку Індексатора розподіляється для розгортання підграфа, що дозволяє йому отримувати винагороди за індексування та обслуговувати запити для цього розгортання підграфа. Агент індексатора керує створенням розподілів на основі правил індексування.

- **Closed** – індексатор може вільно закрити виділення, коли мине 1 епоха ([closeAllocation()](https://github.com/graphprotocol/contracts/blob/master) /contracts/staking/Staking.sol#L873)) або їхній агент автоматично закриє розподіл після **maxAllocationEpochs** (наразі 28 днів). Коли розподіл закрито за допомогою доказу індексації (POI), їх винагороди за індексацію розподіляються між Індексатором і його Делегатами (див. "how are rewards distributed?" нижче, щоб дізнатися більше).

Індексаторам рекомендується використовувати функцію offchain синхронізації для синхронізації розгортань підграфів з head of chain перед створенням розподілів у мережі. Ця функція особливо корисна для підграфів, синхронізація яких може зайняти понад 28 епох, або для яких існує ймовірність невизначеного збою.

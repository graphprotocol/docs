---
title: Meilleure pratique pour les subgraphs 5 - Simplifier et optimiser avec les séries chronologiques et les agrégations
sidebarTitle: Séries chronologiques et agrégations
---

## TLDR

Leveraging the new time-series and aggregations feature in Subgraphs can significantly enhance both indexing speed and query performance.

## Aperçu

Les séries chronologiques et les agrégations réduisent le coûts de traitementt des données et accélèrent les requêtes en déchargeant les calculs d'agrégation dans la base de données et en simplifiant le code de mappage. Cette approche est particulièrement efficace lorsqu'il s'agit de traiter de grands volumes de données chronologiques.

## Avantages des séries chronologiques et des agrégations

1. Amélioration du temps d'indexation

- Moins de données à charger : Les mappages traitent moins de données puisque les points de données brutes sont stockés sous forme d'entités chronologiques immuables.
- Agrégations gérées par la base de données : Les agrégations sont automatiquement calculées par la base de données, ce qui réduit la charge de travail sur les mappages.

2. Code de mappage simplifié

- Pas de calculs manuels : Les développeurs n'ont plus besoin d'écrire une logique d'agrégation complexe dans les mappages.
- Complexité réduite : Simplifie la maintenance du code et minimise les risques d'erreurs.

3. Des requêtes beaucoup plus rapides

- Données immuables : Toutes les données de séries chronologiques sont immuables, ce qui permet un stockage et une extraction efficaces.
- Séparation efficace des données : Les agrégats sont stockés séparément des données chronologiques brutes, ce qui permet aux requêtes de traiter beaucoup moins de données, souvent plusieurs ordres de grandeur en moins.

### Points Importants

- Données immuables : Les données chronologiques ne peuvent pas être modifiées une fois écrites, ce qui garantit l'intégrité des données et simplifie l'indexation.
- Gestion automatique de l'identification et de l'horodatage : les champs d'identification et d'horodatage sont automatiquement gérés par graph-node, ce qui réduit les erreurs potentielles.
- Stockage efficace des données : En séparant les données brutes des agrégats, le stockage est optimisé et les requêtes s'exécutent plus rapidement.

## Comment mettre en œuvre des séries chronologiques et des agrégations

### Prérequis

You need `spec version 1.1.0` for this feature.

### Définition des entités de séries chronologiques

Une entité de séries chronologiques représente des points de données brutes collectés au fil du temps. Elle est définie par l'annotation `@entity(timeseries : true)`. Exigences principales :

- Immuable : Les entités de séries chronologiques sont toujours immuables.
- Champs obligatoires :
  - `id` : Doit être de type `Int8!` et est auto-incrémenté.
  - `timestamp` : Doit être de type 'Timestamp!\` et est automatiquement fixé à l'horodatage du bloc.

L'exemple:

```graphql
type Data @entity(timeseries: true) {
  id: Int8!
  timestamp: Timestamp!
  amount: BigDecimal!
}
```

### Définition des entités d'agrégation

Une entité d'agrégation calcule des valeurs agrégées à partir d'une source de séries chronologiques. Elle est définie par l'annotation `@aggregation`. Composants clés :

- Arguments d'annotation :
  - `intervals` : Spécifie les intervalles de temps (par exemple, `["hour", "day"]`).

L'exemple:

```graphql
type Stats @aggregation(intervals: ["hour", "day"], source: "Data") {
  id: Int8!
  timestamp: Timestamp!
  sum: BigDecimal! @aggregate(fn: "sum", arg: "amount")
}
```

In this example, Stats aggregates the amount field from Data over hourly and daily intervals, computing the sum.

### Interroger des données agrégées

Les agrégations sont exposées via des champs de requête qui permettent le filtrage et la recherche sur la base de dimensions et d'intervalles de temps.

L'exemple:

```graphql
{
  tokenStats(
    interval: "hour"
    where: { token: "0x1234567890abcdef", timestamp_gte: "1704164640000000", timestamp_lt: "1704251040000000" }
  ) {
    id
    timestamp
    token {
      id
    }
    totalVolume
    priceUSD
    count
  }
}
```

### Utilisation des dimensions dans les agrégations

Les dimensions sont des champs non agrégés utilisés pour regrouper des points de données. Elles permettent des agrégations basées sur des critères spécifiques, tels qu'un jeton dans une application financière.

L'exemple:

### Entité de séries chronologiques

```graphql
type TokenData @entity(timeseries: true) {
  id: Int8!
  timestamp: Timestamp!
  token: Token!
  amount: BigDecimal!
  priceUSD: BigDecimal!
}
```

### Entité d'agrégation avec dimension

```graphql
type TokenStats @aggregation(intervals: ["hour", "day"], source: "TokenData") {
  id: Int8!
  timestamp: Timestamp!
  token: Token!
  totalVolume: BigDecimal! @aggregate(fn: "sum", arg: "amount")
  priceUSD: BigDecimal! @aggregate(fn: "last", arg: "priceUSD")
  count: Int8! @aggregate(fn: "count", cumulative: true)
}
```

- Champ dimensionnel : le jeton regroupe les données, de sorte que les agrégats sont calculés par jeton.
- Agrégats :
  - totalVolume: Somme des montants.
  - priceUSD: priceUSD le plus récent Enregistré.
  - count: Nombre cumulé d'enregistrements.

### Fonctions et expressions d'agrégation

Fonctions d'agrégation prises en charge :

- sum
- count
- min
- max
- first
- last

### L'argument dans @aggregate peut être

- Un nom de champ de l'entité de série chronologique.
- Une expression utilisant des champs et des constantes.

### Exemples d'expressions d'agrégation

- Addition de la Valeur du jeton: @aggregate(fn: "sum", arg: "priceUSD \_ amount")
- Montant positif maximum: @aggregate(fn: "max", arg: "greatest(amount0, amount1, 0)")
- Somme conditionnelle: @aggregate(fn: "sum", arg: "case when amount0 > amount1 then amount0 else 0 end")

Les opérateurs et fonctions pris en charge comprennent l'arithmétique de base (+, -, \_, /), les opérateurs de comparaison, les opérateurs logiques (and, or, not) et les fonctions SQL telles que la plus grande, la plus petite, la coalescence, etc.

### Paramètres de requête

- interval: Spécifie l'intervalle de temps (e.g., "heure").
- where: Filtres basés sur les dimensions et les plages d'horodatage.
- timestamp_gte / timestamp_lt: Filtre pour les heures de début et de fin (microsecondes depuis l'epoch).

### Notes

- Tri : Les résultats sont automatiquement triés par date et par numéro d'identification, dans l'ordre décroissant.
- Données actuelles : Un argument facultatif de données actuelles peut inclure l'intervalle actuel, partiellement rempli.

### Conclusion

Implementing timeseries and aggregations in Subgraphs is a best practice for projects dealing with time-based data. This approach:

- Améliore les performances : Accélère l'indexation et l'interrogation en réduisant le coût du traitement des données.
- Simplifie le développement : Élimine la nécessité d'une logique d'agrégation manuelle dans les correspondances.
- Évolue efficacement : Traite d'importants volumes de données sans compromettre la vitesse ou la réactivité.

By adopting this pattern, developers can build more efficient and scalable Subgraphs, providing faster and more reliable data access to end-users. To learn more about implementing timeseries and aggregations, refer to the [Timeseries and Aggregations Readme](https://github.com/graphprotocol/graph-node/blob/master/docs/aggregations.md) and consider experimenting with this feature in your Subgraphs.

## Bonnes pratiques pour les subgraphs 1-6

1. [Improve Query Speed with Subgraph Pruning](/subgraphs/best-practices/pruning/)

2. [Improve Indexing and Query Responsiveness by Using @derivedFrom](/subgraphs/best-practices/derivedfrom/)

3. [Improve Indexing and Query Performance by Using Immutable Entities and Bytes as IDs](/subgraphs/best-practices/immutable-entities-bytes-as-ids/)

4. [Improve Indexing Speed by Avoiding `eth_calls`](/subgraphs/best-practices/avoid-eth-calls/)

5. [Simplify and Optimize with Timeseries and Aggregations](/subgraphs/best-practices/timeseries/)

6. [Use Grafting for Quick Hotfix Deployment](/subgraphs/best-practices/grafting-hotfix/)

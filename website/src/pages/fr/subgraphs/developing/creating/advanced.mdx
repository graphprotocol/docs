---
title: Fonctionnalités avancées des subgraphs
---

## Aperçu

Add and implement advanced Subgraph features to enhanced your Subgraph's built.

Starting from `specVersion` `0.0.4`, Subgraph features must be explicitly declared in the `features` section at the top level of the manifest file, using their `camelCase` name, as listed in the table below:

| Fonctionnalité                                              | Nom              |
| ----------------------------------------------------------- | ---------------- |
| [Erreurs non fatales](#non-fatal-errors)                    | `nonFatalErrors` |
| [Recherche plein texte](#defining-fulltext-search-fields)   | `fullTextSearch` |
| [Greffage](#grafting-onto-existing-subgraphs)               | `grafting`       |

For instance, if a Subgraph uses the **Full-Text Search** and the **Non-fatal Errors** features, the `features` field in the manifest should be:

```yaml
specVersion: 1.3.0
description: Gravatar for Ethereum
features:
  - fullTextSearch
  - nonFatalErrors
dataSources: ...
```

> Note that using a feature without declaring it will incur a **validation error** during Subgraph deployment, but no errors will occur if a feature is declared but not used.

## Séries chronologiques et agrégations

Prerequisites:

- Subgraph specVersion must be ≥1.1.0.

Timeseries and aggregations enable your Subgraph to track statistics like daily average price, hourly total transfers, and more.

This feature introduces two new types of Subgraph entity. Timeseries entities record data points with timestamps. Aggregation entities perform pre-declared calculations on the timeseries data points on an hourly or daily basis, then store the results for easy access via GraphQL.

### Exemple de schéma

```graphql
type Data @entity(timeseries: true) {
  id: Int8!
  timestamp: Timestamp!
  price: BigDecimal!
}

type Stats @aggregation(intervals: ["hour", "day"], source: "Data") {
  id: Int8!
  timestamp: Timestamp!
  sum: BigDecimal! @aggregate(fn: "sum", arg: "price")
}
```

### How to Define Timeseries and Aggregations

Timeseries entities are defined with `@entity(timeseries: true)` in the GraphQL schema. Every timeseries entity must:

- have a unique ID of the int8 type
- have a timestamp of the Timestamp type
- include data that will be used for calculation by aggregation entities.

These Timeseries entities can be saved in regular trigger handlers, and act as the “raw data” for the aggregation entities.

Aggregation entities are defined with `@aggregation` in the GraphQL schema. Every aggregation entity defines the source from which it will gather data (which must be a timeseries entity), sets the intervals (e.g., hour, day), and specifies the aggregation function it will use (e.g., sum, count, min, max, first, last).

Aggregation entities are automatically calculated on the basis of the specified source at the end of the required interval.

#### Intervalles d'Agrégation disponibles

- `hour`: définit la période de séries chronologiques toutes les heures, à l'heure pile.
- `day`: définit la période de séries chronologiques chaque jour, commençant et se terminant à 00:00.

#### Fonctions d'Agrégation disponibles

- `sum`: Total de toutes les valeurs.
- `count`: Nombre de valeurs.
- `min`: Valeur minimum.
- `max`: Valeur maximum.
- `first`: Première valeur de la période.
- `last` : Dernière valeur de la période.

#### Exemple de requête d'Agrégations

```graphql
{
  stats(interval: "hour", where: { timestamp_gt: 1704085200 }) {
    id
    timestamp
    sum
  }
}
```

[En savoir plus](https://github.com/graphprotocol/graph-node/blob/master/docs/aggregations.md) sur les séries chronologiques et Agrégations.

## Erreurs non fatales

Indexing errors on already synced Subgraphs will, by default, cause the Subgraph to fail and stop syncing. Subgraphs can alternatively be configured to continue syncing in the presence of errors, by ignoring the changes made by the handler which provoked the error. This gives Subgraph authors time to correct their Subgraphs while queries continue to be served against the latest block, though the results might be inconsistent due to the bug that caused the error. Note that some errors are still always fatal. To be non-fatal, the error must be known to be deterministic.

> **Note:** The Graph Network does not yet support non-fatal errors, and developers should not deploy Subgraphs using that functionality to the network via the Studio.

Enabling non-fatal errors requires setting the following feature flag on the Subgraph manifest:

```yaml
specVersion: 1.3.0
description: Gravatar for Ethereum
features:
    - nonFatalErrors
    ...
```

The query must also opt-in to querying data with potential inconsistencies through the `subgraphError` argument. It is also recommended to query `_meta` to check if the Subgraph has skipped over errors, as in the example:

```graphql
foos(first: 100, subgraphError: allow) {
  id
}

_meta {
  hasIndexingErrors
}
```

If the Subgraph encounters an error, that query will return both the data and a graphql error with the message `"indexing_error"`, as in this example response:

```graphql
"data": {
    "foos": [
        {
          "id": "0xdead"
        }
    ],
    "_meta": {
        "hasIndexingErrors": true
    }
},
"errors": [
    {
        "message": "indexing_error"
    }
]
```

## File Data Sources de fichiers IPFS/Arweave

File data sources are a new Subgraph functionality for accessing off-chain data during indexing in a robust, extendable way. File data sources support fetching files from IPFS and from Arweave.

> Cela jette également les bases d’une indexation déterministe des données hors chaîne, ainsi que de l’introduction potentielle de données arbitraires provenant de HTTP.

### Aperçu

Plutôt que de récupérer les fichiers "ligne par ligne" pendant l'exécution du gestionnaire, ceci introduit des modèles qui peuvent être générés comme nouvelles sources de données pour un identifiant de fichier donné. Ces nouvelles sources de données récupèrent les fichiers, réessayant en cas d'échec, et exécutant un gestionnaire dédié lorsque le fichier est trouvé.

Cela est similaire aux [modèles de source de données existants](/developing/creating-a-subgraph/#data-source-templates), qui sont utilisés pour créer dynamiquement de nouvelles sources de données basées sur la blockchain.

> Cela remplace l'API `ipfs.cat` existante

### Guide de mise à niveau

#### Mise à jour de `graph-ts` et `graph-cli`

Les fichiers sources de données requièrent graph-ts >=0.29.0 et graph-cli >=0.33.1

#### Ajouter un nouveau type d'entité qui sera mis à jour lorsque des fichiers seront trouvés

Les sources de données de fichier ne peuvent pas accéder ni mettre à jour les entités basées sur une chaîne, mais doivent mettre à jour les entités spécifiques au fichier.

Cela peut impliquer de diviser les champs des entités existantes en entités distinctes, liées entre elles.

Entité combinée d'origine :

```graphql
type Token @entity {
  id: ID!
  tokenID: BigInt!
  tokenURI: String!
  externalURL: String!
  ipfsURI: String!
  image: String!
  name: String!
  description: String!
  type: String!
  updatedAtTimestamp: BigInt
  owner: User!
}
```

Nouvelle entité scindée :

```graphql
type Token @entity {
  id: ID!
  tokenID: BigInt!
  tokenURI: String!
  ipfsURI: TokenMetadata
  updatedAtTimestamp: BigInt
  owner: String!
}

type TokenMetadata @entity {
  id: ID!
  image: String!
  externalURL: String!
  name: String!
  description: String!
}
```

Si la relation est 1:1 entre l'entité parent et l'entité de source de données de fichier résultante, le modèle le plus simple consiste à lier l'entité parent à une entité de fichier résultante en utilisant le CID IPFS comme recherche. Contactez Discord si vous rencontrez des difficultés pour modéliser vos nouvelles entités basées sur des fichiers !

> Vous pouvez utiliser [les filtres imbriqués](/subgraphs/querying/graphql-api/#example-for-nested-entity-filtering) pour filtrer les entités parents sur la base de ces entités imbriquées.

#### Ajouter une nouvelle source de données modélisée avec `kind : file/ipfs` ou `kind : file/arweave`

Il s'agit de la source de données qui sera générée lorsqu'un fichier d'intérêt est identifié.

```yaml
templates:
  - name: TokenMetadata
    kind: file/ipfs
    mapping:
      apiVersion: 0.0.9
      language: wasm/assemblyscript
      file: ./src/mapping.ts
      handler: handleMetadata
      entities:
        - TokenMetadata
      abis:
        - name: Token
          file: ./abis/Token.json
```

> Actuellement, les `abis` sont nécessaires, bien qu'il ne soit pas possible d'appeler des contrats à partir de fichiers sources de données

Le fichier source de données doit mentionner spécifiquement tous les types d'entités avec lesquels elle interagira sous `entities`. Voir [limitations](#limitations) pour plus de détails.

#### Créer un nouveau gestionnaire pour traiter les fichiers

Ce gestionnaire devrait accepter un paramètre `Bytes`, qui sera le contenu du fichier, lorsqu'il sera trouvé, il pourra alors être traité. Il s'agira souvent d'un fichier JSON, qui peut être traité à l'aide des utilitaires de `graph-ts` ([documentation](/subgraphs/developing/creating/graph-ts/api/#json-api)).

Le CID du fichier sous forme de chaîne de caractères lisible est accessible via `dataSource` de la manière suivante :

```typescript
const cid = dataSource.stringParam()
```

Exemple de gestionnaire :

```typescript
import { json, Bytes, dataSource } from '@graphprotocol/graph-ts'
import { TokenMetadata } from '../generated/schema'

export function handleMetadata(content: Bytes): void {
  let tokenMetadata = new TokenMetadata(dataSource.stringParam())
  const value = json.fromBytes(content).toObject()
  if (value) {
    const image = value.get('image')
    const name = value.get('name')
    const description = value.get('description')
    const externalURL = value.get('external_url')

    if (name && image && description && externalURL) {
      tokenMetadata.name = name.toString()
      tokenMetadata.image = image.toString()
      tokenMetadata.externalURL = externalURL.toString()
      tokenMetadata.description = description.toString()
    }

    tokenMetadata.save()
  }
}
```

#### Générer des sources de données de fichiers si nécessaire

Vous pouvez désormais créer des sources de données de fichiers lors de l'exécution de gestionnaires basés sur une chaîne :

- Importer le modèle à partir du fichier `templates` généré automatiquement
- appeler `TemplateName.create(cid : string)` à partir d'un mappage, où le cid est un identifiant de contenu valide pour IPFS ou Arweave

Pour IPFS, Graph Node prend en charge [les identifiants de contenu v0 et v1](https://docs.ipfs.tech/concepts/content-addressing/), et les identifiants de contenu avec des répertoires (par exemple, `bafyreighykzv2we26wfrbzkcdw37sbrby4upq7ae3aqobbq7i4er3tnxci/metadata.json`).

Pour Arweave, à partir de la version 0.33.0, Graph Node peut récupérer des fichiers stockés sur Arweave sur la base de leur [identifiant de transaction](https://docs.arweave.org/developers/arweave-node-server/http-api#transactions) à partir d'une passerelle Arweave ([exemple de fichier](https://bdxujjl5ev5eerd5ouhhs6o4kjrs4g6hqstzlci5pf6vhxezkgaa.arweave.net/CO9EpX0lekJEfXUOeXncUmMuG8eEp5WJHXl9U9yZUYA)). Arweave prend en charge les transactions téléchargées via Irys (anciennement Bundlr), et Graph Node peut également récupérer des fichiers sur la base les [manifestes Irys](https://docs.irys.xyz/overview/gateways#indexing).

L'exemple:

```typescript
import { TokenMetadata as TokenMetadataTemplate } from '../generated/templates'

const ipfshash = 'QmaXzZhcYnsisuue5WRdQDH6FDvqkLQX1NckLqBYeYYEfm'
//This example code is for a Crypto coven Subgraph. The above ipfs hash is a directory with token metadata for all crypto coven NFTs.

export function handleTransfer(event: TransferEvent): void {
  let token = Token.load(event.params.tokenId.toString())
  if (!token) {
    token = new Token(event.params.tokenId.toString())
    token.tokenID = event.params.tokenId

    token.tokenURI = '/' + event.params.tokenId.toString() + '.json'
    const tokenIpfsHash = ipfshash + token.tokenURI
    //This creates a path to the metadata for a single Crypto coven NFT. It concats the directory with "/" + filename + ".json"

    token.ipfsURI = tokenIpfsHash

    TokenMetadataTemplate.create(tokenIpfsHash)
  }

  token.updatedAtTimestamp = event.block.timestamp
  token.owner = event.params.to.toHexString()
  token.save()
}
```

Cela créera une nouvelle source de données de fichier, qui interrogera le point d'extrémité IPFS ou Arweave configuré du nœud de graphique, en réessayant si elle n'est pas trouvée. Lorsque le fichier est trouvé, le gestionnaire de la source de données de fichier est exécuté.

Cet exemple utilise le CID comme référence entre l'entité parent `Token` et l'entité résultante `TokenMetadata`.

> Previously, this is the point at which a Subgraph developer would have called `ipfs.cat(CID)` to fetch the file

Félicitations, vous utilisez des sources de données de fichiers !

#### Deploying your Subgraphs

You can now `build` and `deploy` your Subgraph to any Graph Node >=v0.30.0-rc.0.

#### Limitations

File data source handlers and entities are isolated from other Subgraph entities, ensuring that they are deterministic when executed, and ensuring no contamination of chain-based data sources. To be specific:

- Les entités créées par les sources de données de fichiers sont immuables et ne peuvent pas être mises à jour
- Les gestionnaires de sources de données de fichiers ne peuvent pas accéder à des entités provenant d'autres sources de données de fichiers
- Les entités associées aux sources de données de fichiers ne sont pas accessibles aux gestionnaires basés sur des chaînes

> While this constraint should not be problematic for most use-cases, it may introduce complexity for some. Please get in touch via Discord if you are having issues modelling your file-based data in a Subgraph!

En outre, il n'est pas possible de créer des sources de données à partir d'une source de données de fichier, qu'il s'agisse d'une source de données onchain ou d'une autre source de données de fichier. Cette restriction pourrait être levée à l'avenir.

#### Meilleures pratiques

Si vous liez des métadonnées NFT aux jetons correspondants, utilisez le hachage IPFS des métadonnées pour référencer une entité Metadata à partir de l'entité Token. Enregistrez l'entité Metadata en utilisant le hachage IPFS comme identifiant.

Vous pouvez utiliser [Le contexte de DataSource](/subgraphs/developing/creating/graph-ts/api/#entity-and-datasourcecontext) lors de la création de fichiers sources de données(File Data Sources) pour transmettre des informations supplémentaires qui seront disponibles pour le gestionnaire de la File Data Source.

Si vous avez des entités qui sont actualisées plusieurs fois, créez des entités uniques basées sur des fichiers en utilisant le hash IPFS & l'ID de l'entité, puis référencez-les en utilisant un champ dérivé dans l'entité basée sur la chaîne.

> Nous travaillons à l'amélioration de la recommandation ci-dessus, afin que les requêtes ne renvoient que la version "la plus récente"

#### Problèmes connus

Les fichiers sources de données nécessitent actuellement des ABI, même si les ABI ne sont pas utilisées ([problème](https://github.com/graphprotocol/graph-cli/issues/961)). La solution consiste à ajouter n'importe quel ABI.

Les gestionnaires pour les fichiers sources de données ne peuvent pas être dans des fichiers qui importent des liaisons de contrat `eth_call`, échouant avec "unknown import : `ethereum::ethereum.call` n'a pas été défini" ([problème](https://github.com/graphprotocol/graph-node/issues/4309)). La solution consiste à créer des gestionnaires de fichiers de sources de données dans un fichier dédié.

#### Exemples

[migration de subgraph Crypto Coven ](https://github.com/azf20/cryptocoven-api/tree/file-data-sources-refactor)

#### Les Références

[fichier sources de données GIP](https://forum.thegraph.com/t/gip-file-data-sources/2721)

## Filtres d'Arguments indexés / Filtres de Topics

> **Nécessite** : [SpecVersion](#specversion-releases) >= `1.2.0`

Topic filters, also known as indexed argument filters, are a powerful feature in Subgraphs that allow users to precisely filter blockchain events based on the values of their indexed arguments.

- These filters help isolate specific events of interest from the vast stream of events on the blockchain, allowing Subgraphs to operate more efficiently by focusing only on relevant data.

- This is useful for creating personal Subgraphs that track specific addresses and their interactions with various smart contracts on the blockchain.

### Comment fonctionnent les filtres de Topics

When a smart contract emits an event, any arguments that are marked as indexed can be used as filters in a Subgraph's manifest. This allows the Subgraph to listen selectively for events that match these indexed arguments.

- Le premier argument indexé de l'événement correspond à `topic1`, le second à `topic2`, et ainsi de suite, jusqu'à `topic3`, puisque la machine virtuelle Ethereum (EVM) autorise jusqu'à trois arguments indexés par événement.

```solidity
// SPDX-License-Identifier: MIT
pragma solidity ^0.8.0;

contract Token {
    // Déclaration de l'événement avec des paramètres indexés pour les adresses
    event Transfer(address indexed from, address indexed to, uint256 value);

    // Fonction pour simuler le transfert de tokens
    function transfer(address to, uint256 value) public {
        // Emission de l'événement Transfer avec from, to, et value
        emit Transfer(msg.sender, to, value);
    }
}
```

Dans cet exemple:

- L'événement `Transfer` est utilisé pour enregistrer les transactions de jetons entre adresses.
- Les paramètres `from` et `to` sont indexés, ce qui permet aux auditeurs d'événements de filtrer et de surveiller les transferts impliquant des adresses spécifiques.
- La fonction `transfer` est une représentation simple d'une action de transfert de jeton, émettant l'événement Transfer à chaque fois qu'elle est appelée.

#### Configuration dans les subgraphs

Topic filters are defined directly within the event handler configuration in the Subgraph manifest. Here is how they are configured:

```yaml
eventHandlers:
  - event: SomeEvent(indexed uint256, indexed address, indexed uint256)
    handler: handleSomeEvent
    topic1: ['0xValue1', '0xValue2']
    topic2: ['0xAddress1', '0xAddress2']
    topic3: ['0xValue3']
```

Dans cette configuration :

- `topic1` correspond au premier argument indexé de l'événement, `topic2` au deuxième et `topic3` au troisième.
- Chaque topic peut avoir une ou plusieurs valeurs, et un événement n'est traité que s'il correspond à l'une des valeurs de chaque rubrique spécifiée.

#### Logique des Filtres

- Au sein d'une même Topic: La logique fonctionne comme une condition OR. L'événement sera traité s'il correspond à l'une des valeurs listées dans une rubrique donnée.
- Entre différents Topics: La logique fonctionne comme une condition AND. Un événement doit satisfaire toutes les conditions spécifiées à travers les différents topics pour déclencher le gestionnaire associé.

#### Exemple 1 : Suivi des transferts directs de l'adresse A à l'adresse B

```yaml
eventHandlers:
  - event: Transfer(indexed address,indexed address,uint256)
    handler: handleDirectedTransfer
    topic1: ['0xAddressA'] # Sender Address
    topic2: ['0xAddressB'] # Receiver Address
```

Dans cette configuration:

- `topic1` est configuré pour filtrer les événements `Transfer` dont l'expéditeur est `0xAddressA`.
- `topic2` est configuré pour filtrer les événements `Transfer` dont `0xAddressB` est le destinataire.
- The Subgraph will only index transactions that occur directly from `0xAddressA` to `0xAddressB`.

#### Exemple 2 : Suivi des transactions dans les deux sens entre deux ou plusieurs adresses

```yaml
eventHandlers:
  - event: Transfer(indexed address,indexed address,uint256)
    handler: handleTransferToOrFrom
    topic1: ['0xAddressA', '0xAddressB', '0xAddressC'] # Sender Address
    topic2: ['0xAddressB', '0xAddressC'] # Receiver Address
```

Dans cette configuration:

- `topic1` est configuré pour filtrer les événements `Transfer` dont l'expéditeur est `0xAddressA`, `0xAddressB`, `0xAddressC`.
- `topic2` est configuré pour filtrer les événements `Transfer` où `0xAddressB` et `0xAddressC` sont les destinataires.
- The Subgraph will index transactions that occur in either direction between multiple addresses allowing for comprehensive monitoring of interactions involving all addresses.

## Déclaration eth_call

> Remarque : Il s'agit d'une fonctionnalité expérimentale qui n'est pas encore disponible dans une version stable de Graph Node. Vous ne pouvez l'utiliser que dans Subgraph Studio ou sur votre nœud auto-hébergé.

Declarative `eth_calls` are a valuable Subgraph feature that allows `eth_calls` to be executed ahead of time, enabling `graph-node` to execute them in parallel.

Cette fonctionnalité permet de :

- Significantly improves the performance of fetching data from the Ethereum blockchain by reducing the total time for multiple calls and optimizing the Subgraph's overall efficiency.
- Permet une récupération plus rapide des données, entraînant des réponses de requête plus rapides et une meilleure expérience utilisateur.
- Réduire les temps d'attente pour les applications qui doivent réunir des données de plusieurs appels Ethereum, rendant le processus de récupération des données plus efficace.

### Concepts clés

- Les `eth_calls` déclaratifs : Appels Ethereum qui sont définis pour être exécutés en parallèle plutôt que séquentiellement.
- Exécution en parallèle : Au lieu d'attendre la fin d'un appel avant de commencer le suivant, plusieurs appels peuvent être initiés simultanément.
- Efficacité temporelle : Le temps total nécessaire pour tous les appels passe de la somme des temps d'appel individuels (séquentiels) au temps pris par l'appel le plus long (parallèle).

#### Scénario sans `eth_calls` déclaratifs

Imagine you have a Subgraph that needs to make three Ethereum calls to fetch data about a user's transactions, balance, and token holdings.

Traditionnellement, ces appels pourraient être effectués de manière séquentielle :

1. Appel 1 (Transactions) : Prend 3 secondes
2. Appel 2 (Solde) : Prend 2 secondes
3. Appel 3 (Avoirs en jetons) : Prend 4 secondes

Temps total pris = 3 + 2 + 4 = 9 secondes

#### Scénario avec `eth_calls` déclaratif

Avec cette fonctionnalité, vous pouvez déclarer que ces appels soient exécutés en parallèle :

1. Appel 1 (Transactions) : Prend 3 secondes
2. Appel 2 (Solde) : Prend 2 secondes
3. Appel 3 (Avoirs en jetons) : Prend 4 secondes

Puisque ces appels sont exécutés en parallèle, le temps total pris est égal au temps pris par l'appel le plus long.

Temps total pris = max (3, 2, 4) = 4 secondes

#### Comment ça marche

1. Declarative Definition: In the Subgraph manifest, you declare the Ethereum calls in a way that indicates they can be executed in parallel.
2. Moteur d'exécution parallèle : Le moteur d'exécution de Graph Node reconnaît ces déclarations et exécute les appels simultanément.
3. Result Aggregation: Once all calls are complete, the results are aggregated and used by the Subgraph for further processing.

#### Exemple de configuration dans le manifeste du subgraph

Les `eth_calls` déclarés peuvent accéder à l'adresse `event.address` de l'événement sous-jacent ainsi qu'à tous les paramètres `event.params`.

`subgraph.yaml` using `event.address`:

```yaml
eventHandlers:
event: Swap(indexed address,indexed address,int256,int256,uint160,uint128,int24)
handler: handleSwap
calls:
  global0X128: Pool[event.address].feeGrowthGlobal0X128()
  global1X128: Pool[event.address].feeGrowthGlobal1X128()
```

Détails pour l'exemple ci-dessus :

- `global0X128` est le nom déclaré de `eth_call`.
- Le texte (`global0X128`) est le label de ce `eth_call` qui est utilisé lors de la journalisation des erreurs.
- Le texte (`Pool[event.address].feeGrowthGlobal0X128()`) est le `eth_call` réel qui sera exécuté, et est sous la forme de `Contract[address].function(arguments)`
- L'adresse et les arguments peuvent être remplacés par des variables qui seront disponibles lorsque le gestionnaire sera exécuté.

`subgraph.yaml` using `event.params`

```yaml
calls:
  - ERC20DecimalsToken0: ERC20[event.params.token0].decimals()
```

### Greffe sur des subgraphs existants

> **Note:** il n'est pas recommandé d'utiliser le greffage lors de l'upgrade initial vers The Graph Network. Pour en savoir plus [ici](/subgraphs/cookbook/grafting/#important-note-on-grafting-when-upgrading-to-the-network).

When a Subgraph is first deployed, it starts indexing events at the genesis block of the corresponding chain (or at the `startBlock` defined with each data source) In some circumstances; it is beneficial to reuse the data from an existing Subgraph and start indexing at a much later block. This mode of indexing is called _Grafting_. Grafting is, for example, useful during development to get past simple errors in the mappings quickly or to temporarily get an existing Subgraph working again after it has failed.

A Subgraph is grafted onto a base Subgraph when the Subgraph manifest in `subgraph.yaml` contains a `graft` block at the top-level:

```yaml
description: ...
graft:
  base: Qm... # Subgraph ID of base Subgraph
  block: 7345624 # Block number
```

When a Subgraph whose manifest contains a `graft` block is deployed, Graph Node will copy the data of the `base` Subgraph up to and including the given `block` and then continue indexing the new Subgraph from that block on. The base Subgraph must exist on the target Graph Node instance and must have indexed up to at least the given block. Because of this restriction, grafting should only be used during development or during an emergency to speed up producing an equivalent non-grafted Subgraph.

Because grafting copies rather than indexes base data, it is much quicker to get the Subgraph to the desired block than indexing from scratch, though the initial data copy can still take several hours for very large Subgraphs. While the grafted Subgraph is being initialized, the Graph Node will log information about the entity types that have already been copied.

The grafted Subgraph can use a GraphQL schema that is not identical to the one of the base Subgraph, but merely compatible with it. It has to be a valid Subgraph schema in its own right, but may deviate from the base Subgraph's schema in the following ways:

- Il ajoute ou supprime des types d'entité
- Il supprime les attributs des types d'entité
- Il ajoute des attributs nullables aux types d'entités
- Il transforme les attributs non nullables en attributs nuls
- Cela ajoute des valeurs aux énumérations
- Il ajoute ou supprime des interfaces
- Cela change pour quels types d'entités une interface est implémentée

> **[Feature Management](#experimental-features):** `grafting` must be declared under `features` in the Subgraph manifest.
